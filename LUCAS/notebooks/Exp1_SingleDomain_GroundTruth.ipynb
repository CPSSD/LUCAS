{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Testing on Single Domain (Ground Truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment uses a 'ground truth' labelled dataset of NYC Resteraunt reviews from Yelp. This dataset has 359,052 reviews so should be sufficient for training.\n",
    "\n",
    "The aim of this experiment is to produce a benchmark from which we can compare our explorative experiments. This is the first of a number of experiments using statistical modelling, all of which are done with the aim of finding a benchmark. \n",
    "\n",
    "We will use Complement Naive Bayes to produce a model, and Bag of Words to convert our text features to usable predictor features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to access out project files we add the project directory to PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is located in the following file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = 'data/yelpNYC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is in protobuf format, so we read it into the ReviewSet protobuffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from protos import review_set_pb2\n",
    "review_set = review_set_pb2.ReviewSet()\n",
    "with open(data_file_path, 'rb') as f:\n",
    "  review_set.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our data. We use the following features from our data:\n",
    "* Review Content. The actual text description of the restaurant.\n",
    "* Date user left review.\n",
    "* ID of the user that left the review\n",
    "* ID of the product the review is being left on\n",
    "\n",
    "And also the label (Fake = True, Genuine = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review content</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>2014-12-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>2011-07-28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snack is great place for a  casual sit down lu...</td>\n",
       "      <td>2010-11-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      review content        date  label\n",
       "0  The food at snack is a selection of popular Gr...  2014-12-08   True\n",
       "1  This little place in Soho is wonderful. I had ...  2013-05-16   True\n",
       "2  ordered lunch for 15 from Snack last Friday.  ...  2013-07-01   True\n",
       "3  This is a beautiful quaint little restaurant o...  2011-07-28   True\n",
       "4  Snack is great place for a  casual sit down lu...  2010-11-01   True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "frame_data = {\n",
    "    \"review content\": [],\n",
    "    \"date\": [],\n",
    "    \"label\": []\n",
    "}\n",
    "for review in review_set.reviews:  \n",
    "  frame_data[\"review content\"].append(review.review_content)\n",
    "  frame_data[\"date\"].append(review.date)\n",
    "  frame_data[\"label\"].append(review.label)\n",
    "\n",
    "data_frame = pandas.DataFrame(frame_data)\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to know if the number of fake and genuine reviews are balanced in our training set. If not, the classifier would be biased towards picking either fake or genuine because it is more common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake: 36885 Genuine: 322167\n"
     ]
    }
   ],
   "source": [
    "reviews = review_set.reviews\n",
    "fake_reviews = [x for x in reviews if x.label]\n",
    "num_fake = len(fake_reviews)\n",
    "print(\"Fake:\", len(fake_reviews), \"Genuine:\", len(reviews)-num_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more genuine reviews than fake ones. To avoid a bias, let's get an even number of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genuine_reviews = []\n",
    "i = 0\n",
    "while len(genuine_reviews) < num_fake:\n",
    "  if not reviews[i].label:\n",
    "    genuine_reviews.append(reviews[i])\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will convert our reviews into features. Since we will be doing cross validation, we will prepare our entire sample set, and we will split it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_reviews = shuffle(reviews)#genuine_reviews + fake_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Bag of Words to convert our review content to a format that can be used as a feature. In scikit learn the Bag of Words format is created using a CountVectorizer. We transform our test set into the same feature format to correspond with the Bag of Words created for our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359052, 128280)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_review_content = [x.review_content for x in X_reviews]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(X_review_content)\n",
    "X_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we convert the dates to numerical ordinals, so we can use them as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "def extract_date_ordinals(reviews):\n",
    "  return [dt.strptime(x.date, '%Y-%m-%d').date().toordinal() for x in reviews]\n",
    "\n",
    "X_date_ordinals = extract_date_ordinals(X_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can simply read our user ids and product ids. They are already numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_user_ids = [x.user_id for x in X_reviews]\n",
    "X_product_ids = [x.product_id for x in X_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put our features together. The sparse features from Bag of Words overshadows our dense features (date). We put this into a format we can train/test on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, hstack\n",
    "def format_column(features_row):\n",
    "  return coo_matrix([[x] for x in features_row])\n",
    "\n",
    "def stack_features(counts, ordinals, user_ids, product_ids):\n",
    "  return hstack([counts, format_column(ordinals), format_column(user_ids), format_column(product_ids)])\n",
    "\n",
    "predictor_data = stack_features(X_counts, X_date_ordinals, X_user_ids, X_product_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And preparing the targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [1 if x.label else 0 for x in X_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Complement Naive Bayes to generate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB, MultinomialNB\n",
    "cnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Now let's test what we have. We will use cross validation here, splitting our set into 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.12083054, 0.98920536, 0.98635817, 0.97608113, 0.97887635,\n",
       "        0.9742465 , 0.97270703, 0.98200083, 0.97625303, 0.9753201 ]),\n",
       " 'score_time': array([0.03546643, 0.03169847, 0.03196883, 0.03173232, 0.03199983,\n",
       "        0.03211808, 0.03211379, 0.03218532, 0.03198695, 0.03186417]),\n",
       " 'test_score': array([0.66136579, 0.6618114 , 0.6622013 , 0.66169999, 0.66058597,\n",
       "        0.66180198, 0.66489347, 0.66048351, 0.65686275, 0.66045566])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cross_validate(cnb, predictor_data, targets, cv=10, return_train_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When the only features were review_content (Bag of words) and date, the score was around 0.52. Adding user_id and product_id increased this to around 0.65\n",
    "* When then reducing the number of genuine reviews to match the number of fake reviews, the accuracy increases to 0.88.\n",
    "* When using Multinomail NB with reduced size genuine reviews, it beats Stanfords.\n",
    "\n",
    "The accuracy increases a lot when the number of genuine reviews drops. This might be because with a small enough sample size it's possible to just mimic the behaviour of the sample. I will check how the classifier classes all the remaining genuine reviews. Now it should class as few as possible as fake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285282\n"
     ]
    }
   ],
   "source": [
    "spare_genuine_reviews = [x for x in reviews[i:] if x.label == False]\n",
    "print (len(spare_genuine_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb.fit(predictor_data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_review_content = [s.review_content for s in spare_genuine_reviews]\n",
    "S_counts = count_vect.transform(S_review_content)\n",
    "\n",
    "S_date_ordinals = extract_date_ordinals(spare_genuine_reviews)\n",
    "S_user_ids = [s.user_id for s in spare_genuine_reviews]\n",
    "S_product_ids = [s.product_id for s in spare_genuine_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spare_predictor_data = stack_features(S_counts, S_date_ordinals, S_user_ids, S_product_ids)\n",
    "cnb.predict(spare_predictor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
