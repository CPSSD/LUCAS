{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network Benchmark\n",
    "\n",
    "To create a benchmark for comparing future work, this experiment aims to create a simple feedforward neural network and apply it to a substantial amount of our data.\n",
    "\n",
    "This network will receive pretrained word2vec vectors as input and pass them through three dense layers. One dropout layer will exist after the first dense layer to help reduce overfitting.\n",
    "\n",
    "Although FFNN have been used in earlier experiments, this is the first to run it over a substantial amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scripts.cross_validate import run_single_cross_validate\n",
    "from scripts.feature_extraction import get_balanced_dataset, get_entire_dataset, scaled_reviewer_features\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Dropout, Embedding, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from exp2_feature_extraction import reviewer_features, reviews_by_reviewer\n",
    "from metrics import auroc, f1\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "import statistics\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from seaborn import boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = get_balanced_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156692"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review_content(review_content):\n",
    "  return \" \".join([x for x in nltk.word_tokenize(review_content) if x.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_contents = [clean_review_content(x.review_content) for x in all_reviews]\n",
    "labels = [1 if x.label else 0 for x in all_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must convert our reviews to sequences, as this is the input to the 'Embedding' layer of our model that maps words to their embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(reviews_contents)\n",
    "input_features = np.array(pad_sequences(tokenizer.texts_to_sequences(reviews_contents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words = tokenizer.word_index\n",
    "corpus_vocab_size = len(corpus_words)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the word2vec embeddings pretrained by google over a large Google News corpus. We use this to create an embedding matrix, which is a map of sequence identifier (number of the word) to it's vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(\"../../data/GoogleNews-vectors-negative300.bin\",\n",
    "                                                               binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_length = word_vectors.vector_size\n",
    "embedding_matrix = np.zeros((corpus_vocab_size, embedding_length))\n",
    "for word, index in corpus_words.items():\n",
    "  if word in word_vectors.vocab:\n",
    "    embedding_matrix[index] = np.array(word_vectors[word], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must calculate the max review length since the Embedding layer of our model uses this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "max_review_len = 0\n",
    "for input_feature in input_features:\n",
    "    max_review_len = max(max_review_len, len(input_feature))\n",
    "print(max_review_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of words in our vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76783"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that our input dataset is roughly balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78346"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x.label for x in all_reviews if x.label == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the model described and give our sequences as input. The model converts the sequences to embeddings and passes them through the FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ff_wv_model():\n",
    "  i1 = Input(shape=(max_review_len,))\n",
    "  i2 = Input(shape=(5,))\n",
    "    \n",
    "  l1 = Embedding(corpus_vocab_size, embedding_length, weights=[embedding_matrix], trainable=False)(i1)\n",
    "  l2 = Flatten()(l1)\n",
    "  l3 = Concatenate()([l2, i2])\n",
    "  l4 = Dense(16, activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.l2(0.01))(l3)\n",
    "  l5 = Dropout(0.25)(l4)\n",
    "  l6 = Dense(8, activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.l2(0.01))(l5)\n",
    "  l7 = Dense(1, activation=tf.keras.activations.sigmoid)(l6)\n",
    "\n",
    "  model = Model(inputs=[i1, i2], outputs=l7)\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ffnn_model(train_X, train_y, test_X, test_y):\n",
    "    ffnn_model = get_ff_wv_model()\n",
    "    return ffnn_model.fit([x for x in train_X], train_y, epochs=50, batch_size=256, verbose=1, shuffle=False,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=8)],\n",
    "                   validation_data=([x for x in test_X], test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer = scaled_reviewer_features(all_reviews, get_entire_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_features = input_features[:-10000]\n",
    "train_reviewer = reviewer[:-10000]\n",
    "train_labels = labels[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 132021 samples, validate on 14671 samples\n",
      "Epoch 1/50\n",
      "132021/132021 [==============================] - 44s 336us/step - loss: 0.7748 - acc: 0.6569 - auroc: 0.7101 - f1: 0.6546 - val_loss: 0.6993 - val_acc: 0.6923 - val_auroc: 0.7512 - val_f1: 0.7025\n",
      "Epoch 2/50\n",
      "132021/132021 [==============================] - 44s 331us/step - loss: 0.7135 - acc: 0.6848 - auroc: 0.7419 - f1: 0.6853 - val_loss: 0.6984 - val_acc: 0.6961 - val_auroc: 0.7554 - val_f1: 0.7144\n",
      "Epoch 3/50\n",
      "132021/132021 [==============================] - 44s 333us/step - loss: 0.7043 - acc: 0.6878 - auroc: 0.7450 - f1: 0.6881 - val_loss: 0.6868 - val_acc: 0.6976 - val_auroc: 0.7549 - val_f1: 0.6947\n",
      "Epoch 4/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7013 - acc: 0.6881 - auroc: 0.7458 - f1: 0.6876 - val_loss: 0.6987 - val_acc: 0.6962 - val_auroc: 0.7578 - val_f1: 0.7229\n",
      "Epoch 5/50\n",
      "132021/132021 [==============================] - 44s 333us/step - loss: 0.7016 - acc: 0.6889 - auroc: 0.7463 - f1: 0.6884 - val_loss: 0.6959 - val_acc: 0.6951 - val_auroc: 0.7524 - val_f1: 0.7007\n",
      "Epoch 6/50\n",
      "132021/132021 [==============================] - 44s 330us/step - loss: 0.6996 - acc: 0.6905 - auroc: 0.7487 - f1: 0.6893 - val_loss: 0.6876 - val_acc: 0.7035 - val_auroc: 0.7612 - val_f1: 0.7136\n",
      "Epoch 7/50\n",
      "132021/132021 [==============================] - 44s 332us/step - loss: 0.6995 - acc: 0.6889 - auroc: 0.7480 - f1: 0.6887 - val_loss: 0.6828 - val_acc: 0.7051 - val_auroc: 0.7637 - val_f1: 0.7197\n",
      "Epoch 8/50\n",
      "132021/132021 [==============================] - 43s 328us/step - loss: 0.6981 - acc: 0.6901 - auroc: 0.7486 - f1: 0.6900 - val_loss: 0.6959 - val_acc: 0.6982 - val_auroc: 0.7584 - val_f1: 0.7231\n",
      "Epoch 9/50\n",
      "132021/132021 [==============================] - 44s 330us/step - loss: 0.7013 - acc: 0.6902 - auroc: 0.7495 - f1: 0.6899 - val_loss: 0.6908 - val_acc: 0.7038 - val_auroc: 0.7654 - val_f1: 0.7195\n",
      "Epoch 10/50\n",
      "132021/132021 [==============================] - 44s 332us/step - loss: 0.6993 - acc: 0.6917 - auroc: 0.7506 - f1: 0.6912 - val_loss: 0.6929 - val_acc: 0.7035 - val_auroc: 0.7621 - val_f1: 0.7133\n",
      "Epoch 11/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7011 - acc: 0.6908 - auroc: 0.7501 - f1: 0.6914 - val_loss: 0.6828 - val_acc: 0.7052 - val_auroc: 0.7626 - val_f1: 0.7227\n",
      "Epoch 12/50\n",
      "132021/132021 [==============================] - 44s 333us/step - loss: 0.7005 - acc: 0.6918 - auroc: 0.7510 - f1: 0.6939 - val_loss: 0.6865 - val_acc: 0.7067 - val_auroc: 0.7661 - val_f1: 0.7170\n",
      "Epoch 13/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7007 - acc: 0.6918 - auroc: 0.7511 - f1: 0.6936 - val_loss: 0.6930 - val_acc: 0.7092 - val_auroc: 0.7625 - val_f1: 0.7251\n",
      "Epoch 14/50\n",
      "132021/132021 [==============================] - 45s 339us/step - loss: 0.7003 - acc: 0.6918 - auroc: 0.7511 - f1: 0.6941 - val_loss: 0.6900 - val_acc: 0.7073 - val_auroc: 0.7698 - val_f1: 0.7292\n",
      "Epoch 15/50\n",
      "132021/132021 [==============================] - 45s 340us/step - loss: 0.7034 - acc: 0.6935 - auroc: 0.7517 - f1: 0.6966 - val_loss: 0.6931 - val_acc: 0.7102 - val_auroc: 0.7686 - val_f1: 0.7240\n",
      "Epoch 16/50\n",
      "132021/132021 [==============================] - 45s 342us/step - loss: 0.7051 - acc: 0.6920 - auroc: 0.7512 - f1: 0.6947 - val_loss: 0.6873 - val_acc: 0.6974 - val_auroc: 0.7623 - val_f1: 0.7215\n",
      "Epoch 17/50\n",
      "132021/132021 [==============================] - 45s 343us/step - loss: 0.7006 - acc: 0.6912 - auroc: 0.7515 - f1: 0.6951 - val_loss: 0.6958 - val_acc: 0.6985 - val_auroc: 0.7625 - val_f1: 0.7266\n",
      "Epoch 18/50\n",
      "132021/132021 [==============================] - 45s 344us/step - loss: 0.6997 - acc: 0.6931 - auroc: 0.7519 - f1: 0.6969 - val_loss: 0.6888 - val_acc: 0.7079 - val_auroc: 0.7669 - val_f1: 0.7262\n",
      "Epoch 19/50\n",
      "132021/132021 [==============================] - 45s 344us/step - loss: 0.7055 - acc: 0.6936 - auroc: 0.7529 - f1: 0.6985 - val_loss: 0.6732 - val_acc: 0.7146 - val_auroc: 0.7717 - val_f1: 0.7241\n",
      "Epoch 20/50\n",
      "132021/132021 [==============================] - 45s 343us/step - loss: 0.7028 - acc: 0.6942 - auroc: 0.7526 - f1: 0.6981 - val_loss: 0.6843 - val_acc: 0.7085 - val_auroc: 0.7668 - val_f1: 0.7355\n",
      "Epoch 21/50\n",
      "132021/132021 [==============================] - 45s 339us/step - loss: 0.7022 - acc: 0.6927 - auroc: 0.7522 - f1: 0.6981 - val_loss: 0.6912 - val_acc: 0.7040 - val_auroc: 0.7677 - val_f1: 0.7316\n",
      "Epoch 22/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7043 - acc: 0.6935 - auroc: 0.7524 - f1: 0.6985 - val_loss: 0.6942 - val_acc: 0.7045 - val_auroc: 0.7646 - val_f1: 0.7274\n",
      "Epoch 23/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7058 - acc: 0.6939 - auroc: 0.7526 - f1: 0.6992 - val_loss: 0.6905 - val_acc: 0.7053 - val_auroc: 0.7680 - val_f1: 0.7289\n",
      "Epoch 24/50\n",
      "132021/132021 [==============================] - 44s 336us/step - loss: 0.7042 - acc: 0.6932 - auroc: 0.7526 - f1: 0.6992 - val_loss: 0.7004 - val_acc: 0.6993 - val_auroc: 0.7620 - val_f1: 0.7240\n",
      "Epoch 25/50\n",
      "132021/132021 [==============================] - 44s 337us/step - loss: 0.7054 - acc: 0.6940 - auroc: 0.7528 - f1: 0.6992 - val_loss: 0.6873 - val_acc: 0.7128 - val_auroc: 0.7669 - val_f1: 0.7308\n",
      "Epoch 26/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7006 - acc: 0.6928 - auroc: 0.7528 - f1: 0.6988 - val_loss: 0.6856 - val_acc: 0.7062 - val_auroc: 0.7667 - val_f1: 0.7297\n",
      "Epoch 27/50\n",
      "132021/132021 [==============================] - 44s 333us/step - loss: 0.7058 - acc: 0.6947 - auroc: 0.7540 - f1: 0.6998 - val_loss: 0.6844 - val_acc: 0.7077 - val_auroc: 0.7698 - val_f1: 0.7275\n",
      "Validation Loss:\n",
      "[0.6993487904216604, 0.6984497896448884, 0.6868059744166009, 0.698707974218703, 0.6959366901066639, 0.6876175906604381, 0.6828041801699002, 0.6959195081486097, 0.6907818485245644, 0.6928602219659868, 0.6827885685267034, 0.6865233676653439, 0.6930352644266733, 0.6899912199126732, 0.6930645000113113, 0.6873310520624417, 0.6957985096227723, 0.6888322251461074, 0.6732355435196343, 0.684255246707051, 0.6911981660207676, 0.6942324814690166, 0.6904939644485072, 0.700431757783867, 0.687341415100437, 0.6855933643234068, 0.6843911290055005]\n",
      "Validation Accuracy:\n",
      "[0.6923181785817901, 0.6961352328046375, 0.697566628074217, 0.6962033945978984, 0.6951128077258378, 0.7034966941910461, 0.7051325743853798, 0.6981800833035081, 0.7038375024179294, 0.7034966940204105, 0.7052007360648835, 0.7067002931074101, 0.7091541135329815, 0.7073137481295009, 0.7101765388189816, 0.6973621429219485, 0.6985208915872699, 0.7079272031881564, 0.714607048043606, 0.7084724968882655, 0.7039738257769369, 0.7044509578178562, 0.7053370594238911, 0.6993388318347586, 0.7127666826035606, 0.706154999785137, 0.7076545567342202]\n",
      "Validation F1:\n",
      "[0.7024976801314844, 0.7144282214375542, 0.6947273164753955, 0.7228807848449395, 0.7006623305334131, 0.7135729488196382, 0.7196556445637508, 0.7230758016545481, 0.7194524775959704, 0.7132916554181937, 0.7227240652526443, 0.7169525594069713, 0.7251461636808035, 0.7291574852369564, 0.7240011529090109, 0.7215325429870034, 0.7265663160379741, 0.7261774828362324, 0.7240855165659288, 0.7355030463213293, 0.731592098219118, 0.7274266590281309, 0.7288691127408332, 0.7240309507826843, 0.730804591211071, 0.7296921755425583, 0.727482160804592]\n",
      "Validation AUROC:\n",
      "[0.7024976801314844, 0.7144282214375542, 0.6947273164753955, 0.7228807848449395, 0.7006623305334131, 0.7135729488196382, 0.7196556445637508, 0.7230758016545481, 0.7194524775959704, 0.7132916554181937, 0.7227240652526443, 0.7169525594069713, 0.7251461636808035, 0.7291574852369564, 0.7240011529090109, 0.7215325429870034, 0.7265663160379741, 0.7261774828362324, 0.7240855165659288, 0.7355030463213293, 0.731592098219118, 0.7274266590281309, 0.7288691127408332, 0.7240309507826843, 0.730804591211071, 0.7296921755425583, 0.727482160804592]\n",
      "best: {'val_f1': 0.7240855165659288, 'val_auroc': 0.7716540556686994, 'val_accuracy': 0.714607048043606, 'val_loss': 0.6732355435196343}\n",
      "Train on 132023 samples, validate on 14669 samples\n",
      "Epoch 1/50\n",
      "132023/132023 [==============================] - 45s 341us/step - loss: 0.7702 - acc: 0.6559 - auroc: 0.7089 - f1: 0.6589 - val_loss: 0.7089 - val_acc: 0.6857 - val_auroc: 0.7435 - val_f1: 0.6851\n",
      "Epoch 2/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7168 - acc: 0.6843 - auroc: 0.7404 - f1: 0.6767 - val_loss: 0.7035 - val_acc: 0.6930 - val_auroc: 0.7513 - val_f1: 0.7101\n",
      "Epoch 3/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7121 - acc: 0.6872 - auroc: 0.7448 - f1: 0.6799 - val_loss: 0.7099 - val_acc: 0.6993 - val_auroc: 0.7567 - val_f1: 0.7165\n",
      "Epoch 4/50\n",
      "132023/132023 [==============================] - 44s 336us/step - loss: 0.7146 - acc: 0.6889 - auroc: 0.7473 - f1: 0.6854 - val_loss: 0.7093 - val_acc: 0.6906 - val_auroc: 0.7522 - val_f1: 0.7180\n",
      "Epoch 5/50\n",
      "132023/132023 [==============================] - 44s 331us/step - loss: 0.7183 - acc: 0.6903 - auroc: 0.7487 - f1: 0.6870 - val_loss: 0.7153 - val_acc: 0.6983 - val_auroc: 0.7583 - val_f1: 0.7182\n",
      "Epoch 6/50\n",
      "132023/132023 [==============================] - 44s 336us/step - loss: 0.7195 - acc: 0.6912 - auroc: 0.7502 - f1: 0.6893 - val_loss: 0.7218 - val_acc: 0.6899 - val_auroc: 0.7567 - val_f1: 0.7231\n",
      "Epoch 7/50\n",
      "132023/132023 [==============================] - 45s 340us/step - loss: 0.7159 - acc: 0.6936 - auroc: 0.7504 - f1: 0.6921 - val_loss: 0.7026 - val_acc: 0.7005 - val_auroc: 0.7608 - val_f1: 0.7183\n",
      "Epoch 8/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7157 - acc: 0.6908 - auroc: 0.7507 - f1: 0.6885 - val_loss: 0.7055 - val_acc: 0.7037 - val_auroc: 0.7643 - val_f1: 0.7170\n",
      "Epoch 9/50\n",
      "132023/132023 [==============================] - 44s 334us/step - loss: 0.7128 - acc: 0.6906 - auroc: 0.7514 - f1: 0.6891 - val_loss: 0.7056 - val_acc: 0.7041 - val_auroc: 0.7618 - val_f1: 0.7276\n",
      "Epoch 10/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7130 - acc: 0.6916 - auroc: 0.7507 - f1: 0.6900 - val_loss: 0.7081 - val_acc: 0.6959 - val_auroc: 0.7548 - val_f1: 0.7078\n",
      "Epoch 11/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7139 - acc: 0.6926 - auroc: 0.7524 - f1: 0.6910 - val_loss: 0.7203 - val_acc: 0.6889 - val_auroc: 0.7593 - val_f1: 0.7274\n",
      "Epoch 12/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7136 - acc: 0.6930 - auroc: 0.7527 - f1: 0.6935 - val_loss: 0.7085 - val_acc: 0.6960 - val_auroc: 0.7536 - val_f1: 0.7036\n",
      "Epoch 13/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7148 - acc: 0.6935 - auroc: 0.7531 - f1: 0.6934 - val_loss: 0.6979 - val_acc: 0.7063 - val_auroc: 0.7668 - val_f1: 0.7264\n",
      "Epoch 14/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7137 - acc: 0.6931 - auroc: 0.7539 - f1: 0.6925 - val_loss: 0.7160 - val_acc: 0.6936 - val_auroc: 0.7557 - val_f1: 0.7156\n",
      "Epoch 15/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7166 - acc: 0.6913 - auroc: 0.7531 - f1: 0.6918 - val_loss: 0.7128 - val_acc: 0.6900 - val_auroc: 0.7606 - val_f1: 0.7212\n",
      "Epoch 16/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7138 - acc: 0.6922 - auroc: 0.7521 - f1: 0.6918 - val_loss: 0.7079 - val_acc: 0.7043 - val_auroc: 0.7594 - val_f1: 0.7241\n",
      "Epoch 17/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7117 - acc: 0.6924 - auroc: 0.7517 - f1: 0.6921 - val_loss: 0.7060 - val_acc: 0.6994 - val_auroc: 0.7603 - val_f1: 0.7158\n",
      "Epoch 18/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7160 - acc: 0.6930 - auroc: 0.7528 - f1: 0.6941 - val_loss: 0.7004 - val_acc: 0.7045 - val_auroc: 0.7651 - val_f1: 0.7144\n",
      "Epoch 19/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7150 - acc: 0.6920 - auroc: 0.7534 - f1: 0.6924 - val_loss: 0.7049 - val_acc: 0.7018 - val_auroc: 0.7661 - val_f1: 0.7337\n",
      "Epoch 20/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7120 - acc: 0.6944 - auroc: 0.7549 - f1: 0.6958 - val_loss: 0.7085 - val_acc: 0.6932 - val_auroc: 0.7587 - val_f1: 0.7190\n",
      "Epoch 21/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7137 - acc: 0.6940 - auroc: 0.7529 - f1: 0.6949 - val_loss: 0.6967 - val_acc: 0.7043 - val_auroc: 0.7611 - val_f1: 0.7188\n",
      "Epoch 22/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7181 - acc: 0.6938 - auroc: 0.7527 - f1: 0.6948 - val_loss: 0.7098 - val_acc: 0.7026 - val_auroc: 0.7638 - val_f1: 0.7274\n",
      "Epoch 23/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7151 - acc: 0.6927 - auroc: 0.7526 - f1: 0.6941 - val_loss: 0.7203 - val_acc: 0.6925 - val_auroc: 0.7571 - val_f1: 0.7243\n",
      "Epoch 24/50\n",
      "132023/132023 [==============================] - 43s 325us/step - loss: 0.7184 - acc: 0.6922 - auroc: 0.7512 - f1: 0.6928 - val_loss: 0.7048 - val_acc: 0.7056 - val_auroc: 0.7591 - val_f1: 0.7229\n",
      "Epoch 25/50\n",
      "132023/132023 [==============================] - 43s 325us/step - loss: 0.7126 - acc: 0.6947 - auroc: 0.7537 - f1: 0.6966 - val_loss: 0.7131 - val_acc: 0.7016 - val_auroc: 0.7603 - val_f1: 0.7203\n",
      "Epoch 26/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7158 - acc: 0.6945 - auroc: 0.7540 - f1: 0.6971 - val_loss: 0.7062 - val_acc: 0.7056 - val_auroc: 0.7663 - val_f1: 0.7335\n",
      "Epoch 27/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7164 - acc: 0.6963 - auroc: 0.7561 - f1: 0.6991 - val_loss: 0.7399 - val_acc: 0.6680 - val_auroc: 0.7527 - val_f1: 0.7186\n",
      "Epoch 28/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7159 - acc: 0.6938 - auroc: 0.7526 - f1: 0.6951 - val_loss: 0.7230 - val_acc: 0.6773 - val_auroc: 0.7581 - val_f1: 0.7257\n",
      "Epoch 29/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7131 - acc: 0.6933 - auroc: 0.7540 - f1: 0.6951 - val_loss: 0.7369 - val_acc: 0.6869 - val_auroc: 0.7558 - val_f1: 0.7216\n",
      "Validation Loss:\n",
      "[0.7089087691106503, 0.7035164259533119, 0.7098849653116853, 0.7092862599661066, 0.7152752500588409, 0.7218016671966991, 0.7025957824595664, 0.705483658587293, 0.7055504856823785, 0.708112122152097, 0.7203034082352323, 0.7085122281491322, 0.6978533264155345, 0.7160245209467079, 0.7127520018409257, 0.7078991870433489, 0.706002762886683, 0.7004120856700268, 0.7049443134013939, 0.7084668380479984, 0.6966541145661994, 0.709849647924175, 0.7203461812052699, 0.7048118811328521, 0.7130678466829317, 0.7062125463241594, 0.7398501122702411, 0.7229794042267612, 0.7369408052475859]\n",
      "Validation Accuracy:\n",
      "[0.6857318154092589, 0.692957938477276, 0.6992978389476558, 0.690571954380524, 0.6983434453284588, 0.6898902447744254, 0.7004567455340117, 0.703660781182462, 0.7040698070680204, 0.6958892903564263, 0.6888676800605295, 0.6959574613048464, 0.706251278246373, 0.6936396482296537, 0.6899584156740857, 0.70427431993766, 0.6994341808688755, 0.704478832904819, 0.7017519939440681, 0.6932306223440954, 0.7043424910079792, 0.7026382165904652, 0.692548912689237, 0.7056377394424154, 0.7016156519984685, 0.7056377394424154, 0.6680073625747717, 0.6773467856573664, 0.686890721971235]\n",
      "Validation F1:\n",
      "[0.6851302536282041, 0.7101080533965525, 0.7164549006990912, 0.7179580594150963, 0.7182274933680166, 0.7231210483892928, 0.7182534470767183, 0.7169588326237605, 0.7275928366614133, 0.7077512074625316, 0.7274026757361285, 0.7036149791351767, 0.7263556151873122, 0.7156466034846898, 0.7211526883583841, 0.7241096817827053, 0.7157904243849563, 0.7143925324857451, 0.7336739395584535, 0.7190440165841333, 0.718812044099663, 0.7274087928329495, 0.7242504471332816, 0.722936547483531, 0.7202791904767636, 0.7334786035692905, 0.7185662530326544, 0.725749037628062, 0.721581509666084]\n",
      "Validation AUROC:\n",
      "[0.6851302536282041, 0.7101080533965525, 0.7164549006990912, 0.7179580594150963, 0.7182274933680166, 0.7231210483892928, 0.7182534470767183, 0.7169588326237605, 0.7275928366614133, 0.7077512074625316, 0.7274026757361285, 0.7036149791351767, 0.7263556151873122, 0.7156466034846898, 0.7211526883583841, 0.7241096817827053, 0.7157904243849563, 0.7143925324857451, 0.7336739395584535, 0.7190440165841333, 0.718812044099663, 0.7274087928329495, 0.7242504471332816, 0.722936547483531, 0.7202791904767636, 0.7334786035692905, 0.7185662530326544, 0.725749037628062, 0.721581509666084]\n",
      "best: {'val_f1': 0.718812044099663, 'val_auroc': 0.7610934306845143, 'val_accuracy': 0.7043424910079792, 'val_loss': 0.6966541145661994}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 132023 samples, validate on 14669 samples\n",
      "Epoch 1/50\n",
      "132023/132023 [==============================] - 44s 334us/step - loss: 0.7599 - acc: 0.6622 - auroc: 0.7172 - f1: 0.6632 - val_loss: 0.6979 - val_acc: 0.6975 - val_auroc: 0.7594 - val_f1: 0.7188\n",
      "Epoch 2/50\n",
      "132023/132023 [==============================] - 43s 324us/step - loss: 0.7151 - acc: 0.6832 - auroc: 0.7401 - f1: 0.6830 - val_loss: 0.6988 - val_acc: 0.6893 - val_auroc: 0.7590 - val_f1: 0.7238\n",
      "Epoch 3/50\n",
      "132023/132023 [==============================] - 44s 330us/step - loss: 0.7106 - acc: 0.6852 - auroc: 0.7429 - f1: 0.6851 - val_loss: 0.6967 - val_acc: 0.6995 - val_auroc: 0.7600 - val_f1: 0.7179\n",
      "Epoch 4/50\n",
      "132023/132023 [==============================] - 43s 325us/step - loss: 0.7104 - acc: 0.6853 - auroc: 0.7437 - f1: 0.6842 - val_loss: 0.6891 - val_acc: 0.7018 - val_auroc: 0.7639 - val_f1: 0.7247\n",
      "Epoch 5/50\n",
      "132023/132023 [==============================] - 43s 325us/step - loss: 0.7082 - acc: 0.6861 - auroc: 0.7451 - f1: 0.6849 - val_loss: 0.6921 - val_acc: 0.6945 - val_auroc: 0.7590 - val_f1: 0.7172\n",
      "Epoch 6/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7075 - acc: 0.6887 - auroc: 0.7463 - f1: 0.6878 - val_loss: 0.6848 - val_acc: 0.7067 - val_auroc: 0.7649 - val_f1: 0.7227\n",
      "Epoch 7/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7033 - acc: 0.6891 - auroc: 0.7475 - f1: 0.6880 - val_loss: 0.7001 - val_acc: 0.6968 - val_auroc: 0.7618 - val_f1: 0.7271\n",
      "Epoch 8/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7091 - acc: 0.6910 - auroc: 0.7491 - f1: 0.6899 - val_loss: 0.7056 - val_acc: 0.6983 - val_auroc: 0.7679 - val_f1: 0.7307\n",
      "Epoch 9/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7074 - acc: 0.6890 - auroc: 0.7480 - f1: 0.6877 - val_loss: 0.7029 - val_acc: 0.7082 - val_auroc: 0.7639 - val_f1: 0.7183\n",
      "Epoch 10/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7113 - acc: 0.6889 - auroc: 0.7485 - f1: 0.6883 - val_loss: 0.6987 - val_acc: 0.7026 - val_auroc: 0.7607 - val_f1: 0.7220\n",
      "Epoch 11/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7073 - acc: 0.6903 - auroc: 0.7498 - f1: 0.6897 - val_loss: 0.7031 - val_acc: 0.7043 - val_auroc: 0.7688 - val_f1: 0.7330\n",
      "Epoch 12/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7061 - acc: 0.6935 - auroc: 0.7514 - f1: 0.6933 - val_loss: 0.7021 - val_acc: 0.7069 - val_auroc: 0.7646 - val_f1: 0.7289\n",
      "Epoch 13/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7086 - acc: 0.6918 - auroc: 0.7510 - f1: 0.6917 - val_loss: 0.6859 - val_acc: 0.7064 - val_auroc: 0.7693 - val_f1: 0.7201\n",
      "Epoch 14/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7083 - acc: 0.6900 - auroc: 0.7493 - f1: 0.6895 - val_loss: 0.6992 - val_acc: 0.7084 - val_auroc: 0.7686 - val_f1: 0.7386\n",
      "Validation Loss:\n",
      "[0.6978960544900974, 0.6987717320431602, 0.6966823123700698, 0.6890632490031241, 0.6920672347391381, 0.6847531079709616, 0.7001445295701966, 0.705560443989541, 0.7029024218519867, 0.6986770173045249, 0.7031325255242242, 0.7020623607701811, 0.6858611224992882, 0.6991622760557707]\n",
      "Validation Accuracy:\n",
      "[0.6974572227552012, 0.6893448770407868, 0.699502351890435, 0.7017519940903472, 0.6944576999032511, 0.7066603040831717, 0.6968436840000032, 0.6983434454991178, 0.708160065484767, 0.7025700457151849, 0.7043424910811187, 0.7068648170747106, 0.7063876201919727, 0.7083645785006857]\n",
      "Validation F1:\n",
      "[0.718826675014397, 0.7237503286787594, 0.7179343513415565, 0.7247041964085607, 0.7172371451657554, 0.7226795409669888, 0.7270839188848018, 0.7307492123603235, 0.718253591970169, 0.7220027749503802, 0.7329830258274072, 0.728862163885474, 0.7201304594320838, 0.7385817872282511]\n",
      "Validation AUROC:\n",
      "[0.718826675014397, 0.7237503286787594, 0.7179343513415565, 0.7247041964085607, 0.7172371451657554, 0.7226795409669888, 0.7270839188848018, 0.7307492123603235, 0.718253591970169, 0.7220027749503802, 0.7329830258274072, 0.728862163885474, 0.7201304594320838, 0.7385817872282511]\n",
      "best: {'val_f1': 0.7226795409669888, 'val_auroc': 0.7649041749196194, 'val_accuracy': 0.7066603040831717, 'val_loss': 0.6847531079709616}\n",
      "Train on 132023 samples, validate on 14669 samples\n",
      "Epoch 1/50\n",
      "132023/132023 [==============================] - 44s 336us/step - loss: 0.7582 - acc: 0.6584 - auroc: 0.7095 - f1: 0.6593 - val_loss: 0.7222 - val_acc: 0.6862 - val_auroc: 0.7501 - val_f1: 0.7061\n",
      "Epoch 2/50\n",
      "132023/132023 [==============================] - 44s 334us/step - loss: 0.7121 - acc: 0.6826 - auroc: 0.7392 - f1: 0.6795 - val_loss: 0.7020 - val_acc: 0.6827 - val_auroc: 0.7436 - val_f1: 0.6562\n",
      "Epoch 3/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7057 - acc: 0.6852 - auroc: 0.7418 - f1: 0.6841 - val_loss: 0.7061 - val_acc: 0.6842 - val_auroc: 0.7430 - val_f1: 0.6914\n",
      "Epoch 4/50\n",
      "132023/132023 [==============================] - 44s 331us/step - loss: 0.7070 - acc: 0.6867 - auroc: 0.7430 - f1: 0.6865 - val_loss: 0.7019 - val_acc: 0.6831 - val_auroc: 0.7421 - val_f1: 0.6905\n",
      "Epoch 5/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7055 - acc: 0.6865 - auroc: 0.7442 - f1: 0.6871 - val_loss: 0.6767 - val_acc: 0.7018 - val_auroc: 0.7607 - val_f1: 0.6989\n",
      "Epoch 6/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7033 - acc: 0.6891 - auroc: 0.7468 - f1: 0.6888 - val_loss: 0.7065 - val_acc: 0.6865 - val_auroc: 0.7484 - val_f1: 0.7089\n",
      "Epoch 7/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7036 - acc: 0.6886 - auroc: 0.7465 - f1: 0.6885 - val_loss: 0.6886 - val_acc: 0.6994 - val_auroc: 0.7651 - val_f1: 0.7185\n",
      "Epoch 8/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7064 - acc: 0.6911 - auroc: 0.7488 - f1: 0.6916 - val_loss: 0.7011 - val_acc: 0.6851 - val_auroc: 0.7552 - val_f1: 0.7092\n",
      "Epoch 9/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7075 - acc: 0.6899 - auroc: 0.7489 - f1: 0.6896 - val_loss: 0.7065 - val_acc: 0.6923 - val_auroc: 0.7611 - val_f1: 0.7202\n",
      "Epoch 10/50\n",
      "132023/132023 [==============================] - 44s 336us/step - loss: 0.7045 - acc: 0.6901 - auroc: 0.7499 - f1: 0.6891 - val_loss: 0.6992 - val_acc: 0.6969 - val_auroc: 0.7621 - val_f1: 0.7223\n",
      "Epoch 11/50\n",
      "132023/132023 [==============================] - 44s 335us/step - loss: 0.7070 - acc: 0.6908 - auroc: 0.7517 - f1: 0.6906 - val_loss: 0.7035 - val_acc: 0.7067 - val_auroc: 0.7645 - val_f1: 0.7207\n",
      "Epoch 12/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7051 - acc: 0.6913 - auroc: 0.7511 - f1: 0.6912 - val_loss: 0.6814 - val_acc: 0.7044 - val_auroc: 0.7629 - val_f1: 0.7112\n",
      "Epoch 13/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7043 - acc: 0.6910 - auroc: 0.7508 - f1: 0.6918 - val_loss: 0.6957 - val_acc: 0.7035 - val_auroc: 0.7654 - val_f1: 0.7227\n",
      "Validation Loss:\n",
      "[0.7221901363021018, 0.7020349610281735, 0.7060680688991894, 0.7018676804768071, 0.6767350786164118, 0.7065172477915647, 0.6886110126960009, 0.7011085939972961, 0.7065479093407697, 0.6992348858537959, 0.7035420844627878, 0.6813560030895781, 0.6957098486534177]\n",
      "Validation Accuracy:\n",
      "[0.6862090121700977, 0.682732292532929, 0.6841638830348639, 0.6831413183941075, 0.7018201649900074, 0.6865498669853369, 0.699434180942015, 0.6851182765321616, 0.6922762287248985, 0.6969118548996635, 0.7067284750072118, 0.7044106619320193, 0.703456268361582]\n",
      "Validation F1:\n",
      "[0.7060878957469443, 0.6561827789632745, 0.691368765313816, 0.6905012273846963, 0.6988804128664274, 0.7088992617492564, 0.7184549416978225, 0.7092088408139888, 0.7202388869081833, 0.7222508052487796, 0.7206545963155052, 0.7112347295503852, 0.7226706416103541]\n",
      "Validation AUROC:\n",
      "[0.7060878957469443, 0.6561827789632745, 0.691368765313816, 0.6905012273846963, 0.6988804128664274, 0.7088992617492564, 0.7184549416978225, 0.7092088408139888, 0.7202388869081833, 0.7222508052487796, 0.7206545963155052, 0.7112347295503852, 0.7226706416103541]\n",
      "best: {'val_f1': 0.6988804128664274, 'val_auroc': 0.7606790216029338, 'val_accuracy': 0.7018201649900074, 'val_loss': 0.6767350786164118}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 132023 samples, validate on 14669 samples\n",
      "Epoch 1/50\n",
      "132023/132023 [==============================] - 45s 343us/step - loss: 0.7615 - acc: 0.6625 - auroc: 0.7160 - f1: 0.6600 - val_loss: 0.7017 - val_acc: 0.6906 - val_auroc: 0.7503 - val_f1: 0.7088\n",
      "Epoch 2/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7111 - acc: 0.6848 - auroc: 0.7420 - f1: 0.6855 - val_loss: 0.6890 - val_acc: 0.6943 - val_auroc: 0.7549 - val_f1: 0.7066\n",
      "Epoch 3/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7075 - acc: 0.6858 - auroc: 0.7427 - f1: 0.6877 - val_loss: 0.6980 - val_acc: 0.6846 - val_auroc: 0.7402 - val_f1: 0.6920\n",
      "Epoch 4/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7041 - acc: 0.6838 - auroc: 0.7421 - f1: 0.6857 - val_loss: 0.6914 - val_acc: 0.6925 - val_auroc: 0.7497 - val_f1: 0.6985\n",
      "Epoch 5/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7048 - acc: 0.6862 - auroc: 0.7440 - f1: 0.6887 - val_loss: 0.7033 - val_acc: 0.6913 - val_auroc: 0.7447 - val_f1: 0.7056\n",
      "Epoch 6/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7040 - acc: 0.6878 - auroc: 0.7448 - f1: 0.6889 - val_loss: 0.6918 - val_acc: 0.6952 - val_auroc: 0.7545 - val_f1: 0.7163\n",
      "Epoch 7/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7037 - acc: 0.6870 - auroc: 0.7451 - f1: 0.6879 - val_loss: 0.6889 - val_acc: 0.6968 - val_auroc: 0.7581 - val_f1: 0.7137\n",
      "Epoch 8/50\n",
      "132023/132023 [==============================] - 44s 334us/step - loss: 0.7023 - acc: 0.6878 - auroc: 0.7458 - f1: 0.6886 - val_loss: 0.6948 - val_acc: 0.6890 - val_auroc: 0.7439 - val_f1: 0.6951\n",
      "Epoch 9/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7000 - acc: 0.6894 - auroc: 0.7470 - f1: 0.6903 - val_loss: 0.6964 - val_acc: 0.6945 - val_auroc: 0.7551 - val_f1: 0.7175\n",
      "Epoch 10/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7020 - acc: 0.6898 - auroc: 0.7482 - f1: 0.6915 - val_loss: 0.6954 - val_acc: 0.6977 - val_auroc: 0.7603 - val_f1: 0.7206\n",
      "Epoch 11/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7026 - acc: 0.6896 - auroc: 0.7486 - f1: 0.6908 - val_loss: 0.6935 - val_acc: 0.6968 - val_auroc: 0.7565 - val_f1: 0.7153\n",
      "Epoch 12/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7020 - acc: 0.6922 - auroc: 0.7499 - f1: 0.6948 - val_loss: 0.7037 - val_acc: 0.6960 - val_auroc: 0.7576 - val_f1: 0.7235\n",
      "Epoch 13/50\n",
      "132023/132023 [==============================] - 44s 331us/step - loss: 0.7058 - acc: 0.6892 - auroc: 0.7487 - f1: 0.6898 - val_loss: 0.6924 - val_acc: 0.6982 - val_auroc: 0.7626 - val_f1: 0.7208\n",
      "Epoch 14/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7012 - acc: 0.6908 - auroc: 0.7510 - f1: 0.6926 - val_loss: 0.6948 - val_acc: 0.6990 - val_auroc: 0.7545 - val_f1: 0.7143\n",
      "Epoch 15/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7039 - acc: 0.6924 - auroc: 0.7515 - f1: 0.6932 - val_loss: 0.6911 - val_acc: 0.7026 - val_auroc: 0.7605 - val_f1: 0.7137\n",
      "Validation Loss:\n",
      "[0.7017323866245798, 0.6890312802963067, 0.6979904952684106, 0.6913580911251671, 0.7032692936253585, 0.6917840632097602, 0.6889497483911929, 0.6948410850644267, 0.6964117575337025, 0.6954081687542695, 0.6934675382961565, 0.7036669088073105, 0.6924071016223228, 0.6948491920397012, 0.6911396613369057]\n",
      "Validation Accuracy:\n",
      "[0.6905719545024233, 0.6943213579820314, 0.6846410797957027, 0.6924807417164373, 0.6912536642060412, 0.6952075806771882, 0.6967755130759631, 0.6890040221036484, 0.6945258709735702, 0.6976617356979804, 0.696843684024383, 0.6960256323751655, 0.6982071035535181, 0.6990251551052163, 0.7026382167611241]\n",
      "Validation F1:\n",
      "[0.7088212068562485, 0.7065567674385891, 0.6919724613182285, 0.6985481070898429, 0.7055965413815796, 0.7162644336320959, 0.7137401629602733, 0.6951390323938625, 0.7175414779693512, 0.7205846370611465, 0.715264605873648, 0.723508856569431, 0.7208279889251924, 0.7143298474847926, 0.7136715799031695]\n",
      "Validation AUROC:\n",
      "[0.7088212068562485, 0.7065567674385891, 0.6919724613182285, 0.6985481070898429, 0.7055965413815796, 0.7162644336320959, 0.7137401629602733, 0.6951390323938625, 0.7175414779693512, 0.7205846370611465, 0.715264605873648, 0.723508856569431, 0.7208279889251924, 0.7143298474847926, 0.7136715799031695]\n",
      "best: {'val_f1': 0.7137401629602733, 'val_auroc': 0.7580518727327646, 'val_accuracy': 0.6967755130759631, 'val_loss': 0.6889497483911929}\n",
      "Train on 132023 samples, validate on 14669 samples\n",
      "Epoch 1/50\n",
      "132023/132023 [==============================] - 45s 339us/step - loss: 0.7685 - acc: 0.6638 - auroc: 0.7179 - f1: 0.6624 - val_loss: 0.7138 - val_acc: 0.6948 - val_auroc: 0.7531 - val_f1: 0.6920\n",
      "Epoch 2/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7161 - acc: 0.6845 - auroc: 0.7419 - f1: 0.6836 - val_loss: 0.6974 - val_acc: 0.6976 - val_auroc: 0.7569 - val_f1: 0.7090\n",
      "Epoch 3/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7140 - acc: 0.6858 - auroc: 0.7440 - f1: 0.6849 - val_loss: 0.7034 - val_acc: 0.7014 - val_auroc: 0.7584 - val_f1: 0.7069\n",
      "Epoch 4/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7156 - acc: 0.6871 - auroc: 0.7450 - f1: 0.6856 - val_loss: 0.7033 - val_acc: 0.6998 - val_auroc: 0.7575 - val_f1: 0.7109\n",
      "Epoch 5/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7143 - acc: 0.6883 - auroc: 0.7469 - f1: 0.6879 - val_loss: 0.6913 - val_acc: 0.7095 - val_auroc: 0.7699 - val_f1: 0.7267\n",
      "Epoch 6/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7152 - acc: 0.6899 - auroc: 0.7483 - f1: 0.6895 - val_loss: 0.6913 - val_acc: 0.7111 - val_auroc: 0.7715 - val_f1: 0.7288\n",
      "Epoch 7/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7146 - acc: 0.6893 - auroc: 0.7473 - f1: 0.6876 - val_loss: 0.7034 - val_acc: 0.7058 - val_auroc: 0.7627 - val_f1: 0.7235\n",
      "Epoch 8/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7153 - acc: 0.6918 - auroc: 0.7511 - f1: 0.6907 - val_loss: 0.7081 - val_acc: 0.7067 - val_auroc: 0.7615 - val_f1: 0.7153\n",
      "Epoch 9/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7132 - acc: 0.6916 - auroc: 0.7504 - f1: 0.6913 - val_loss: 0.6964 - val_acc: 0.7103 - val_auroc: 0.7668 - val_f1: 0.7270\n",
      "Epoch 10/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7095 - acc: 0.6913 - auroc: 0.7499 - f1: 0.6901 - val_loss: 0.6852 - val_acc: 0.7129 - val_auroc: 0.7710 - val_f1: 0.7314\n",
      "Epoch 11/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7114 - acc: 0.6933 - auroc: 0.7522 - f1: 0.6939 - val_loss: 0.6947 - val_acc: 0.7108 - val_auroc: 0.7709 - val_f1: 0.7269\n",
      "Epoch 12/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7137 - acc: 0.6917 - auroc: 0.7518 - f1: 0.6922 - val_loss: 0.6897 - val_acc: 0.7131 - val_auroc: 0.7715 - val_f1: 0.7324\n",
      "Epoch 13/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7109 - acc: 0.6920 - auroc: 0.7516 - f1: 0.6925 - val_loss: 0.6990 - val_acc: 0.7124 - val_auroc: 0.7724 - val_f1: 0.7292\n",
      "Epoch 14/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7096 - acc: 0.6909 - auroc: 0.7512 - f1: 0.6919 - val_loss: 0.6946 - val_acc: 0.7133 - val_auroc: 0.7727 - val_f1: 0.7323\n",
      "Epoch 15/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7090 - acc: 0.6903 - auroc: 0.7505 - f1: 0.6913 - val_loss: 0.6964 - val_acc: 0.7102 - val_auroc: 0.7663 - val_f1: 0.7341\n",
      "Epoch 16/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7090 - acc: 0.6916 - auroc: 0.7516 - f1: 0.6923 - val_loss: 0.6943 - val_acc: 0.7122 - val_auroc: 0.7723 - val_f1: 0.7333\n",
      "Epoch 17/50\n",
      "  1792/132023 [..............................] - ETA: 39s - loss: 0.7167 - acc: 0.6908 - auroc: 0.7483 - f1: 0.6808"
     ]
    }
   ],
   "source": [
    "bests = []\n",
    "for cross in range(10):\n",
    "    ffnn_wv_scores = run_single_cross_validate(evaluate_ffnn_model, [train_input_features, train_reviewer],\n",
    "                                               train_labels, cross, splitter)\n",
    "    \n",
    "    print(\"Validation Loss:\")\n",
    "    val_loss = ffnn_wv_scores.history['val_loss']\n",
    "    print(val_loss)\n",
    "    print(\"Validation Accuracy:\")\n",
    "    val_accuracy = ffnn_wv_scores.history['val_acc']\n",
    "    print(val_accuracy)\n",
    "    print(\"Validation F1:\")\n",
    "    val_f1 = ffnn_wv_scores.history['val_f1']\n",
    "    print(val_f1)\n",
    "    print(\"Validation AUROC:\")\n",
    "    val_auroc = ffnn_wv_scores.history['val_auroc']\n",
    "    print(val_f1)\n",
    "\n",
    "    min_val_loss = 1\n",
    "    best = None\n",
    "    for loss, accuracy, f1_score, auroc_score in zip(val_loss, val_accuracy, val_f1, val_auroc):\n",
    "        if loss < min_val_loss:\n",
    "            min_val_loss = loss\n",
    "            best = { 'val_loss': loss, 'val_accuracy': accuracy, 'val_f1': f1_score, 'val_auroc': auroc_score }\n",
    "    print(\"best:\", best)\n",
    "    bests.append(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "{'val_f1': 0.7240855165659288, 'val_auroc': 0.7716540556686994, 'val_accuracy': 0.714607048043606, 'val_loss': 0.6732355435196343}\n",
      "==============================================================\n",
      "{'val_f1': 0.718812044099663, 'val_auroc': 0.7610934306845143, 'val_accuracy': 0.7043424910079792, 'val_loss': 0.6966541145661994}\n",
      "==============================================================\n",
      "{'val_f1': 0.7226795409669888, 'val_auroc': 0.7649041749196194, 'val_accuracy': 0.7066603040831717, 'val_loss': 0.6847531079709616}\n",
      "==============================================================\n",
      "{'val_f1': 0.6988804128664274, 'val_auroc': 0.7606790216029338, 'val_accuracy': 0.7018201649900074, 'val_loss': 0.6767350786164118}\n",
      "==============================================================\n",
      "{'val_f1': 0.7137401629602733, 'val_auroc': 0.7580518727327646, 'val_accuracy': 0.6967755130759631, 'val_loss': 0.6889497483911929}\n",
      "==============================================================\n",
      "{'val_f1': 0.731433466380583, 'val_auroc': 0.7709812828045498, 'val_accuracy': 0.7128638626323317, 'val_loss': 0.6851975975027519}\n",
      "==============================================================\n",
      "{'val_f1': 0.715971848034844, 'val_auroc': 0.7588348850443973, 'val_accuracy': 0.695343922452129, 'val_loss': 0.684315042490364}\n",
      "==============================================================\n",
      "{'val_f1': 0.7249707128382532, 'val_auroc': 0.764970304355763, 'val_accuracy': 0.7054332265971556, 'val_loss': 0.6937418827673142}\n",
      "==============================================================\n",
      "{'val_f1': 0.7072323118261264, 'val_auroc': 0.7576979800599316, 'val_accuracy': 0.6996386938604143, 'val_loss': 0.6874851513407909}\n",
      "==============================================================\n",
      "{'val_f1': 0.7132548566683401, 'val_auroc': 0.7676437449418216, 'val_accuracy': 0.7063194492923124, 'val_loss': 0.6747895663635758}\n",
      "==============================================================\n",
      "Average accuracy: 0.704380467603507\n"
     ]
    }
   ],
   "source": [
    "print(\"==============================================================\")\n",
    "for best in bests:\n",
    "  print(best)\n",
    "  print(\"==============================================================\")\n",
    "print(\"Average accuracy:\", statistics.mean([x['val_accuracy'] for x in bests]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our FFNN has not immediately shown improvements over the earlier statistical experiments. It is possible to perform more precise hypertuning, although at this stage it is unlikely we will see a dramatic increase in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results look good for a benchmark, with just a little variance seen in this data. The following graph shows the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feed-Forward Neural Network Accuracies')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEICAYAAACUOKXLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFjRJREFUeJzt3XmYXFWZx/HvSzpA2CEBxMgQMTAIozCKqCgjuAwMLjCOIogsjhERjbjvo8jACDqyGNxQERhlFJmREUQFlSAgEYmCoiA0EQgRkC0QBEXwzB/nFLlddHV1ujtVfcj38zz15NZd3zr31u/ee24liZQSkqQ6rNbvAiRJo2doS1JFDG1JqoihLUkVMbQlqSKGtiRVxNCeYBExKyJSRAz0u5aJFBHzI2JOv+sYjcfTPqip3ccrIu6PiC37Xcdkt0qFdkTcGBEPloOj9Xpij2s4OCIeaavhpF7WMNEi4ogSkvs0xg2UcbP6V9nwynHwh4hYuzFuTkTMH+Xyp0bEUSutwHEqQX9PRKzR71pWREppnZTSon7XMdmtUqFdvLwcHK3X7/tQw2VtNbx1RVewsq4ix7Heu4GPRcSUiaxnOBO0jSnA4ROwnpUishX+fpaT5C5AAl4xwWV123b1dzY1WBVDe1gR8ZyI+ElELI2IqyJi18a09SPiyxFxa0QsiYijWsEREVMi4j8j4s6IWAS8dBw1rB8Rp0fEHRFxU0R8uPXFLVfol0bE8RFxF3BEmeeZZfr+5cp2u/L+DRFxdhneKSIuK5/t1og4KSJWb2w3RcRbIuJ64Poy7iURcW1E3FvuBKJL+d8DHgJe1+GzrVHa6eaIuD0iPh8R0xqf7ZK2+VNEzC7Dp0bE5yLivIj4I7BbRLw0In4REfdFxOKIOGLFWptPAu+OiA061LtNRFwQEXdHxG9bdxERcQiwP/Decpd0TkS8PiLOaSx7fUR8s/F+cUTsUIZ3joiflXb9WUTs3JhvfkQcHRGXAg8AQ7oKImKziPhlRLxnhM91ILAAOBU4qG35aRHxqXLc3BsRlzT2wfMbx//iiDi4UdOcxjqG7KsOx86JZR33RcTCiNilMf+UiPhgRNwQEcvK9M0b62rt85GOlxkRcW6p9e6IuDjGcIKrVkpplXkBNwIvHmb8TOAuYE/yiewl5f3GZfq3gC8AawObAJcDbyrTDgWuBTYHNgIuJF/lDHSo4WDgkg7TTgf+D1gXmAVcB7yhsdzDwFxgAJhW5n9XmX4ycAPw5sa63lGGnwk8pyw3C7gGeHtjuwm4oNQ/DZgBLANeBUwF3lG2PadD3UcAXyVf2S0qywyU9c4q8xwPfLtsY13gHODjndqkLDu7DJ8K3As8r+yfNYFdgaeV908Hbgf2LvPP6rIPbgReDPwvcFQZNweYX4bXBhYDry+f4++BO4FtG/Uc1VjflsDSUssTgZuAWxrT7inTNirDB5T17lfeTy/zzgduBrYr06eWcXOAJ5OPh0O6HOODwGFln/8F2LQx7TNlfTPJdxo7A2sAW5T9vV/Z5nRgh0ZNcxrrGLKvaDt2yrjXlXUMAO8CbgPWLNPeA/wK+FvyhcD2jc/f3OcjHS8fBz5fap1KvrOIfudLz3Ks3wX09MPmL+v95Qu2FDi7jH8f8F9t836ffKWyKfDn1gFZpu0HXFiGfwQc2pj2j3QP7YcbNSwlB+oU8pXqto1538TyIDkYuLltXW8Avl2Grylf7q+X9zcBz+hQw9uBbzXeJ+CFjfcHAgsa7wO4hS6hXYZ/CryZRmiX5f8IPKWxzHOB3zU+W7fQPr3Lvj0BOL4Mz+qyD24kh/bfkU8GGzM0tF8DXNy2zBeAjzbqOapt+mLgGcC+5BPo5cA25OBv7aMDgMvblrsMOLgMzweObJs+Hziu1LxflzZ4PjmoZ5T317L8xL0a8CCw/TDLfaB5PAyz/W6h/cIudd3T2i7wW2CvDvMlYPYojpcjyRc3s1fk+/94ea06txTL7Z1S2qC89i7jtgBeXW63lkbEUvIXYLMybSpwa2PaF8hX3JCvrBY31n9TayAidonlDxt/3ZhnQaOGDVJKC8hXt1Oby5fhmY33ze0AXATsEhGbkUP/TOB5kfs11weuLHVsXW4nb4uI+4D/KNtraq57yGdK+ZvSvu1OPgx8iHw13LIxsBawsNGG3yvjR2vI9iPi2RFxYeSupHvJdzztn2lEKaWrgXOB97dN2gJ4dtvxsD/whBFWdxH56v8fyvB84AXldVGZp3UV3tRtH1O2vQQ4a+RPxEHA+SmlO8v7M1jeRTKDvE9uGGa5zTuMH632ffPuiLimdMEsJR+LrX0zmm11O14+Sb6jOD8iFkVE+/57XFsVQ3s4i8lX2s0gXTuldEyZ9mfy1Utr2noppe3KsreSD8SWv2kNpJQuTssfNm7HyO4kXyVt0bauJY33Q/5JxpTSILnvcy7w45TSfeRb0UPIV0N/LbN+jnzVtVVKaT3ggzy2j7q57iGfKSKi7TN2lFK6gOW36M3P9iCwXaMN108prVOm/5H8JW1tb7hwbP/nKM8g3z5vnlJan3y73K3ffTgfBd7IY4PzorbjYZ2U0ps71ALLQ3uXMnwRjw3t3zN0/0KXfVwcQW7DM6LDQ9jS37sP8IJycr6N3K21fURsX5b/E/CUYRZf3GE8tO0bhj9xPVpz6b9+b6llw5TSBuS7mda+GWlbLSMeLymlZSmld6WUtiR3yb0zIl7UZZ2PG4Z29lXg5RGxe3lQsmZE7BoRT0op3QqcD3wqItaLiNUi4ikR8YKy7JnA2yLiSRGxIY+9ahuVlNIjZV1HR8S6EbEF8M5S20guAt7K8mCY3/Yecp/gfcD9EbENuftiJN8BtouIV0b+RcDbGPkqs92HyF9cAMrJ44vA8RGxCUBEzIyI3cssV5Xt7RARa5JDqpt1gbtTSn+KiJ2A165AfY8qJ75vkD9jy7nA1hFxQERMLa9nRcRTy/TbaXtISG7v3cjdaLcAFwN7kPt2f1HmOa+s97WRfxL5GmDbsr2R/AV4Nbmv/fQOD932Bh4p69uhvJ5a6jiw7INTgOMi4onlOH9u5J8Ffg14cUTsU+qaHuXBKflu7ZURsVZ5SPiGLrWuS+7+uwMYiIiPAOs1pn8J+PeI2Cqyp0fE9OYKuh0vEfGyiJhdLibuLZ/7r6wiDG0gpbQY2It8BXoH+WrgPSxvnwOB1YHfkPvnziJ3nUA+uL5PDp6fkx9ujdVc8pXNIuAS8tXkKV2WuYj8Rflxh/cA7yaH2rJS7zdGWmG5vX41cAz5gexWwKWj/RAppUvJfbpN7yNfgS8oXTQ/ID+MIqV0Hbmf8gfkXyBcQneHAUdGxDLgI+QT3lgdSQ7EVv3LyM8m9iVfHd8GHEt+aAfwZWDbcut+duMz3E8OScpdzyLg0nJCJqV0F/Ay8sO5u8gntpc1ujM6Sik9BLyS/IzllGGC+yDgKymlm1NKt7VewEnA/uXk+27yQ8CfkX+ieSywWkrpZvJD+HeV8VeSHxBCfiD4EPlEdRo54EfyfXJXxnXkrp8/MbT75DjyvjqffCHxZfLD73Ydjxfy8fgDcntfBnw2pXRhl7oeNyJ3V0qSauCVtiRVxNCWpIoY2pJUEUNbkioyrn/gZcaMGWnWrFkTVIokrRoWLlx4Z0ppRf5y2aPGFdqzZs3iiiuuGM8qJGmVExHtfzN21OwekaSKGNqSVBFDW5IqYmhLUkUMbUmqiKEtSRUxtCWpIoa2JFXE0JakihjaklQRQ1uSKmJoS1JFDG1JqoihLUkVMbQlqSKGtiRVxNCWpIoY2pJUEUNbkioyrv8jUr0zb948BgcH+13GpLdkyRIAZs6c2ZPtzZ49m7lz5/ZkWxIY2tUYHBzkyquv4ZG1Nup3KZPalAfuBeC2P6/8Q3vKA3ev9G1I7Qztijyy1kY8uM2e/S5jUpt27XkAPWmn1rakXrJPW5IqYmhLUkUMbUmqiKEtSRUxtCWpIoa2JFXE0JakihjaklQRQ1uSKmJoS1JFDG1JqoihLUkVMbQlqSKGtiRVxNCWpIoY2pJUEUNbkipiaEtSRQxtSaqIoS1JFTG0JakihrYkVcTQlqSKGNqSVBFDW5IqYmhLUkUMbUmqiKEtSRUxtCWpIoa2JFXE0JakihjaklQRQ1uSKmJoS1JFDG1JqoihLUkVMbQlqSKGtiRVxNCWpIoY2pJUEUNbkirSl9CeN28e8+bN68emJWlc+p1fA/3Y6ODgYD82K0nj1u/8sntEkipiaEtSRQxtSaqIoS1JFTG0JakihrYkVcTQlqSKGNqSVBFDW5IqYmhLUkUMbUmqiKEtSRUxtCWpIoa2JFXE0JakihjaklQRQ1uSKmJoS1JFDG1JqoihLUkVMbQlqSKGtiRVxNCWpIoY2pJUEUNbkipiaEtSRQxtSaqIoS1JFTG0JakihrYkVcTQlqSKGNqSVBFDW5IqYmhLUkUMbUmqiKEtSRUxtCWpIoa2JFXE0JakihjaklQRQ1uSKjLQj40uWbKEBx98kMMPP7wfm6/S4OAgqz2U+l2GGlb7030MDi7zOF7FDA4OMm3atL5tf4WvtCPikIi4IiKuuOOOO1ZGTZKkDlb4SjuldDJwMsCOO+44pku/mTNnAnDiiSeOZfFV0uGHH87CRbf3uww1/HXN9Zi95aYex6uYft9Z2actSRUxtCWpIoa2JFXE0JakihjaklQRQ1uSKmJoS1JFDG1JqoihLUkVMbQlqSKGtiRVxNCWpIoY2pJUEUNbkipiaEtSRQxtSaqIoS1JFTG0JakihrYkVcTQlqSKGNqSVBFDW5IqYmhLUkUMbUmqiKEtSRUxtCWpIoa2JFXE0JakihjaklQRQ1uSKmJoS1JFDG1JqoihLUkVMbQlqSKGtiRVxNCWpIoY2pJUEUNbkipiaEtSRQxtSaqIoS1JFTG0JakiA/3Y6OzZs/uxWUkat37nV19Ce+7cuf3YrCSNW7/zy+4RSaqIoS1JFTG0JakihrYkVcTQlqSKGNqSVBFDW5IqYmhLUkUMbUmqiKEtSRUxtCWpIoa2JFXE0JakihjaklQRQ1uSKmJoS1JFDG1JqoihLUkVMbQlqSKGtiRVxNCWpIoY2pJUEUNbkipiaEtSRQxtSaqIoS1JFTG0JakihrYkVcTQlqSKGNqSVBFDW5IqYmhLUkUMbUmqiKEtSRUxtCWpIoa2JFXE0JakihjaklQRQ1uSKmJoS1JFBvpdgEZvygN3M+3a8/pdxqQ25YG7AHrSTlMeuBvYdKVvR2oytCsxe/bsfpdQhSVLHgZg5sxehOmm7hf1nKFdiblz5/a7BEmTgH3aklQRQ1uSKmJoS1JFDG1JqoihLUkVMbQlqSKGtiRVxNCWpIoY2pJUEUNbkipiaEtSRQxtSaqIoS1JFTG0JakihrYkVcTQlqSKGNqSVBFDW5IqYmhLUkUMbUmqSKSUxr5wxB3ATaOYdQZw55g3tHJN5tpgctc3mWuDyV3fZK4NJnd9k7k2GF19W6SUNh7LyscV2qPeSMQVKaUdV/qGxmAy1waTu77JXBtM7vomc20wueubzLXByq/P7hFJqoihLUkV6VVon9yj7YzFZK4NJnd9k7k2mNz1TebaYHLXN5lrg5VcX0/6tCVJE8PuEUmqiKEtSTVJKXV9AXsAvwUGgfd3mGcf4DfAr4EzGuOPBa4ur9c0xp8K/A64srx2KOMD+HTZ1i+BZ/Shtosbdf0eOLuM3xW4tzHtI+NtO+D4xvquA5Y2ph0EXF9eBzXGPxP4VVnnp1nezbURcEGZ/wJgw17WBqwFfAe4trT1MY35DwbuaKxvTp/abn5ZZ2u5Tcr4NYBvlG39FJjV47ZbtzH/leTf+Z7Qp7b7HrAUOLdtmSeXthksbbV6H9quU21fK+u8GjgFmNqn72yn+k5lAvIupdQ9tIEpwA3AlsDqwFXAtm3zbAX8ghISLP8ivJQcHgPA2sDPgPUaH+JVw2xvT+C75cM8B/hpr2trW/5/gAMbB8C5neoZS31t888FTinDGwGLyp8bluHWZ7i8tE2UtvqnMv4TrYMMeD9wbC9rI4f2bmWe1cknv1ZtBwMnTYK2mw/sOMzyhwGfL8P7At/odW1tyywE/qHXbVfevwh4efuxDpwJ7FuGPw+8uZdt16W2PcnfhwD+u1Hbru3z9qntTmWcedd6jaZ7ZCdgMKW0KKX0EPB1YK+2ed4IfCaldA9ASukPZfy2wI9TSg+nlP5IPpPs0WV7ewGnp2wBsEFEbNaP2iJiPeCFwNldau5kNPU17Uc+4AB2By5IKd1dar8A2KO0xXoppQUp7/XTgb3LMnsBp5Xh0xrje1JbSumBlNKFAGWdPweeNMI6RzLh9XXZXrPtzgJeFBHRj9oiYmtgE/JJbyzGUx8ppR8Cy9pqCvJ34awyqnl89arthq2tjD+vZEYiX9T047jrWN8IViTvgNH1ac8EFjfe31LGNW0NbB0Rl0bEgohoHYRXkYNmrYiYAewGbN5Y7uiI+GVEHB8Ra6zA9npRG+SD8ocppfsa454bEVdFxHcjYrsOda1IfQBExBbk288fdVl2Zhkebp2bppRuLcO3AZv2uLbmMhuQrzh+2Bj9L2V/nxUR7W3dy/q+EhFXRsS/NcLl0WVSSg+Tb6mn96E2WH612vxpV6/arpPp5G6Ah4dZZ6/arquImAocQO6maOnVd7ab8eYdMHEPIgfI3RC7ks88X4yIDVJK5wPnAT8hn40uAx4py3wA2AZ4FvlW8X0TVMtE1NYy5CxKvnLcIqW0PTCPsV+BD2df4KyUUnsNY1K+8BP1e84Vqi0iBsjt9umU0qIy+hxyX+fTyVeXp3VafiXXt39K6WnALuV1wATWMZyx7Nd9GXrcTZa267Wx1PZZ8h106y5lsnxnJyzvRhPaSxh6BfqkMq7pFuDbKaW/pJR+R+6c3wogpXR0SmmHlNJLyP0215Xxt5Zbgj8DXyHflox2eyu1NoBy9b0T+cEaZf77Ukr3l+HzgKllvk5W5LO0f1E7LbuEobd+zXXe3rq1Kn/+gc5WRm0tJwPXp5ROaI1IKd1V9jXAl8gPU0eyUupLKbX+XAacwTDHXTnprA/c1cvayra3BwZSSgtb43rcdp3cRb51Hxhmnb1quxFFxEeBjYF3tsb1+Dvb0QTl3aMr69YxP0B+WPJklnfMb9c2zx7AaWV4Bvlyfzq5U396Gf908pPdgfJ+s/JnACdQfmlAfkDY7Ji/vNe1lXGHtpZrjHsCy3+psRNwc+v9WOsr820D3NhcF/ls/Dvyw6oNy/BGZVr7g8g9y/hPMvRB5Cf6UNtR5Ie3q7WtZ7PG8D8DC8Z73K1ofWWdM8o8U8n9r4eW929h6MO0M3vddmX6McDH+tV2jWm78tiHad9k6IPIw3rZdl1qm0O+a57Wr+9sl/rGnXePrqvbDGXFe5KvQm8APlTGHQm8olHIceSf1f2qsWPXLON+Ayyg/MylTPtRmfdq4KvAOo11faZs61cM86R/ZddWps8nP1xrjnsr+adsV5Vldh5v25X3R9D4eVxj/L+Sfwo0CLy+MX7H0m43ACc1Dsrp5D7k64Ef0AiDXtRGvkpIwDW0/TwN+Hij7S4Etul125F/JbSQ/ND518CJwJTG8fDNMv/lwJa93q9l2qL2tulD211M/onhg+Q71d3L+C1L2wyWtlqjD23XqbaHy/qG/LSP3n9nO9U3IXmXUvKvsUtSTfwbkZJUEUNbkipiaEtSRQxtSaqIoS1JFTG0JakihrYkVeT/AbmoeUZAOeNZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from seaborn import boxplot\n",
    "from pandas import DataFrame\n",
    "boxplot(DataFrame([x['val_accuracy'] for x in bests])).set_title(\"Feed-Forward Neural Network Accuracies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feed-Forward Neural Network AUC scores')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(DataFrame([x['val_auroc'] for x in bests])).set_title(\"Feed-Forward Neural Network AUC scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feed-Forward Neural Network F1 scores')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAEICAYAAABoLY4BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEz1JREFUeJzt3Xm0XWV5x/HvQ8IQgQARRLjQBIw2hcKigohYWhwoiAMs6wAiAooI1ojWsdVWZGHVTpHGVqBLpchCRValilTFIRGRyKCAIggXBEIIGMBAkAgIb//Y7212Tu6Q4Z5znpv7/ax1VvbZ47Pfs8/vvPvdJEQpBUlS/23S7wIkSQ0DWZKSMJAlKQkDWZKSMJAlKQkDWZKSMJDHWUTMiogSEVP7Xct4iogFEXFiv+tYGxvTZzCR2l0bblIFckTcERErI+KR1mvnHtdwfEQ82VHDp3tZw3iLiNNqAL6uNW9qnTerf5UNr14Hv46ILVvzToyIBWu5/bkRcUbXClxPo13fEXFORPwyIp6KiOP7XKpGMKkCuXplKWWr1uuePtRwZUcN71jXHXSr97cB+30Q+GhETBnPeoYzTseYApw6Dvvpimisz/dzpOv7euDtwE/Gr8r1szHcuXTLZAzkYUXEARHxo4hYHhHXR8TBrWXbRMRnI2JpRCyJiDOGQiEipkTEP0fE/RFxO/DyDahhm4g4LyKWRcSdEfHhoS9l7VlfERHzIuIB4LS6zr51+TG1R7pnff+WiLi4Tu8fEVfWc1saEZ+OiM1axy0R8VcRcStwa513SETcHBEP1R58jFH+N4HHgTeOcG6b13a6KyLui4izImJa69x+2LF+iYjZdfrciPhMRFwaEb8FXhQRL4+In0bEwxGxOCJOW7fW5p+A90bEtiPUOyciLouIB2vP8nV1/knAMcD7aw/06xFxQkR8vbXtrRHxldb7xRGxT50+MCKuru16dUQc2FpvQUR8LCKuAB4Fdu+oaaeIuCEi3reO50op5d9LKd8FfjfWuhFxeET8IiJW1Ov9va1lR0TEdbXdb4uIw+r8nSPia7W9BiPira1tTouIiyLi/Ih4GDg+IjaJiA/WfTwQERdGxIy6/hZ13QfqNXt1ROy4ruc8IZVSJs0LuAN46TDzB4AHgMNpfqQOqe93qMu/CpwNbAk8A7gKeFtddjJwM7ArMAP4PlCAqSPUcDzwwxGWnQf8D7A1MAu4BXhLa7vfA3OBqcC0uv576vJzgNuAU1r7ened3hc4oG43C7gJeFfruAW4rNY/DdgeWAG8BtgUeHc99okj1H0acD7wKuD2us3Uut9ZdZ15wNfqMbYGvg58fKQ2qdvOrtPnAg8BL6yfzxbAwcBe9f3ewH3AkXX9WWN8BncALwX+GzijzjsRWFCntwQWAyfU8/gT4H5gj1Y9Z7T2tzuwvNayM3AncHdr2W/qshl1+ti636Pr+6fXdRcAdwF71uWb1nknArvRXA8nrev13bHOD4Hjx1hnKXBQnd4OeG6d3r9+DofU8xkA5tRlPwD+o342+wDLgBe3ro8ngCPrdtNo7k4WAbsAm9N8v75Y139bvT6eRnMnsy8wvd/50ZOM6ncBPT3Z5oJ9pH55lgMX1/kfAL7Qse63gOOAHYHHgGmtZUcD36/T3wNObi37izHC4HiacFveeh1QL7zHh770dd23sSokjgfu6tjXW4Cv1emb6hf3S/X9nUNfpGFqeBfw1db7MvTlqe/fBCxqvQ/gbsYI5Dr9Y+AUWoFct/8t8KzWNi8AftU6t7EC+bwxPttPAfPq9KwxPoM7aAL5j2kCZgdWD+TXA5d3bHM28JFWPWd0LF8MPBc4iubH8SpgDk2oD31GxwJXdWx3JTUgacL39I7lC4B/rTUfvT7Xd8c6axPId9Vrb3rH/LOH2rhj/q7Ak8DWrXkfB85tXR8/6NjmJuAlrfc70YT2VODNwI+Avcfjez+RXpNxyOLIUsq29XVknTcTeG29PVoeEcuBP6W5SGbS9FSWtpadTdNThqZHtLi1/zuHJiLioFj1cOXG1jqLWjVsW0pZRNMr3bS9fZ0eaL1vHwdgIXBQROxEE+gXAi+M5kHaNsB1tY7nRMQlEXFvvWX8h3q8tva+Vzun0nxjOo89kg8DH6LpKQ3Zgaa3c22rDb9Z56+t1Y4fEc+PiO/X4Z2HaO5UOs9pVKWUnwOXAB/sWDQTeH7H9XAM8MxRdreQptf+Z3V6AfDn9bWwrjPUe24b6zOmHnsJcNHoZwQMf32vq7+kuVu8MyIWRsQL6vxdae7COu0MPFhKWdGaN9Z5zQS+2mrfm2hCfUfgCzQdoi9FxD0R8Y8Rsel6nsuEMhkDeTiLaXrI7ZDcspTyibrsMWD71rLppZQ967ZLaS7UIX8wNFFKubyseriyJ6O7n6aHMLNjX0ta71f7p/lKKYM0Y41zaXogDwP3AifR9Difqqt+hmZY5dmllOnA37LmmHB736udU0RExzmOqJRyGTBI8wCpfW4rgT1bbbhNKWWruvy3NIE9dLzhgq/znyW8gGYIZNdSyjbAWcOc09r4CPBW1gyPhR3Xw1allFNGqAVWBfJBdXohawbyPaz++cIYn3F1Gk0bXhA9eGhaSrm6lHIETafjYpofemja5VnDbHIPMCMitm7NG+u8FgMv62jjLUopS0opT5RSPlpK2QM4EHgFzV3bRs9AbpwPvDIiDo3mId0WEXFwROxSSlkKfBv4l4iYXh9GPCsi/rxueyHwzojYJSK2Y83e1loppTxZ9/WxiNg6ImYCf11rG81C4B2s+tIv6HgPzZjtw8AjETGHZkhhNN8A9oyIV0fzRPydjN477PQh4P1Db+oPw38C8yLiGQARMRARh9ZVrq/H2ycitqAJoLFsTdMr+11E7A+8YR3q+3/1R+3LNOc45BLgORFxbERsWl/Pi4g/qsvvo+OBG017v4hmaOtu4HLgMODpwE/rOpfW/b4hmv8s8PXAHvV4o3kCeC3N2PZ5sR7/9UVEbFbbNoBN6zW+xn7qesdExDallCdorpuhH/bPAidExEvq92AgIuaUUhbTDDF8vO53b5rhtNGu3bNorvWZ9bg7RMQRdfpFEbFX/fF5uJ7/UyPvauNhIAP1gjqCpue4jObX+32sap83AZsBv6B5CHMRzXAGNEHzLZpQ+QnNg6L1NZemt3g7zVjfBcDnxthmIU04/WCE9wDvpQmsFbXeL4+2w1LK/TQB8Amah5vPBq5Y25MopVxBM4ba9gGanvOiOmzyHeAP6/q3AKfXebfSnPtY3g6cHhErgL9nVS9ufZxOE3ZD9a+geRZwFE3v717gkzQPn6AJpj3q7fbFrXN4hCaIqXcrtwNX1B9bSikP0PT23kPTru8HXlHbe1SllMeBV9Pc0n9uPUL52zR3KQfSjHGvpBleGc6xwB31czqZZsiEUspVNGPi82jG3heyqsd/NM3Y/T00D8E/Ukr5zij1nElzh/Pt+hkuAp5flz2T5jv2MM1QxkKaYYyNXjTDg5KkfrOHLElJGMiSlISBLElJGMiSlMQ6/SMf22+/fZk1a1aXSpGkjdO11157fyllzL8ItU6BPGvWLK655pr1r0qSJqGI6PwbmsNyyEKSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSklin/6eeNN7mz5/P4OBgv8tYw5IlSwAYGBjocyW9MXv2bObOndvvMiY9A1l9NTg4yHU/v4knnzaj36WsZsqjDwFw72Mb/1dkyqMP9rsEVRv/1ab0nnzaDFbOObzfZaxm2s2XAqSrqxuGzlX95xiyJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCVhIEtSEgayJCXRk0CeP38+8+fP78WhJGlc9TK/pvbiIIODg704jCSNu17ml0MWkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpSEgSxJSRjIkpTE1F4cZMmSJaxcuZJTTz21F4fTBDI4OMgmj5d+lzGpbfK7hxkcXOH3cwSDg4NMmzatJ8cas4ccESdFxDURcc2yZct6UZMkTUpj9pBLKecA5wDst99+69WVGRgYAODMM89cn821ETv11FO59vb7+l3GpPbUFtOZvfuOfj9H0Ms7B8eQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkpjai4PMnj27F4eRpHHXy/zqSSDPnTu3F4eRpHHXy/xyyEKSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSkJA1mSkjCQJSmJqf0uQJry6INMu/nSfpexmimPPgCQrq5umPLog8CO/S5DGMjqs9mzZ/e7hGEtWfJ7AAYGJkNQ7Zj2c5hsDGT11dy5c/tdgpSGY8iSlISBLElJGMiSlISBLElJGMiSlISBLElJGMiSlISBLElJGMiSlISBLElJGMiSlISBLElJGMiSlISBLElJGMiSlISBLElJGMiSlISBLElJGMiSlISBLElJRCll7VeOWAbc2b1yANgeuL/Lx+gWa++PiVr7RK0brH1dzSyl7DDWSusUyL0QEdeUUvbrdx3rw9r7Y6LWPlHrBmvvFocsJCkJA1mSksgYyOf0u4ANYO39MVFrn6h1g7V3RboxZEmarDL2kCVpUjKQJSmJrgdyRBwWEb+MiMGI+OAwy+dFxHX1dUtELG8tOy4ibq2v41rz942In9V9/ltExASqfUHd59B2z0hW9zcjYnlEXNKxzW4R8eO6zy9HxGbjXXcXaz83In7V2m6fTLVHxD4RcWVE3BgRN0TE61vbdL3du1R39jafGRE/qfNvjIiTW9v0JF+GVUrp2guYAtwG7A5sBlwP7DHK+nOBz9XpGcDt9c/t6vR2ddlVwAFAAP8LvGwC1b4A2C9jm9f3LwFeCVzSsd6FwFF1+izglAlU+7nAaxJf688Bnl2ndwaWAtv2ot27WHf2Nt8M2LxObwXcAexc33c9X0Z6dbuHvD8wWEq5vZTyOPAl4IhR1j8a+GKdPhS4rJTyYCnlN8BlwGERsRMwvZSyqDStdx5w5ESovQs1DmdD6qaU8l1gRXuF2kN4MXBRnfVf5GvzYWvvofWuvZRySynl1jp9D/BrYIcetfu41z3O9Y1mQ2p/vJTyWJ2/OXW0oIf5MqxuB/IAsLj1/u46bw0RMRPYDfjeGNsO1Okx97mBulH7kM/XW6W/68Lt0IbUPZKnA8tLKb8fa58bqBu1D/lYva2eFxGbb1iZwxqX2iNif5re2230pt27UfeQ1G0eEbtGxA11H5+sPyq9ypdhZXqodxRwUSnlyX4Xsh7WpfZjSil7AQfV17FdrWx0k6XN/waYAzyPZhjpA90sbC0MW3vtnX0BOKGU8lRfKhvdutSdvs1LKYtLKXsDs4HjImLHvlVXdTuQlwC7tt7vUucN5yhat5+jbLukTq/NPjdEN2qnlDL05wrgAprbrvG0IXWP5AFg24iYuhb73BDdqJ1SytLSeAz4POPf5rCBtUfEdOAbwIdKKYvq7F60ezfqnhBtPqT2jH9O00HqVb4Mr8uD7lNpHmjtxqpB9z2HWW8OzaB6tObNAH5F81Bsuzo9Y4RB98MnQu11n9vXdTalGRs8OUvdrWUHs+aDsa+w+sOlt2dq8zFq36n+GcCngE9kqr2u/13gXcOs39V272Ld2dt8F2Band4OuAXYq77ver6MeE5dPwAcXk/2NppfUYDTgVe11jltuA8MeDMwWF8ntObvR/OLdhvw6eG+mBlrB7YErgVuAG4EzgSmJKv7cmAZsJJm/OzQOn/3eqEO1pDYPGGbj1T794Cf1WvmfGCrTLUDbwSeAK5rvfbpVbt3qe7sbX5I/R5eX/88qbWsJ/ky3Mu/Oi1JSWR6qCdJk5qBLElJGMiSlISBLElJGMiSlISBLElJGMiSlMT/AUI7IcKKICQhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(DataFrame([x['val_f1'] for x in bests])).set_title(\"Feed-Forward Neural Network F1 scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one outlier in our results, the second cross validation. For this validation it is actually more accurate than the others, but for the AUC and F1 score it is slightly lower. It's not a very distant outlier, so it appears that this is a suitable benchmark for Feed-Forward neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "146692/146692 [==============================] - 49s 332us/step - loss: 0.7613 - acc: 0.6617 - auroc: 0.7161 - f1: 0.6666\n",
      "Epoch 2/25\n",
      "146692/146692 [==============================] - 45s 310us/step - loss: 0.7126 - acc: 0.6849 - auroc: 0.7420 - f1: 0.6873\n",
      "Epoch 3/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7111 - acc: 0.6880 - auroc: 0.7448 - f1: 0.6892\n",
      "Epoch 4/25\n",
      "146692/146692 [==============================] - 46s 310us/step - loss: 0.7085 - acc: 0.6871 - auroc: 0.7451 - f1: 0.6863\n",
      "Epoch 5/25\n",
      "146692/146692 [==============================] - 46s 310us/step - loss: 0.7091 - acc: 0.6903 - auroc: 0.7469 - f1: 0.6898\n",
      "Epoch 6/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7117 - acc: 0.6891 - auroc: 0.7478 - f1: 0.6887\n",
      "Epoch 7/25\n",
      "146692/146692 [==============================] - 46s 310us/step - loss: 0.7126 - acc: 0.6904 - auroc: 0.7494 - f1: 0.6899\n",
      "Epoch 8/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7111 - acc: 0.6909 - auroc: 0.7501 - f1: 0.6907\n",
      "Epoch 9/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7102 - acc: 0.6922 - auroc: 0.7515 - f1: 0.6929\n",
      "Epoch 10/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7087 - acc: 0.6927 - auroc: 0.7519 - f1: 0.6934\n",
      "Epoch 11/25\n",
      "146692/146692 [==============================] - 45s 310us/step - loss: 0.7090 - acc: 0.6930 - auroc: 0.7523 - f1: 0.6935\n",
      "Epoch 12/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7070 - acc: 0.6947 - auroc: 0.7533 - f1: 0.6962\n",
      "Epoch 13/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7104 - acc: 0.6930 - auroc: 0.7523 - f1: 0.6939\n",
      "Epoch 14/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7111 - acc: 0.6931 - auroc: 0.7534 - f1: 0.6938\n",
      "Epoch 15/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7107 - acc: 0.6932 - auroc: 0.7527 - f1: 0.6947\n",
      "Epoch 16/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7118 - acc: 0.6910 - auroc: 0.7521 - f1: 0.6917\n",
      "Epoch 17/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7111 - acc: 0.6918 - auroc: 0.7514 - f1: 0.6936\n",
      "Epoch 18/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7093 - acc: 0.6936 - auroc: 0.7535 - f1: 0.6949\n",
      "Epoch 19/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7104 - acc: 0.6944 - auroc: 0.7533 - f1: 0.6972\n",
      "Epoch 20/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7085 - acc: 0.6933 - auroc: 0.7533 - f1: 0.6954\n",
      "Epoch 21/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7108 - acc: 0.6947 - auroc: 0.7528 - f1: 0.6972\n",
      "Epoch 22/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7116 - acc: 0.6951 - auroc: 0.7538 - f1: 0.6977\n",
      "Epoch 23/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7092 - acc: 0.6944 - auroc: 0.7536 - f1: 0.6964\n",
      "Epoch 24/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7120 - acc: 0.6939 - auroc: 0.7537 - f1: 0.6961\n",
      "Epoch 25/25\n",
      "146692/146692 [==============================] - 46s 311us/step - loss: 0.7140 - acc: 0.6919 - auroc: 0.7517 - f1: 0.6940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2b729a35c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffnn_model = get_ff_wv_model()\n",
    "ffnn_model.fit([train_input_features, train_reviewer], train_labels, epochs=25, batch_size=256, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 478us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7064118288993836, 0.7018, 0.7542242023871568, 0.7133180366516113]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores = ffnn_model.evaluate([input_features[-10000:], reviewer[-10000:]], labels[-10000:])\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results on the test set show a loss of 70.6, accuracy of 70.2, auroc of 75.4 and f1 of 71.3. This shows that our model has not excessively overfit, and suggests that it would perform usefully on unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
