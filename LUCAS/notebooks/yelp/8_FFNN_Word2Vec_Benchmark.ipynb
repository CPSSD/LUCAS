{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network Benchmark\n",
    "\n",
    "To create a benchmark for comparing future work, this experiment aims to create a simple feedforward neural network and apply it to a substantial amount of our data.\n",
    "\n",
    "This network will receive pretrained word2vec vectors as input and pass them through three dense layers. One dropout layer will exist after the first dense layer to help reduce overfitting.\n",
    "\n",
    "Although FFNN have been used in earlier experiments, this is the first to run it over a substantial amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scripts.cross_validate import run_single_cross_validate\n",
    "from scripts.feature_extraction import get_balanced_dataset, get_entire_dataset, scaled_reviewer_features\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Dropout, Embedding, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from exp2_feature_extraction import reviewer_features, reviews_by_reviewer\n",
    "from metrics import auroc, f1\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "import statistics\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from seaborn import boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = get_balanced_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156692"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review_content(review_content):\n",
    "  return \" \".join([x for x in nltk.word_tokenize(review_content) if x.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_contents = [clean_review_content(x.review_content) for x in all_reviews]\n",
    "labels = [1 if x.label else 0 for x in all_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must convert our reviews to sequences, as this is the input to the 'Embedding' layer of our model that maps words to their embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(reviews_contents)\n",
    "input_features = np.array(pad_sequences(tokenizer.texts_to_sequences(reviews_contents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words = tokenizer.word_index\n",
    "corpus_vocab_size = len(corpus_words)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the word2vec embeddings pretrained by google over a large Google News corpus. We use this to create an embedding matrix, which is a map of sequence identifier (number of the word) to it's vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(\"../../data/GoogleNews-vectors-negative300.bin\",\n",
    "                                                               binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_length = word_vectors.vector_size\n",
    "embedding_matrix = np.zeros((corpus_vocab_size, embedding_length))\n",
    "for word, index in corpus_words.items():\n",
    "  if word in word_vectors.vocab:\n",
    "    embedding_matrix[index] = np.array(word_vectors[word], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must calculate the max review length since the Embedding layer of our model uses this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "max_review_len = 0\n",
    "for input_feature in input_features:\n",
    "    max_review_len = max(max_review_len, len(input_feature))\n",
    "print(max_review_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of words in our vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76783"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that our input dataset is roughly balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78346"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x.label for x in all_reviews if x.label == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the model described and give our sequences as input. The model converts the sequences to embeddings and passes them through the FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ff_wv_model():\n",
    "  i1 = Input(shape=(max_review_len,))\n",
    "  i2 = Input(shape=(5,))\n",
    "    \n",
    "  l1 = Embedding(corpus_vocab_size, embedding_length, weights=[embedding_matrix], trainable=False)(i1)\n",
    "  l2 = Flatten()(l1)\n",
    "  l3 = Concatenate()([l2, i2])\n",
    "  l4 = Dense(16, activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.l2(0.01))(l3)\n",
    "  l5 = Dropout(0.25)(l4)\n",
    "  l6 = Dense(8, activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.l2(0.01))(l5)\n",
    "  l7 = Dense(1, activation=tf.keras.activations.sigmoid)(l6)\n",
    "\n",
    "  model = Model(inputs=[i1, i2], outputs=l7)\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ffnn_model(train_X, train_y, test_X, test_y):\n",
    "    ffnn_model = get_ff_wv_model()\n",
    "    return ffnn_model.fit([x for x in train_X], train_y, epochs=50, batch_size=256, verbose=1, shuffle=False,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=8)],\n",
    "                   validation_data=([x for x in test_X], test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer = scaled_reviewer_features(all_reviews, get_entire_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_features = input_features[:-10000]\n",
    "train_reviewer = reviewer[:-10000]\n",
    "train_labels = labels[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 132021 samples, validate on 14671 samples\n",
      "Epoch 1/50\n",
      "132021/132021 [==============================] - 44s 336us/step - loss: 0.7748 - acc: 0.6569 - auroc: 0.7101 - f1: 0.6546 - val_loss: 0.6993 - val_acc: 0.6923 - val_auroc: 0.7512 - val_f1: 0.7025\n",
      "Epoch 2/50\n",
      "132021/132021 [==============================] - 44s 331us/step - loss: 0.7135 - acc: 0.6848 - auroc: 0.7419 - f1: 0.6853 - val_loss: 0.6984 - val_acc: 0.6961 - val_auroc: 0.7554 - val_f1: 0.7144\n",
      "Epoch 3/50\n",
      "132021/132021 [==============================] - 44s 333us/step - loss: 0.7043 - acc: 0.6878 - auroc: 0.7450 - f1: 0.6881 - val_loss: 0.6868 - val_acc: 0.6976 - val_auroc: 0.7549 - val_f1: 0.6947\n",
      "Epoch 4/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7013 - acc: 0.6881 - auroc: 0.7458 - f1: 0.6876 - val_loss: 0.6987 - val_acc: 0.6962 - val_auroc: 0.7578 - val_f1: 0.7229\n",
      "Epoch 5/50\n",
      "132021/132021 [==============================] - 44s 333us/step - loss: 0.7016 - acc: 0.6889 - auroc: 0.7463 - f1: 0.6884 - val_loss: 0.6959 - val_acc: 0.6951 - val_auroc: 0.7524 - val_f1: 0.7007\n",
      "Epoch 6/50\n",
      "132021/132021 [==============================] - 44s 330us/step - loss: 0.6996 - acc: 0.6905 - auroc: 0.7487 - f1: 0.6893 - val_loss: 0.6876 - val_acc: 0.7035 - val_auroc: 0.7612 - val_f1: 0.7136\n",
      "Epoch 7/50\n",
      "132021/132021 [==============================] - 44s 332us/step - loss: 0.6995 - acc: 0.6889 - auroc: 0.7480 - f1: 0.6887 - val_loss: 0.6828 - val_acc: 0.7051 - val_auroc: 0.7637 - val_f1: 0.7197\n",
      "Epoch 8/50\n",
      "132021/132021 [==============================] - 43s 328us/step - loss: 0.6981 - acc: 0.6901 - auroc: 0.7486 - f1: 0.6900 - val_loss: 0.6959 - val_acc: 0.6982 - val_auroc: 0.7584 - val_f1: 0.7231\n",
      "Epoch 9/50\n",
      "132021/132021 [==============================] - 44s 330us/step - loss: 0.7013 - acc: 0.6902 - auroc: 0.7495 - f1: 0.6899 - val_loss: 0.6908 - val_acc: 0.7038 - val_auroc: 0.7654 - val_f1: 0.7195\n",
      "Epoch 10/50\n",
      "132021/132021 [==============================] - 44s 332us/step - loss: 0.6993 - acc: 0.6917 - auroc: 0.7506 - f1: 0.6912 - val_loss: 0.6929 - val_acc: 0.7035 - val_auroc: 0.7621 - val_f1: 0.7133\n",
      "Epoch 11/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7011 - acc: 0.6908 - auroc: 0.7501 - f1: 0.6914 - val_loss: 0.6828 - val_acc: 0.7052 - val_auroc: 0.7626 - val_f1: 0.7227\n",
      "Epoch 12/50\n",
      "132021/132021 [==============================] - 44s 333us/step - loss: 0.7005 - acc: 0.6918 - auroc: 0.7510 - f1: 0.6939 - val_loss: 0.6865 - val_acc: 0.7067 - val_auroc: 0.7661 - val_f1: 0.7170\n",
      "Epoch 13/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7007 - acc: 0.6918 - auroc: 0.7511 - f1: 0.6936 - val_loss: 0.6930 - val_acc: 0.7092 - val_auroc: 0.7625 - val_f1: 0.7251\n",
      "Epoch 14/50\n",
      "132021/132021 [==============================] - 45s 339us/step - loss: 0.7003 - acc: 0.6918 - auroc: 0.7511 - f1: 0.6941 - val_loss: 0.6900 - val_acc: 0.7073 - val_auroc: 0.7698 - val_f1: 0.7292\n",
      "Epoch 15/50\n",
      "132021/132021 [==============================] - 45s 340us/step - loss: 0.7034 - acc: 0.6935 - auroc: 0.7517 - f1: 0.6966 - val_loss: 0.6931 - val_acc: 0.7102 - val_auroc: 0.7686 - val_f1: 0.7240\n",
      "Epoch 16/50\n",
      "132021/132021 [==============================] - 45s 342us/step - loss: 0.7051 - acc: 0.6920 - auroc: 0.7512 - f1: 0.6947 - val_loss: 0.6873 - val_acc: 0.6974 - val_auroc: 0.7623 - val_f1: 0.7215\n",
      "Epoch 17/50\n",
      "132021/132021 [==============================] - 45s 343us/step - loss: 0.7006 - acc: 0.6912 - auroc: 0.7515 - f1: 0.6951 - val_loss: 0.6958 - val_acc: 0.6985 - val_auroc: 0.7625 - val_f1: 0.7266\n",
      "Epoch 18/50\n",
      "132021/132021 [==============================] - 45s 344us/step - loss: 0.6997 - acc: 0.6931 - auroc: 0.7519 - f1: 0.6969 - val_loss: 0.6888 - val_acc: 0.7079 - val_auroc: 0.7669 - val_f1: 0.7262\n",
      "Epoch 19/50\n",
      "132021/132021 [==============================] - 45s 344us/step - loss: 0.7055 - acc: 0.6936 - auroc: 0.7529 - f1: 0.6985 - val_loss: 0.6732 - val_acc: 0.7146 - val_auroc: 0.7717 - val_f1: 0.7241\n",
      "Epoch 20/50\n",
      "132021/132021 [==============================] - 45s 343us/step - loss: 0.7028 - acc: 0.6942 - auroc: 0.7526 - f1: 0.6981 - val_loss: 0.6843 - val_acc: 0.7085 - val_auroc: 0.7668 - val_f1: 0.7355\n",
      "Epoch 21/50\n",
      "132021/132021 [==============================] - 45s 339us/step - loss: 0.7022 - acc: 0.6927 - auroc: 0.7522 - f1: 0.6981 - val_loss: 0.6912 - val_acc: 0.7040 - val_auroc: 0.7677 - val_f1: 0.7316\n",
      "Epoch 22/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7043 - acc: 0.6935 - auroc: 0.7524 - f1: 0.6985 - val_loss: 0.6942 - val_acc: 0.7045 - val_auroc: 0.7646 - val_f1: 0.7274\n",
      "Epoch 23/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7058 - acc: 0.6939 - auroc: 0.7526 - f1: 0.6992 - val_loss: 0.6905 - val_acc: 0.7053 - val_auroc: 0.7680 - val_f1: 0.7289\n",
      "Epoch 24/50\n",
      "132021/132021 [==============================] - 44s 336us/step - loss: 0.7042 - acc: 0.6932 - auroc: 0.7526 - f1: 0.6992 - val_loss: 0.7004 - val_acc: 0.6993 - val_auroc: 0.7620 - val_f1: 0.7240\n",
      "Epoch 25/50\n",
      "132021/132021 [==============================] - 44s 337us/step - loss: 0.7054 - acc: 0.6940 - auroc: 0.7528 - f1: 0.6992 - val_loss: 0.6873 - val_acc: 0.7128 - val_auroc: 0.7669 - val_f1: 0.7308\n",
      "Epoch 26/50\n",
      "132021/132021 [==============================] - 44s 334us/step - loss: 0.7006 - acc: 0.6928 - auroc: 0.7528 - f1: 0.6988 - val_loss: 0.6856 - val_acc: 0.7062 - val_auroc: 0.7667 - val_f1: 0.7297\n",
      "Epoch 27/50\n",
      "132021/132021 [==============================] - 44s 333us/step - loss: 0.7058 - acc: 0.6947 - auroc: 0.7540 - f1: 0.6998 - val_loss: 0.6844 - val_acc: 0.7077 - val_auroc: 0.7698 - val_f1: 0.7275\n",
      "Validation Loss:\n",
      "[0.6993487904216604, 0.6984497896448884, 0.6868059744166009, 0.698707974218703, 0.6959366901066639, 0.6876175906604381, 0.6828041801699002, 0.6959195081486097, 0.6907818485245644, 0.6928602219659868, 0.6827885685267034, 0.6865233676653439, 0.6930352644266733, 0.6899912199126732, 0.6930645000113113, 0.6873310520624417, 0.6957985096227723, 0.6888322251461074, 0.6732355435196343, 0.684255246707051, 0.6911981660207676, 0.6942324814690166, 0.6904939644485072, 0.700431757783867, 0.687341415100437, 0.6855933643234068, 0.6843911290055005]\n",
      "Validation Accuracy:\n",
      "[0.6923181785817901, 0.6961352328046375, 0.697566628074217, 0.6962033945978984, 0.6951128077258378, 0.7034966941910461, 0.7051325743853798, 0.6981800833035081, 0.7038375024179294, 0.7034966940204105, 0.7052007360648835, 0.7067002931074101, 0.7091541135329815, 0.7073137481295009, 0.7101765388189816, 0.6973621429219485, 0.6985208915872699, 0.7079272031881564, 0.714607048043606, 0.7084724968882655, 0.7039738257769369, 0.7044509578178562, 0.7053370594238911, 0.6993388318347586, 0.7127666826035606, 0.706154999785137, 0.7076545567342202]\n",
      "Validation F1:\n",
      "[0.7024976801314844, 0.7144282214375542, 0.6947273164753955, 0.7228807848449395, 0.7006623305334131, 0.7135729488196382, 0.7196556445637508, 0.7230758016545481, 0.7194524775959704, 0.7132916554181937, 0.7227240652526443, 0.7169525594069713, 0.7251461636808035, 0.7291574852369564, 0.7240011529090109, 0.7215325429870034, 0.7265663160379741, 0.7261774828362324, 0.7240855165659288, 0.7355030463213293, 0.731592098219118, 0.7274266590281309, 0.7288691127408332, 0.7240309507826843, 0.730804591211071, 0.7296921755425583, 0.727482160804592]\n",
      "Validation AUROC:\n",
      "[0.7024976801314844, 0.7144282214375542, 0.6947273164753955, 0.7228807848449395, 0.7006623305334131, 0.7135729488196382, 0.7196556445637508, 0.7230758016545481, 0.7194524775959704, 0.7132916554181937, 0.7227240652526443, 0.7169525594069713, 0.7251461636808035, 0.7291574852369564, 0.7240011529090109, 0.7215325429870034, 0.7265663160379741, 0.7261774828362324, 0.7240855165659288, 0.7355030463213293, 0.731592098219118, 0.7274266590281309, 0.7288691127408332, 0.7240309507826843, 0.730804591211071, 0.7296921755425583, 0.727482160804592]\n",
      "best: {'val_f1': 0.7240855165659288, 'val_auroc': 0.7716540556686994, 'val_accuracy': 0.714607048043606, 'val_loss': 0.6732355435196343}\n",
      "Train on 132023 samples, validate on 14669 samples\n",
      "Epoch 1/50\n",
      "132023/132023 [==============================] - 45s 341us/step - loss: 0.7702 - acc: 0.6559 - auroc: 0.7089 - f1: 0.6589 - val_loss: 0.7089 - val_acc: 0.6857 - val_auroc: 0.7435 - val_f1: 0.6851\n",
      "Epoch 2/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7168 - acc: 0.6843 - auroc: 0.7404 - f1: 0.6767 - val_loss: 0.7035 - val_acc: 0.6930 - val_auroc: 0.7513 - val_f1: 0.7101\n",
      "Epoch 3/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7121 - acc: 0.6872 - auroc: 0.7448 - f1: 0.6799 - val_loss: 0.7099 - val_acc: 0.6993 - val_auroc: 0.7567 - val_f1: 0.7165\n",
      "Epoch 4/50\n",
      "132023/132023 [==============================] - 44s 336us/step - loss: 0.7146 - acc: 0.6889 - auroc: 0.7473 - f1: 0.6854 - val_loss: 0.7093 - val_acc: 0.6906 - val_auroc: 0.7522 - val_f1: 0.7180\n",
      "Epoch 5/50\n",
      "132023/132023 [==============================] - 44s 331us/step - loss: 0.7183 - acc: 0.6903 - auroc: 0.7487 - f1: 0.6870 - val_loss: 0.7153 - val_acc: 0.6983 - val_auroc: 0.7583 - val_f1: 0.7182\n",
      "Epoch 6/50\n",
      "132023/132023 [==============================] - 44s 336us/step - loss: 0.7195 - acc: 0.6912 - auroc: 0.7502 - f1: 0.6893 - val_loss: 0.7218 - val_acc: 0.6899 - val_auroc: 0.7567 - val_f1: 0.7231\n",
      "Epoch 7/50\n",
      "132023/132023 [==============================] - 45s 340us/step - loss: 0.7159 - acc: 0.6936 - auroc: 0.7504 - f1: 0.6921 - val_loss: 0.7026 - val_acc: 0.7005 - val_auroc: 0.7608 - val_f1: 0.7183\n",
      "Epoch 8/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7157 - acc: 0.6908 - auroc: 0.7507 - f1: 0.6885 - val_loss: 0.7055 - val_acc: 0.7037 - val_auroc: 0.7643 - val_f1: 0.7170\n",
      "Epoch 9/50\n",
      "132023/132023 [==============================] - 44s 334us/step - loss: 0.7128 - acc: 0.6906 - auroc: 0.7514 - f1: 0.6891 - val_loss: 0.7056 - val_acc: 0.7041 - val_auroc: 0.7618 - val_f1: 0.7276\n",
      "Epoch 10/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7130 - acc: 0.6916 - auroc: 0.7507 - f1: 0.6900 - val_loss: 0.7081 - val_acc: 0.6959 - val_auroc: 0.7548 - val_f1: 0.7078\n",
      "Epoch 11/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7139 - acc: 0.6926 - auroc: 0.7524 - f1: 0.6910 - val_loss: 0.7203 - val_acc: 0.6889 - val_auroc: 0.7593 - val_f1: 0.7274\n",
      "Epoch 12/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7136 - acc: 0.6930 - auroc: 0.7527 - f1: 0.6935 - val_loss: 0.7085 - val_acc: 0.6960 - val_auroc: 0.7536 - val_f1: 0.7036\n",
      "Epoch 13/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7148 - acc: 0.6935 - auroc: 0.7531 - f1: 0.6934 - val_loss: 0.6979 - val_acc: 0.7063 - val_auroc: 0.7668 - val_f1: 0.7264\n",
      "Epoch 14/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7137 - acc: 0.6931 - auroc: 0.7539 - f1: 0.6925 - val_loss: 0.7160 - val_acc: 0.6936 - val_auroc: 0.7557 - val_f1: 0.7156\n",
      "Epoch 15/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7166 - acc: 0.6913 - auroc: 0.7531 - f1: 0.6918 - val_loss: 0.7128 - val_acc: 0.6900 - val_auroc: 0.7606 - val_f1: 0.7212\n",
      "Epoch 16/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7138 - acc: 0.6922 - auroc: 0.7521 - f1: 0.6918 - val_loss: 0.7079 - val_acc: 0.7043 - val_auroc: 0.7594 - val_f1: 0.7241\n",
      "Epoch 17/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7117 - acc: 0.6924 - auroc: 0.7517 - f1: 0.6921 - val_loss: 0.7060 - val_acc: 0.6994 - val_auroc: 0.7603 - val_f1: 0.7158\n",
      "Epoch 18/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7160 - acc: 0.6930 - auroc: 0.7528 - f1: 0.6941 - val_loss: 0.7004 - val_acc: 0.7045 - val_auroc: 0.7651 - val_f1: 0.7144\n",
      "Epoch 19/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7150 - acc: 0.6920 - auroc: 0.7534 - f1: 0.6924 - val_loss: 0.7049 - val_acc: 0.7018 - val_auroc: 0.7661 - val_f1: 0.7337\n",
      "Epoch 20/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7120 - acc: 0.6944 - auroc: 0.7549 - f1: 0.6958 - val_loss: 0.7085 - val_acc: 0.6932 - val_auroc: 0.7587 - val_f1: 0.7190\n",
      "Epoch 21/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7137 - acc: 0.6940 - auroc: 0.7529 - f1: 0.6949 - val_loss: 0.6967 - val_acc: 0.7043 - val_auroc: 0.7611 - val_f1: 0.7188\n",
      "Epoch 22/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7181 - acc: 0.6938 - auroc: 0.7527 - f1: 0.6948 - val_loss: 0.7098 - val_acc: 0.7026 - val_auroc: 0.7638 - val_f1: 0.7274\n",
      "Epoch 23/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7151 - acc: 0.6927 - auroc: 0.7526 - f1: 0.6941 - val_loss: 0.7203 - val_acc: 0.6925 - val_auroc: 0.7571 - val_f1: 0.7243\n",
      "Epoch 24/50\n",
      "132023/132023 [==============================] - 43s 325us/step - loss: 0.7184 - acc: 0.6922 - auroc: 0.7512 - f1: 0.6928 - val_loss: 0.7048 - val_acc: 0.7056 - val_auroc: 0.7591 - val_f1: 0.7229\n",
      "Epoch 25/50\n",
      "132023/132023 [==============================] - 43s 325us/step - loss: 0.7126 - acc: 0.6947 - auroc: 0.7537 - f1: 0.6966 - val_loss: 0.7131 - val_acc: 0.7016 - val_auroc: 0.7603 - val_f1: 0.7203\n",
      "Epoch 26/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7158 - acc: 0.6945 - auroc: 0.7540 - f1: 0.6971 - val_loss: 0.7062 - val_acc: 0.7056 - val_auroc: 0.7663 - val_f1: 0.7335\n",
      "Epoch 27/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7164 - acc: 0.6963 - auroc: 0.7561 - f1: 0.6991 - val_loss: 0.7399 - val_acc: 0.6680 - val_auroc: 0.7527 - val_f1: 0.7186\n",
      "Epoch 28/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7159 - acc: 0.6938 - auroc: 0.7526 - f1: 0.6951 - val_loss: 0.7230 - val_acc: 0.6773 - val_auroc: 0.7581 - val_f1: 0.7257\n",
      "Epoch 29/50\n",
      "132023/132023 [==============================] - 43s 329us/step - loss: 0.7131 - acc: 0.6933 - auroc: 0.7540 - f1: 0.6951 - val_loss: 0.7369 - val_acc: 0.6869 - val_auroc: 0.7558 - val_f1: 0.7216\n",
      "Validation Loss:\n",
      "[0.7089087691106503, 0.7035164259533119, 0.7098849653116853, 0.7092862599661066, 0.7152752500588409, 0.7218016671966991, 0.7025957824595664, 0.705483658587293, 0.7055504856823785, 0.708112122152097, 0.7203034082352323, 0.7085122281491322, 0.6978533264155345, 0.7160245209467079, 0.7127520018409257, 0.7078991870433489, 0.706002762886683, 0.7004120856700268, 0.7049443134013939, 0.7084668380479984, 0.6966541145661994, 0.709849647924175, 0.7203461812052699, 0.7048118811328521, 0.7130678466829317, 0.7062125463241594, 0.7398501122702411, 0.7229794042267612, 0.7369408052475859]\n",
      "Validation Accuracy:\n",
      "[0.6857318154092589, 0.692957938477276, 0.6992978389476558, 0.690571954380524, 0.6983434453284588, 0.6898902447744254, 0.7004567455340117, 0.703660781182462, 0.7040698070680204, 0.6958892903564263, 0.6888676800605295, 0.6959574613048464, 0.706251278246373, 0.6936396482296537, 0.6899584156740857, 0.70427431993766, 0.6994341808688755, 0.704478832904819, 0.7017519939440681, 0.6932306223440954, 0.7043424910079792, 0.7026382165904652, 0.692548912689237, 0.7056377394424154, 0.7016156519984685, 0.7056377394424154, 0.6680073625747717, 0.6773467856573664, 0.686890721971235]\n",
      "Validation F1:\n",
      "[0.6851302536282041, 0.7101080533965525, 0.7164549006990912, 0.7179580594150963, 0.7182274933680166, 0.7231210483892928, 0.7182534470767183, 0.7169588326237605, 0.7275928366614133, 0.7077512074625316, 0.7274026757361285, 0.7036149791351767, 0.7263556151873122, 0.7156466034846898, 0.7211526883583841, 0.7241096817827053, 0.7157904243849563, 0.7143925324857451, 0.7336739395584535, 0.7190440165841333, 0.718812044099663, 0.7274087928329495, 0.7242504471332816, 0.722936547483531, 0.7202791904767636, 0.7334786035692905, 0.7185662530326544, 0.725749037628062, 0.721581509666084]\n",
      "Validation AUROC:\n",
      "[0.6851302536282041, 0.7101080533965525, 0.7164549006990912, 0.7179580594150963, 0.7182274933680166, 0.7231210483892928, 0.7182534470767183, 0.7169588326237605, 0.7275928366614133, 0.7077512074625316, 0.7274026757361285, 0.7036149791351767, 0.7263556151873122, 0.7156466034846898, 0.7211526883583841, 0.7241096817827053, 0.7157904243849563, 0.7143925324857451, 0.7336739395584535, 0.7190440165841333, 0.718812044099663, 0.7274087928329495, 0.7242504471332816, 0.722936547483531, 0.7202791904767636, 0.7334786035692905, 0.7185662530326544, 0.725749037628062, 0.721581509666084]\n",
      "best: {'val_f1': 0.718812044099663, 'val_auroc': 0.7610934306845143, 'val_accuracy': 0.7043424910079792, 'val_loss': 0.6966541145661994}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 132023 samples, validate on 14669 samples\n",
      "Epoch 1/50\n",
      "132023/132023 [==============================] - 44s 334us/step - loss: 0.7599 - acc: 0.6622 - auroc: 0.7172 - f1: 0.6632 - val_loss: 0.6979 - val_acc: 0.6975 - val_auroc: 0.7594 - val_f1: 0.7188\n",
      "Epoch 2/50\n",
      "132023/132023 [==============================] - 43s 324us/step - loss: 0.7151 - acc: 0.6832 - auroc: 0.7401 - f1: 0.6830 - val_loss: 0.6988 - val_acc: 0.6893 - val_auroc: 0.7590 - val_f1: 0.7238\n",
      "Epoch 3/50\n",
      "132023/132023 [==============================] - 44s 330us/step - loss: 0.7106 - acc: 0.6852 - auroc: 0.7429 - f1: 0.6851 - val_loss: 0.6967 - val_acc: 0.6995 - val_auroc: 0.7600 - val_f1: 0.7179\n",
      "Epoch 4/50\n",
      "132023/132023 [==============================] - 43s 325us/step - loss: 0.7104 - acc: 0.6853 - auroc: 0.7437 - f1: 0.6842 - val_loss: 0.6891 - val_acc: 0.7018 - val_auroc: 0.7639 - val_f1: 0.7247\n",
      "Epoch 5/50\n",
      "132023/132023 [==============================] - 43s 325us/step - loss: 0.7082 - acc: 0.6861 - auroc: 0.7451 - f1: 0.6849 - val_loss: 0.6921 - val_acc: 0.6945 - val_auroc: 0.7590 - val_f1: 0.7172\n",
      "Epoch 6/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7075 - acc: 0.6887 - auroc: 0.7463 - f1: 0.6878 - val_loss: 0.6848 - val_acc: 0.7067 - val_auroc: 0.7649 - val_f1: 0.7227\n",
      "Epoch 7/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7033 - acc: 0.6891 - auroc: 0.7475 - f1: 0.6880 - val_loss: 0.7001 - val_acc: 0.6968 - val_auroc: 0.7618 - val_f1: 0.7271\n",
      "Epoch 8/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7091 - acc: 0.6910 - auroc: 0.7491 - f1: 0.6899 - val_loss: 0.7056 - val_acc: 0.6983 - val_auroc: 0.7679 - val_f1: 0.7307\n",
      "Epoch 9/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7074 - acc: 0.6890 - auroc: 0.7480 - f1: 0.6877 - val_loss: 0.7029 - val_acc: 0.7082 - val_auroc: 0.7639 - val_f1: 0.7183\n",
      "Epoch 10/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7113 - acc: 0.6889 - auroc: 0.7485 - f1: 0.6883 - val_loss: 0.6987 - val_acc: 0.7026 - val_auroc: 0.7607 - val_f1: 0.7220\n",
      "Epoch 11/50\n",
      "132023/132023 [==============================] - 43s 326us/step - loss: 0.7073 - acc: 0.6903 - auroc: 0.7498 - f1: 0.6897 - val_loss: 0.7031 - val_acc: 0.7043 - val_auroc: 0.7688 - val_f1: 0.7330\n",
      "Epoch 12/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7061 - acc: 0.6935 - auroc: 0.7514 - f1: 0.6933 - val_loss: 0.7021 - val_acc: 0.7069 - val_auroc: 0.7646 - val_f1: 0.7289\n",
      "Epoch 13/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7086 - acc: 0.6918 - auroc: 0.7510 - f1: 0.6917 - val_loss: 0.6859 - val_acc: 0.7064 - val_auroc: 0.7693 - val_f1: 0.7201\n",
      "Epoch 14/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7083 - acc: 0.6900 - auroc: 0.7493 - f1: 0.6895 - val_loss: 0.6992 - val_acc: 0.7084 - val_auroc: 0.7686 - val_f1: 0.7386\n",
      "Validation Loss:\n",
      "[0.6978960544900974, 0.6987717320431602, 0.6966823123700698, 0.6890632490031241, 0.6920672347391381, 0.6847531079709616, 0.7001445295701966, 0.705560443989541, 0.7029024218519867, 0.6986770173045249, 0.7031325255242242, 0.7020623607701811, 0.6858611224992882, 0.6991622760557707]\n",
      "Validation Accuracy:\n",
      "[0.6974572227552012, 0.6893448770407868, 0.699502351890435, 0.7017519940903472, 0.6944576999032511, 0.7066603040831717, 0.6968436840000032, 0.6983434454991178, 0.708160065484767, 0.7025700457151849, 0.7043424910811187, 0.7068648170747106, 0.7063876201919727, 0.7083645785006857]\n",
      "Validation F1:\n",
      "[0.718826675014397, 0.7237503286787594, 0.7179343513415565, 0.7247041964085607, 0.7172371451657554, 0.7226795409669888, 0.7270839188848018, 0.7307492123603235, 0.718253591970169, 0.7220027749503802, 0.7329830258274072, 0.728862163885474, 0.7201304594320838, 0.7385817872282511]\n",
      "Validation AUROC:\n",
      "[0.718826675014397, 0.7237503286787594, 0.7179343513415565, 0.7247041964085607, 0.7172371451657554, 0.7226795409669888, 0.7270839188848018, 0.7307492123603235, 0.718253591970169, 0.7220027749503802, 0.7329830258274072, 0.728862163885474, 0.7201304594320838, 0.7385817872282511]\n",
      "best: {'val_f1': 0.7226795409669888, 'val_auroc': 0.7649041749196194, 'val_accuracy': 0.7066603040831717, 'val_loss': 0.6847531079709616}\n",
      "Train on 132023 samples, validate on 14669 samples\n",
      "Epoch 1/50\n",
      "132023/132023 [==============================] - 44s 336us/step - loss: 0.7582 - acc: 0.6584 - auroc: 0.7095 - f1: 0.6593 - val_loss: 0.7222 - val_acc: 0.6862 - val_auroc: 0.7501 - val_f1: 0.7061\n",
      "Epoch 2/50\n",
      "132023/132023 [==============================] - 44s 334us/step - loss: 0.7121 - acc: 0.6826 - auroc: 0.7392 - f1: 0.6795 - val_loss: 0.7020 - val_acc: 0.6827 - val_auroc: 0.7436 - val_f1: 0.6562\n",
      "Epoch 3/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7057 - acc: 0.6852 - auroc: 0.7418 - f1: 0.6841 - val_loss: 0.7061 - val_acc: 0.6842 - val_auroc: 0.7430 - val_f1: 0.6914\n",
      "Epoch 4/50\n",
      "132023/132023 [==============================] - 44s 331us/step - loss: 0.7070 - acc: 0.6867 - auroc: 0.7430 - f1: 0.6865 - val_loss: 0.7019 - val_acc: 0.6831 - val_auroc: 0.7421 - val_f1: 0.6905\n",
      "Epoch 5/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7055 - acc: 0.6865 - auroc: 0.7442 - f1: 0.6871 - val_loss: 0.6767 - val_acc: 0.7018 - val_auroc: 0.7607 - val_f1: 0.6989\n",
      "Epoch 6/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7033 - acc: 0.6891 - auroc: 0.7468 - f1: 0.6888 - val_loss: 0.7065 - val_acc: 0.6865 - val_auroc: 0.7484 - val_f1: 0.7089\n",
      "Epoch 7/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7036 - acc: 0.6886 - auroc: 0.7465 - f1: 0.6885 - val_loss: 0.6886 - val_acc: 0.6994 - val_auroc: 0.7651 - val_f1: 0.7185\n",
      "Epoch 8/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7064 - acc: 0.6911 - auroc: 0.7488 - f1: 0.6916 - val_loss: 0.7011 - val_acc: 0.6851 - val_auroc: 0.7552 - val_f1: 0.7092\n",
      "Epoch 9/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7075 - acc: 0.6899 - auroc: 0.7489 - f1: 0.6896 - val_loss: 0.7065 - val_acc: 0.6923 - val_auroc: 0.7611 - val_f1: 0.7202\n",
      "Epoch 10/50\n",
      "132023/132023 [==============================] - 44s 336us/step - loss: 0.7045 - acc: 0.6901 - auroc: 0.7499 - f1: 0.6891 - val_loss: 0.6992 - val_acc: 0.6969 - val_auroc: 0.7621 - val_f1: 0.7223\n",
      "Epoch 11/50\n",
      "132023/132023 [==============================] - 44s 335us/step - loss: 0.7070 - acc: 0.6908 - auroc: 0.7517 - f1: 0.6906 - val_loss: 0.7035 - val_acc: 0.7067 - val_auroc: 0.7645 - val_f1: 0.7207\n",
      "Epoch 12/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7051 - acc: 0.6913 - auroc: 0.7511 - f1: 0.6912 - val_loss: 0.6814 - val_acc: 0.7044 - val_auroc: 0.7629 - val_f1: 0.7112\n",
      "Epoch 13/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7043 - acc: 0.6910 - auroc: 0.7508 - f1: 0.6918 - val_loss: 0.6957 - val_acc: 0.7035 - val_auroc: 0.7654 - val_f1: 0.7227\n",
      "Validation Loss:\n",
      "[0.7221901363021018, 0.7020349610281735, 0.7060680688991894, 0.7018676804768071, 0.6767350786164118, 0.7065172477915647, 0.6886110126960009, 0.7011085939972961, 0.7065479093407697, 0.6992348858537959, 0.7035420844627878, 0.6813560030895781, 0.6957098486534177]\n",
      "Validation Accuracy:\n",
      "[0.6862090121700977, 0.682732292532929, 0.6841638830348639, 0.6831413183941075, 0.7018201649900074, 0.6865498669853369, 0.699434180942015, 0.6851182765321616, 0.6922762287248985, 0.6969118548996635, 0.7067284750072118, 0.7044106619320193, 0.703456268361582]\n",
      "Validation F1:\n",
      "[0.7060878957469443, 0.6561827789632745, 0.691368765313816, 0.6905012273846963, 0.6988804128664274, 0.7088992617492564, 0.7184549416978225, 0.7092088408139888, 0.7202388869081833, 0.7222508052487796, 0.7206545963155052, 0.7112347295503852, 0.7226706416103541]\n",
      "Validation AUROC:\n",
      "[0.7060878957469443, 0.6561827789632745, 0.691368765313816, 0.6905012273846963, 0.6988804128664274, 0.7088992617492564, 0.7184549416978225, 0.7092088408139888, 0.7202388869081833, 0.7222508052487796, 0.7206545963155052, 0.7112347295503852, 0.7226706416103541]\n",
      "best: {'val_f1': 0.6988804128664274, 'val_auroc': 0.7606790216029338, 'val_accuracy': 0.7018201649900074, 'val_loss': 0.6767350786164118}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 132023 samples, validate on 14669 samples\n",
      "Epoch 1/50\n",
      "132023/132023 [==============================] - 45s 343us/step - loss: 0.7615 - acc: 0.6625 - auroc: 0.7160 - f1: 0.6600 - val_loss: 0.7017 - val_acc: 0.6906 - val_auroc: 0.7503 - val_f1: 0.7088\n",
      "Epoch 2/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7111 - acc: 0.6848 - auroc: 0.7420 - f1: 0.6855 - val_loss: 0.6890 - val_acc: 0.6943 - val_auroc: 0.7549 - val_f1: 0.7066\n",
      "Epoch 3/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7075 - acc: 0.6858 - auroc: 0.7427 - f1: 0.6877 - val_loss: 0.6980 - val_acc: 0.6846 - val_auroc: 0.7402 - val_f1: 0.6920\n",
      "Epoch 4/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7041 - acc: 0.6838 - auroc: 0.7421 - f1: 0.6857 - val_loss: 0.6914 - val_acc: 0.6925 - val_auroc: 0.7497 - val_f1: 0.6985\n",
      "Epoch 5/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7048 - acc: 0.6862 - auroc: 0.7440 - f1: 0.6887 - val_loss: 0.7033 - val_acc: 0.6913 - val_auroc: 0.7447 - val_f1: 0.7056\n",
      "Epoch 6/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7040 - acc: 0.6878 - auroc: 0.7448 - f1: 0.6889 - val_loss: 0.6918 - val_acc: 0.6952 - val_auroc: 0.7545 - val_f1: 0.7163\n",
      "Epoch 7/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7037 - acc: 0.6870 - auroc: 0.7451 - f1: 0.6879 - val_loss: 0.6889 - val_acc: 0.6968 - val_auroc: 0.7581 - val_f1: 0.7137\n",
      "Epoch 8/50\n",
      "132023/132023 [==============================] - 44s 334us/step - loss: 0.7023 - acc: 0.6878 - auroc: 0.7458 - f1: 0.6886 - val_loss: 0.6948 - val_acc: 0.6890 - val_auroc: 0.7439 - val_f1: 0.6951\n",
      "Epoch 9/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7000 - acc: 0.6894 - auroc: 0.7470 - f1: 0.6903 - val_loss: 0.6964 - val_acc: 0.6945 - val_auroc: 0.7551 - val_f1: 0.7175\n",
      "Epoch 10/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7020 - acc: 0.6898 - auroc: 0.7482 - f1: 0.6915 - val_loss: 0.6954 - val_acc: 0.6977 - val_auroc: 0.7603 - val_f1: 0.7206\n",
      "Epoch 11/50\n",
      "132023/132023 [==============================] - 44s 332us/step - loss: 0.7026 - acc: 0.6896 - auroc: 0.7486 - f1: 0.6908 - val_loss: 0.6935 - val_acc: 0.6968 - val_auroc: 0.7565 - val_f1: 0.7153\n",
      "Epoch 12/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7020 - acc: 0.6922 - auroc: 0.7499 - f1: 0.6948 - val_loss: 0.7037 - val_acc: 0.6960 - val_auroc: 0.7576 - val_f1: 0.7235\n",
      "Epoch 13/50\n",
      "132023/132023 [==============================] - 44s 331us/step - loss: 0.7058 - acc: 0.6892 - auroc: 0.7487 - f1: 0.6898 - val_loss: 0.6924 - val_acc: 0.6982 - val_auroc: 0.7626 - val_f1: 0.7208\n",
      "Epoch 14/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7012 - acc: 0.6908 - auroc: 0.7510 - f1: 0.6926 - val_loss: 0.6948 - val_acc: 0.6990 - val_auroc: 0.7545 - val_f1: 0.7143\n",
      "Epoch 15/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7039 - acc: 0.6924 - auroc: 0.7515 - f1: 0.6932 - val_loss: 0.6911 - val_acc: 0.7026 - val_auroc: 0.7605 - val_f1: 0.7137\n",
      "Validation Loss:\n",
      "[0.7017323866245798, 0.6890312802963067, 0.6979904952684106, 0.6913580911251671, 0.7032692936253585, 0.6917840632097602, 0.6889497483911929, 0.6948410850644267, 0.6964117575337025, 0.6954081687542695, 0.6934675382961565, 0.7036669088073105, 0.6924071016223228, 0.6948491920397012, 0.6911396613369057]\n",
      "Validation Accuracy:\n",
      "[0.6905719545024233, 0.6943213579820314, 0.6846410797957027, 0.6924807417164373, 0.6912536642060412, 0.6952075806771882, 0.6967755130759631, 0.6890040221036484, 0.6945258709735702, 0.6976617356979804, 0.696843684024383, 0.6960256323751655, 0.6982071035535181, 0.6990251551052163, 0.7026382167611241]\n",
      "Validation F1:\n",
      "[0.7088212068562485, 0.7065567674385891, 0.6919724613182285, 0.6985481070898429, 0.7055965413815796, 0.7162644336320959, 0.7137401629602733, 0.6951390323938625, 0.7175414779693512, 0.7205846370611465, 0.715264605873648, 0.723508856569431, 0.7208279889251924, 0.7143298474847926, 0.7136715799031695]\n",
      "Validation AUROC:\n",
      "[0.7088212068562485, 0.7065567674385891, 0.6919724613182285, 0.6985481070898429, 0.7055965413815796, 0.7162644336320959, 0.7137401629602733, 0.6951390323938625, 0.7175414779693512, 0.7205846370611465, 0.715264605873648, 0.723508856569431, 0.7208279889251924, 0.7143298474847926, 0.7136715799031695]\n",
      "best: {'val_f1': 0.7137401629602733, 'val_auroc': 0.7580518727327646, 'val_accuracy': 0.6967755130759631, 'val_loss': 0.6889497483911929}\n",
      "Train on 132023 samples, validate on 14669 samples\n",
      "Epoch 1/50\n",
      "132023/132023 [==============================] - 45s 339us/step - loss: 0.7685 - acc: 0.6638 - auroc: 0.7179 - f1: 0.6624 - val_loss: 0.7138 - val_acc: 0.6948 - val_auroc: 0.7531 - val_f1: 0.6920\n",
      "Epoch 2/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7161 - acc: 0.6845 - auroc: 0.7419 - f1: 0.6836 - val_loss: 0.6974 - val_acc: 0.6976 - val_auroc: 0.7569 - val_f1: 0.7090\n",
      "Epoch 3/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7140 - acc: 0.6858 - auroc: 0.7440 - f1: 0.6849 - val_loss: 0.7034 - val_acc: 0.7014 - val_auroc: 0.7584 - val_f1: 0.7069\n",
      "Epoch 4/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7156 - acc: 0.6871 - auroc: 0.7450 - f1: 0.6856 - val_loss: 0.7033 - val_acc: 0.6998 - val_auroc: 0.7575 - val_f1: 0.7109\n",
      "Epoch 5/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7143 - acc: 0.6883 - auroc: 0.7469 - f1: 0.6879 - val_loss: 0.6913 - val_acc: 0.7095 - val_auroc: 0.7699 - val_f1: 0.7267\n",
      "Epoch 6/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7152 - acc: 0.6899 - auroc: 0.7483 - f1: 0.6895 - val_loss: 0.6913 - val_acc: 0.7111 - val_auroc: 0.7715 - val_f1: 0.7288\n",
      "Epoch 7/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7146 - acc: 0.6893 - auroc: 0.7473 - f1: 0.6876 - val_loss: 0.7034 - val_acc: 0.7058 - val_auroc: 0.7627 - val_f1: 0.7235\n",
      "Epoch 8/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7153 - acc: 0.6918 - auroc: 0.7511 - f1: 0.6907 - val_loss: 0.7081 - val_acc: 0.7067 - val_auroc: 0.7615 - val_f1: 0.7153\n",
      "Epoch 9/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7132 - acc: 0.6916 - auroc: 0.7504 - f1: 0.6913 - val_loss: 0.6964 - val_acc: 0.7103 - val_auroc: 0.7668 - val_f1: 0.7270\n",
      "Epoch 10/50\n",
      "132023/132023 [==============================] - 43s 327us/step - loss: 0.7095 - acc: 0.6913 - auroc: 0.7499 - f1: 0.6901 - val_loss: 0.6852 - val_acc: 0.7129 - val_auroc: 0.7710 - val_f1: 0.7314\n",
      "Epoch 11/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7114 - acc: 0.6933 - auroc: 0.7522 - f1: 0.6939 - val_loss: 0.6947 - val_acc: 0.7108 - val_auroc: 0.7709 - val_f1: 0.7269\n",
      "Epoch 12/50\n",
      "132023/132023 [==============================] - 44s 333us/step - loss: 0.7137 - acc: 0.6917 - auroc: 0.7518 - f1: 0.6922 - val_loss: 0.6897 - val_acc: 0.7131 - val_auroc: 0.7715 - val_f1: 0.7324\n",
      "Epoch 13/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7109 - acc: 0.6920 - auroc: 0.7516 - f1: 0.6925 - val_loss: 0.6990 - val_acc: 0.7124 - val_auroc: 0.7724 - val_f1: 0.7292\n",
      "Epoch 14/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7096 - acc: 0.6909 - auroc: 0.7512 - f1: 0.6919 - val_loss: 0.6946 - val_acc: 0.7133 - val_auroc: 0.7727 - val_f1: 0.7323\n",
      "Epoch 15/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7090 - acc: 0.6903 - auroc: 0.7505 - f1: 0.6913 - val_loss: 0.6964 - val_acc: 0.7102 - val_auroc: 0.7663 - val_f1: 0.7341\n",
      "Epoch 16/50\n",
      "132023/132023 [==============================] - 43s 328us/step - loss: 0.7090 - acc: 0.6916 - auroc: 0.7516 - f1: 0.6923 - val_loss: 0.6943 - val_acc: 0.7122 - val_auroc: 0.7723 - val_f1: 0.7333\n",
      "Epoch 17/50\n",
      "  1792/132023 [..............................] - ETA: 39s - loss: 0.7167 - acc: 0.6908 - auroc: 0.7483 - f1: 0.6808"
     ]
    }
   ],
   "source": [
    "bests = []\n",
    "for cross in range(10):\n",
    "    ffnn_wv_scores = run_single_cross_validate(evaluate_ffnn_model, [train_input_features, train_reviewer],\n",
    "                                               train_labels, cross, splitter)\n",
    "    \n",
    "    print(\"Validation Loss:\")\n",
    "    val_loss = ffnn_wv_scores.history['val_loss']\n",
    "    print(val_loss)\n",
    "    print(\"Validation Accuracy:\")\n",
    "    val_accuracy = ffnn_wv_scores.history['val_acc']\n",
    "    print(val_accuracy)\n",
    "    print(\"Validation F1:\")\n",
    "    val_f1 = ffnn_wv_scores.history['val_f1']\n",
    "    print(val_f1)\n",
    "    print(\"Validation AUROC:\")\n",
    "    val_auroc = ffnn_wv_scores.history['val_auroc']\n",
    "    print(val_f1)\n",
    "\n",
    "    min_val_loss = 1\n",
    "    best = None\n",
    "    for loss, accuracy, f1_score, auroc_score in zip(val_loss, val_accuracy, val_f1, val_auroc):\n",
    "        if loss < min_val_loss:\n",
    "            min_val_loss = loss\n",
    "            best = { 'val_loss': loss, 'val_accuracy': accuracy, 'val_f1': f1_score, 'val_auroc': auroc_score }\n",
    "    print(\"best:\", best)\n",
    "    bests.append(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "{'val_f1': 0.7240855165659288, 'val_auroc': 0.7716540556686994, 'val_accuracy': 0.714607048043606, 'val_loss': 0.6732355435196343}\n",
      "==============================================================\n",
      "{'val_f1': 0.718812044099663, 'val_auroc': 0.7610934306845143, 'val_accuracy': 0.7043424910079792, 'val_loss': 0.6966541145661994}\n",
      "==============================================================\n",
      "{'val_f1': 0.7226795409669888, 'val_auroc': 0.7649041749196194, 'val_accuracy': 0.7066603040831717, 'val_loss': 0.6847531079709616}\n",
      "==============================================================\n",
      "{'val_f1': 0.6988804128664274, 'val_auroc': 0.7606790216029338, 'val_accuracy': 0.7018201649900074, 'val_loss': 0.6767350786164118}\n",
      "==============================================================\n",
      "{'val_f1': 0.7137401629602733, 'val_auroc': 0.7580518727327646, 'val_accuracy': 0.6967755130759631, 'val_loss': 0.6889497483911929}\n",
      "==============================================================\n",
      "{'val_f1': 0.731433466380583, 'val_auroc': 0.7709812828045498, 'val_accuracy': 0.7128638626323317, 'val_loss': 0.6851975975027519}\n",
      "==============================================================\n",
      "{'val_f1': 0.715971848034844, 'val_auroc': 0.7588348850443973, 'val_accuracy': 0.695343922452129, 'val_loss': 0.684315042490364}\n",
      "==============================================================\n",
      "{'val_f1': 0.7249707128382532, 'val_auroc': 0.764970304355763, 'val_accuracy': 0.7054332265971556, 'val_loss': 0.6937418827673142}\n",
      "==============================================================\n",
      "{'val_f1': 0.7072323118261264, 'val_auroc': 0.7576979800599316, 'val_accuracy': 0.6996386938604143, 'val_loss': 0.6874851513407909}\n",
      "==============================================================\n",
      "{'val_f1': 0.7132548566683401, 'val_auroc': 0.7676437449418216, 'val_accuracy': 0.7063194492923124, 'val_loss': 0.6747895663635758}\n",
      "==============================================================\n",
      "Average accuracy: 0.704380467603507\n"
     ]
    }
   ],
   "source": [
    "print(\"==============================================================\")\n",
    "for best in bests:\n",
    "  print(best)\n",
    "  print(\"==============================================================\")\n",
    "print(\"Average accuracy:\", statistics.mean([x['val_accuracy'] for x in bests]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our FFNN has not immediately shown improvements over the earlier statistical experiments. It is possible to perform more precise hypertuning, although at this stage it is unlikely we will see a dramatic increase in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results look good for a benchmark, with just a little variance seen in this data. The following graph shows the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feed-Forward Neural Network Accuracies')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from seaborn import boxplot\n",
    "from pandas import DataFrame\n",
    "boxplot(DataFrame([ff_wv_scores['accuracies']])).set_title(\"Feed-Forward Neural Network Accuracies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feed-Forward Neural Network AUC scores')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAEICAYAAABoLY4BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAFEBJREFUeJzt3Xu0XGV5x/Hvkxwu4aokiBCQiAfkolUB76WAhZqqIFpBEA24RBQliSiiq7oqi4WVVq1C8AZVSbQI6lIUjQlBSQRK1FigCEE5xEASLoXEQCAIJrz9Y7/H7AznkpyZM/OenO9nrVnMvszez7v3nt+8+505IVJKSJI6b0ynC5AkVQxkSSqEgSxJhTCQJakQBrIkFcJAlqRCGMhDFBGTIiJFRFena2mliJgfEad1uo5NsSWdg5F03DV8tshAjoilEfFERDxWe+zR5hpOjYj1DTVc3M4aWi0izs0BeHxtXleeN6lzlfUtXwcPRsT2tXmnRcT8TXz9ZRFx/rAV2KQc4n+KiG36mH9aw7wjImJ5bToiYlpE/C4iHo+I5RHxvYh4cbvq1zNtkYGcHZNS2qH2uK8DNdzUUMOZm7uB4er9NbHdVcB5ETG2lfX0pUX76AKmt2A7wyIH42a/D/MH4GFAAo4dwq4vpDou04BdgP2Aq4A3DmFbTWvH9TQSbMmB3KeIeFVE/HdErI6IWyPiiNqynSPi6xFxf0SsiIjzey+UiBgbEZ+LiIcjYglNXLh5P7Mi4qGIuCciPtn7psw96xsj4gsRsQo4N69zSF7+ztwjPTBPnxYRV+Xnr4iIm3Lb7o+IiyNi69p+U0R8MCLuAu7K846OiDsj4pHcg49Byp8DPAW8s5+2bZOP0725d/rViBhXa9sNDeuniOjOzy+LiK9ExOyIeBw4MiLeGBE3R8SjEbEsIs7dvKPNZ4GzI+JZ/dS7f0TMi4hVEfH7iDghzz8dOBk4J9/dXB0R746Iq2uv7YmI79aml0XES/Pz10TEb/Jx/U1EvKa23vyI+HRE3AisBfZpqGn3iPjfiDh7gHZNARYClwGnbM4BiYh9gQ8CJ6WUfpFSejKltDal9F8ppQv6ec2pEbEkItZExB8j4uTasvdGxOK87I6IODjPPyC3dXVE3B4Rx9Ze09e5HujamRARP8nbWhUR18cQPsiKl1La4h7AUuCoPuZPBFYCb6D6MDo6T++al18FfA3YHngO8GvgfXnZ+4E7gb2oehTXUfVOuvqp4VTghn6WzQJ+BOwITAL+ALyn9rp1wFSq3t24vP5H8vJLgLuBM2rbOis/PwR4VX7dJGAx8KHafhMwL9c/DpgAPAq8DdgKOCvv+7R+6j4X+DZVj2xJfk1X3u6kvM4XgR/nfewIXA18pr9jkl/bnZ9fBjwCvDafn22BI4AX5+m/AR4EjsvrTxrkHCwFjgJ+AJyf550GzM/PtweWAe/O7TgYeBg4qFbP+bXt7QOszrXsDtwDrKgt+1Netkt+/q683ZPy9Pi87nzgXuCgvHyrPO80NlwPpw9yjfcAH8jn/C/AbrVl8xvPYT6Oy2vX8j2b8X7aPl8nL8zTu9eO0fHACuDlVB/m3cDeuU09wD8DWwOvA9bUttHXuR7o2vkM8NW83a2o7g6i01nT8uzqdAHD0qjqjfhYfvOsBq7K8z8GfKth3blUPYzdgCeBcbVlJwHX5ee/AN5fW/YPDB7I62o1rKYKy7F5PwfW1n0fG0LiVODehm29B/hxfr44v3GvyNP3AAf3U8OHgB/WphPwutr0FGBhbTqA5Y1v5tryc4Fv5+e/As6gFsj59Y8DL6i95tXAH2ttGyyQZw1ybr8IfCE/nzTIOVhKFcgvym/+Xdk4kN8OXN/wmq8Bn6rVc37D8mVUwX0i1Yfjr4H9qUK99xy9C/h1w+tuAk7Nz+cD5zUsnw/8R675pEGOwd9ShfCEPH0n+UO5tq2BAvkT9fO+Ce+n7amu33+i9v6ovX+m9/Gaw4AHgDG1ed8Bzu3rXG/CtXMeVSeme1PrHomPLa/Lv8FxKaVn5cdxed7ewPH5tmd1RKymurh3Z8On+v21ZV+j6ikD7EH1Zux1T++TiDgsNnxxd3ttnYW1Gp6VUlpI1Svduv76/Hxibbq+H4AFwGER8VyqQL8SeG1U44g7A7fkOvbLt3UPRMSjwL/m/dXVt71Rm1J15Tfuuz+fpHpjb1ubtyuwHfDb2jGck+dvqo32HxGvjIjrohreeYSqd9fYpgGllH4H/AT4eMOivYFXNlwPJwPPHWBzC6jC7e/y8/nA4fmxIK+zBxufXxj8HJP3vQL4/sAt4hTgmpTSw3n6cjYetlhHdS3XbUUV4lDdFe4+yD7+KqX0ONWH1/up3h8/jYj98+K9qO7YGu0BLEspPV2bN9AxGOza+SxVj/uaPHTSeC63CFtyIPdlGVUPuR6S26dq3GwZVc91Qm3ZTimlg/Jr76e6+Ho9r/dJSun6tOGLu4MY2MNUb4y9G7a1oja90T/Bl1LqoRprnAb8MqW0hqr3cTpVj7P3ov8KVW9p35TSTlS3i41jwvVtb9SmiIiGNvYrpTSPDbfN9bY9QXU723sMd04p7ZCXP071puvdX1/B1/jPD15OdRu7V0ppZ6rb1sHGufvyKeC9PDMQFjRcDzuklM7opxbYEMiH5ecLeGYg38fG5xcGOcfZuVTH8PLo50uuPKZ6AnB4/uB9gGqo6SUR8ZK82r1Udw91z2fDh8TPgT0j4tC+9tGXlNLclNLRVEF+J3BpXrQMeEEfL7kP2KthnHegYzDgtZNSWpNS+khKaR/gGODDEfH3m1r/SDHaAvnbwDER8fqovqTbNqqfA+2ZUrofuAb4fETsFBFjIuIFEXF4fu13gWkRsWdEPJtn9rY2SUppfd7WpyNix4jYG/hwrm0gC4Az2fCmn98wDdW426PAY7kHcwYD+ylwUES8NapfXUxj4N5ho08A5/RO5A+GS4EvRMRzACJiYkS8Pq9ya97fSyNiW6oAGsyOwKqU0p8j4hXAOzajvr/KH2pXUrWx10+A/SLiXRGxVX68PCIOyMsfpOELN6rjfSTVrfty4HpgMjAeuDmvMztv9x1R/Szw7cCBeX8D+QvVmOz2wLf6+dLqOGB93t5L8+OAXMeUvM6VwLuj+pI3ImI/qtC+Ih+Lu4AvA9/J1//W+b1wYl89z4jYLSKOjerng09SDQeuz4v/k+pL00PyvrrzNf0rqg/gc/JxPYIqSK/oq+GDXTsR8aa87aC6xtfXathijKpATiktA95M1XN8iOrT/aNsOA5TqIYT7qD6Eub7bLi1u5RqvOxW4H+ovigaqqlUF+sS4AaqXuA3BnnNAqpw+mU/0wBnUwXWmlzvlQNtMN/yHg9cQHUbuy9w46Y2IqV0I9UYat3HqHrOC/OwybXAC/P6f6AaC7yW6lceNzC4D1D9zG4N8C9UH2ZDdR5V2PXWv4bqu4ATqXp0DwD/BvT+rvfrwIH5FvqqWhseowpAUkqPUp3HG/OHLSmllcCbgI9QHddzgDfVhhj6lVJ6Cngr1VDZN/oI5VOAb6aU7k0pPdD7AC4GTo6IrpTSXKoOwzepxs5nAzOpxrx7Tcuv+RLV+PDdwFuovkhrNCa35T6qnz0eTr4zSil9D/g01TW8huqL8V1yO44F/pGq9/tlYEpK6c4Bmt/vtUN1bV5LdexvAr6cUpo/wLZGpKiGDSVJnTaqesiSVDIDWZIKYSBLUiEMZEkqxGb9AzMTJkxIkyZNGqZSJGnLM2HCBObOnTs3pTR5sHU3K5AnTZrEokWLhl6ZJI1CEbFJf13qkIUkFcJAlqRCGMiSVAgDWZIKYSBLUiEMZEkqhIEsSYUwkCWpEAayJBXCQJakQhjIklQIA1mSCmEgS1IhDGRJKoSBLEmFMJAlqRAGsiQVwkCWpEIYyJJUiM36f+pJao8ZM2bQ09PT6TKGbMWKFQBMnDixpdvt7u5m6tSpLd1mSQxkqUA9PT3c8rvFrN9ul06XMiRj1z4CwANPti5ixq5d1bJtlcpAlgq1frtdeGL/N3S6jCEZd+dsgJbW37vNLZljyJJUCANZkgphIEtSIQxkSSqEgSxJhTCQJakQBrIkFcJAlqRCGMiSVAgDWZIKYSBLUiEMZEkqhIEsSYUwkCWpEAayJBXCQJakQhjIklQIA1mSCmEgS1IhDGRJKoSBLEmFMJAlqRAGsiQVwkCWpEIYyJJUCANZkgphIEtSIQxkSSqEgSxJhTCQJakQBrIkFcJAlqRCGMiSVAgDWZIKYSBLUiEMZEkqhIEsSYUwkCWpEAayJBXCQJakQhjIklQIA1lqsRkzZjBjxoxOl6EWaef57GrLXqRRpKenp9MlqIXaeT7tIUtSIQxkSSqEgSxJhTCQJakQBrIkFcJAlqRCGMiSVAgDWZIKYSBLUiEMZEkqhIEsSYUwkCWpEAayJBXCQJakQhjIklQIA1mSCmEgS1IhDGRJKoSBLEmFMJAlqRAGsiQVwkCWpEIYyJJUCANZkgphIEtSIQxkSSqEgSxJhTCQJakQBrIkFcJAlqRCGMiSVAgDWZIKYSBLUiEMZEkqhIEsSYUwkCWpEAayJBXCQJakQrQlkFeuXMm0adNYuXJlO3YnSSNSWwJ55syZ3HbbbcyaNasdu5OkEWnYA3nlypXMmTOHlBJz5syxlyxJ/ega7h3MnDmTp59+GoD169cza9YszjrrrOHerdQxK1as4IknnmD69OlD3kZPTw9jnkotrGrkG/PnR+npWdPUcR2Knp4exo0b15Z9DdpDjojTI2JRRCx66KGHNnsH1157LevWrQNg3bp1zJs3b/OrlKRRYNAeckrpEuASgEMPPXSzP7KPOuooZs+ezbp16+jq6uLoo48eQpnSyDFx4kQALrzwwiFvY/r06fx2yYOtKmmL8PS2O9G9z25NHdehaGePfNjHkE855RTGjKl2M3bsWKZMmTLcu5SkEWnYA3n8+PFMnjyZiGDy5MmMHz9+uHcpSSPSsH+pB1UveenSpfaOJWkAbQnk8ePHc9FFF7VjV5I0Yvmn05JUCANZkgphIEtSIQxkSSqEgSxJhTCQJakQBrIkFcJAlqRCGMiSVAgDWZIKYSBLUiEMZEkqhIEsSYUwkCWpEAayJBXCQJakQhjIklQIA1mSCmEgS1IhDGRJKoSBLEmFMJAlqRAGsiQVwkCWpEIYyJJUCANZkgphIEtSIQxkSSqEgSxJhTCQJakQBrIkFcJAlqRCGMiSVAgDWZIKYSBLUiEMZEkqhIEsSYUwkCWpEF2dLkDa0nR3d3e6BLVQO8+ngSy12NSpUztdglqonefTIQtJKoSBLEmFMJAlqRAGsiQVwkCWpEIYyJJUCANZkgphIEtSIQxkSSqEgSxJhTCQJakQBrIkFcJAlqRCGMiSVAgDWZIKYSBLUiEMZEkqhIEsSYUwkCWpEAayJBXCQJakQhjIklQIA1mSCmEgS1IhDGRJKoSBLEmFMJAlqRAGsiQVwkCWpEIYyJJUCANZkgphIEtSIQxkSSqEgSxJhTCQJakQBrIkFcJAlqRCGMiSVAgDWZIKYSBLUiG6Ol2ApL6NXbuKcXfO7nQZQzJ27UqAltY/du0qYLeWba9EBrJUoO7u7k6X0JQVK9YBMHFiKwN0txF/XAZjIEsFmjp1aqdLUAc4hixJhTCQJakQBrIkFcJAlqRCGMiSVAgDWZIKYSBLUiEMZEkqhIEsSYUwkCWpEAayJBXCQJakQhjIklQIA1mSCmEgS1IhDGRJKoSBLEmFMJAlqRAGsiQVwkCWpEJESmnTV454CLhn+MrpuAnAw50uogNGa7th9LZ9tLYb2t/2hwFSSpMHW3GzAnlLFxGLUkqHdrqOdhut7YbR2/bR2m4ou+0OWUhSIQxkSSqEgbyxSzpdQIeM1nbD6G37aG03FNx2x5AlqRD2kCWpEAayJBVi1ARyREyOiN9HRE9EfLyfdU6IiDsi4vaIuLxh2U4RsSIiLm5Pxa3RTLsjYn1E3JIfP25f1c1rst3Pi4hrImJxXj6pXXW3wlDbHhFH1s73LRHx54g4rr3VD12T5/zf87zFEXFRRET7Kq9JKW3xD2AscDewD7A1cCtwYMM6+wI3A8/O089pWH4hcDlwcafb0652A491ug0davd84Oj8fAdgu063qV1tr62zC7BqpLS9mXYDrwFuzNsYC9wEHNGJdoyWHvIrgJ6U0pKU0lPAFcCbG9Z5L/CllNKfAFJK/9e7ICIOAXYDrmlTva3SVLtHsCG3OyIOBLpSSvPy/MdSSmvbV3rTWnXO3wb8bAS1vZl2J2BbqiDfBtgKeLAtVTcYLYE8EVhWm16e59XtB+wXETdGxMKImAwQEWOAzwMfbUulrTXkdmfbRsSiPH/E3LrSXLv3A1ZHxA8i4uaI+GxEjG1Dza3S7DnvdSLwnWGqcTgMud0ppZuA64D782NuSmlxG2p+hq5O7LQD+hoPavy9XxfVLc0RwJ7A9RHxIuCdwOyU0rJODSs1YcjtTimtBp6XUrovIvYBfhERt6WU7h7WilujmfPdBRwGvAy4F7gSOBX4+jDV2mrNnnMiYnfgxcDcYayz1Zo55xOAA/I8gHkR8XcppV8OU639Gi095OXAXrXpPYH7+ljnRymlv6SU/gj8nurkvRo4MyKWAp8DpkTEBcNfcks0025SSvfl/y6hGld92XAX3CLNtHs5cHO+9V0HXAUc3IaaW6Wpc56dAPwwpfSXYa20tZpp91uAhXl46jHgZ8Cr2lDzM3V6ML4dD6pPxiXA89kw4H9QwzqTgZn5+QSq25/xDeucysj6Um/I7QaeDWxTm38XDV+SlPpost1j8/q75mXfBD7Y6Ta1o+215QuBIzvdljae87cD1+ZtbAX8HDimE+0YFT3kVPV0zqS6BVsMfDeldHtEnBcRx+bV5gIrI+IOqvGkj6aUVnam4tZost0HAIsi4tY8/4KU0h3tb8Xma6bdKaX1wNnAzyPiNqpb4Uvb34qhafZazz/x2wtY0O7am9Fku79P9QuN26iC/NaU0tVtbwT+6bQkFWNU9JAlaSQwkCWpEAayJBXCQJakQhjIklQIA1mSCmEgS1Ih/h+4BGnfer7yPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(DataFrame([ff_wv_scores['auc']])).set_title(\"Feed-Forward Neural Network AUC scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feed-Forward Neural Network F1 scores')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(DataFrame([ff_wv_scores['f1-score']])).set_title(\"Feed-Forward Neural Network F1 scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one outlier in our results, the second cross validation. For this validation it is actually more accurate than the others, but for the AUC and F1 score it is slightly lower. It's not a very distant outlier, so it appears that this is a suitable benchmark for Feed-Forward neural networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
