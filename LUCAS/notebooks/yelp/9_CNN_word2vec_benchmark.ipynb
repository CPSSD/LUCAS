{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network Benchmark\n",
    "\n",
    "To obtain a benchmark for a basic convolutional network, we will create a simple network that informs us what to expect when using these networks. This will not contain any novel specializations, it is done to find a baseline which we can improve upon.\n",
    "\n",
    "The architecture used here is inspired by the research in the form of the paper ['A Sensitivity Analysis of (and Practitionersâ€™ Guide to) Convolutional Neural Networks for Sentence Classification'](https://arxiv.org/pdf/1510.03820.pdf), and is not complex.\n",
    "\n",
    "While previous experiments have been done to find applicability of convolutional networks, this is the first to run it over a large set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from exp8_feature_extraction import get_balanced_dataset\n",
    "from scripts.cross_validate import run_cross_validate\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pickle\n",
    "from seaborn import boxplot\n",
    "from pandas import DataFrame\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = get_balanced_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_contents = [x.review_content for x in all_reviews]\n",
    "labels = [1 if x.label else 0 for x in all_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_words = 150\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(short_reviews)\n",
    "\n",
    "short_sequences = []\n",
    "short_labels = []\n",
    "for i, sequence in enumerate(tokenizer.texts_to_sequences(reviews_contents)):\n",
    "    if len(sequence) <= max_review_words:\n",
    "        short_sequences.append(sequence)\n",
    "        short_labels.append(labels[i])\n",
    "        \n",
    "word_sequences = np.array(pad_sequences(short_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words = tokenizer.word_index\n",
    "corpus_vocab_size = len(corpus_words)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(\"../../data/GoogleNews-vectors-negative300.bin\",\n",
    "                                                             binary=True)\n",
    "embedding_length = word_vectors.vector_size\n",
    "\n",
    "embedding_matrix = np.zeros((corpus_vocab_size, embedding_length))\n",
    "for word, index in corpus_words.items():\n",
    "  if word in word_vectors.vocab:\n",
    "    embedding_matrix[index] = np.array(word_vectors[word], dtype=np.float32)\n",
    "\n",
    "with open(embeddings_file_name, 'w') as outfile:\n",
    "  json.dump(embedding_matrix.tolist(), outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a quick check to make sure any modifications haven't caused our sequences and embedding matrix to misalign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hello_wv = embedding_matrix[tokenizer.texts_to_sequences([\"hello\"])[0][0]]\n",
    "assert hello_wv[0] > -0.055 and hello_wv[0] < -0.054\n",
    "assert hello_wv[1] > 0.017 and hello_wv[1] < 0.018\n",
    "assert hello_wv[2] > -0.006 and hello_wv[2] < -0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vectorized_reviews(word_sequences, max_review_len, embedding_matrix):\n",
    "    vectorized_reviews = np.zeros((len(word_sequences), max_review_len, embedding_matrix.shape[1], 1))\n",
    "    for i, word_sequence in enumerate(word_sequences):\n",
    "        for j, word in enumerate(word_sequence):\n",
    "            for k, val in enumerate(embedding_matrix[word]):\n",
    "                vectorized_reviews[i][j][k][0] = val\n",
    "    return vectorized_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add quick tests for our vectorizing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding_matrix = np.array([[1, 2, 3], [3, 2, 1]])\n",
    "\n",
    "actual_vectorized_reviews = to_vectorized_reviews([[0, 1]], 2, test_embedding_matrix)\n",
    "assert np.array_equal(actual_vectorized_reviews, np.array([[[[1], [2], [3]], [[3], [2], [1]]]]))\n",
    "\n",
    "actual_vectorized_reviews = to_vectorized_reviews([[1, 0]], 2, test_embedding_matrix)\n",
    "assert np.array_equal(actual_vectorized_reviews, np.array([[[[3], [2], [1]], [[1], [2], [3]]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_reviews = to_vectorized_reviews(word_sequences, len(word_sequences[0]), embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will separate some data, holding it until after I have finished tweaking the model. This is because tweaking the model towards the data I'm testing against is likely to cause a misrepresentation of how well the model performs. Using unseen data is better representative of future unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_vectors = vectorized_reviews[:-10000]\n",
    "training_labels = short_labels_2[:-10000]\n",
    "held_vectors = vectorized_reviews[-10000:]\n",
    "held_labels = short_labels_2[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_wv_model():\n",
    "  model = Sequential([\n",
    "      Conv2D(\n",
    "          filters=50,\n",
    "          kernel_size=(10, 300),\n",
    "          data_format=\"channels_last\",\n",
    "          input_shape=(max_review_words, 300, 1),\n",
    "          activation=relu),\n",
    "      tf.keras.layers.GlobalMaxPooling2D(data_format=\"channels_last\"),\n",
    "      Dropout(0.5),\n",
    "      Flatten(),\n",
    "      Dense(2, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_wv_scores = run_cross_validate(get_conv_wv_model, training_vectors, training_labels, cv=6, categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracies': [0.66613211939372, 0.6612177331746935, 0.6639077130029282, 0.6568368772311035, 0.654612240674634, 0.6592684567230587]}\n",
      "Average accuracy: 0.6603291900333562\n"
     ]
    }
   ],
   "source": [
    "print(conv_wv_scores)\n",
    "print(\"Average accuracy:\", sum(conv_wv_scores['accuracies'])/len(conv_wv_scores['accuracies']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional networks perform significantly better than FFNNs and the results are not widely varying. This appears to be a confident benchmark for a simple convolutional network.\n",
    "\n",
    "The distribution of results is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(DataFrame(conv_wv_scores)).set_title(\"Convolutional Network Accuracies\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the model on unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81186 samples, validate on 34794 samples\n",
      "Epoch 1/12\n",
      "81186/81186 [==============================] - 137s 2ms/step - loss: 0.6485 - acc: 0.6256 - val_loss: 0.6260 - val_acc: 0.6526\n",
      "Epoch 2/12\n",
      "81186/81186 [==============================] - 136s 2ms/step - loss: 0.6242 - acc: 0.6541 - val_loss: 0.6272 - val_acc: 0.6517\n",
      "Epoch 3/12\n",
      "81186/81186 [==============================] - 136s 2ms/step - loss: 0.6081 - acc: 0.6727 - val_loss: 0.6189 - val_acc: 0.6581\n",
      "Epoch 4/12\n",
      "81186/81186 [==============================] - 135s 2ms/step - loss: 0.5940 - acc: 0.6828 - val_loss: 0.6121 - val_acc: 0.6670\n",
      "Epoch 5/12\n",
      "81186/81186 [==============================] - 136s 2ms/step - loss: 0.5795 - acc: 0.6974 - val_loss: 0.6121 - val_acc: 0.6675\n",
      "Epoch 6/12\n",
      "81186/81186 [==============================] - 136s 2ms/step - loss: 0.5644 - acc: 0.7110 - val_loss: 0.6200 - val_acc: 0.6597\n",
      "Epoch 7/12\n",
      "81186/81186 [==============================] - 136s 2ms/step - loss: 0.5502 - acc: 0.7193 - val_loss: 0.6173 - val_acc: 0.6630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc80748d320>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "conv_model = get_conv_wv_model()\n",
    "conv_model.fit(training_vectors, to_categorical(training_labels), epochs=12, batch_size=128, validation_split=0.3,\n",
    "               callbacks=[EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_labels = to_categorical(held_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 609us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6657"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.evaluate(held_vectors, categorical_labels)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_metric = tf.metrics.auc(categorical_labels, conv_model.predict(held_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf auc: [9999999000.0, 0.72368735]\n"
     ]
    }
   ],
   "source": [
    "auc, update_op = auc_metric\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    print(\"tf auc: {}\".format(sess.run([auc, update_op])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs very similarly on the unseen data as the data used to create the model. There was not a lot of tweaking, so it is not unreasonable that this should occur. If this can be maintained then this model could do well with slight changes in the domain, something very easy to do with product and service reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
