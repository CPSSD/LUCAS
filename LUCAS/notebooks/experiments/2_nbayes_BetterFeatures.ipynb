{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following experiment 1, we now want to try to find better features. This will take inspiration from existing research done at Stanford. We will derive the same features and attempt to replicate the same benchmark as them. [Paper here](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwjf1Pbo6ZveAhUKBsAKHbeSAicQFjAAegQIBhAC&url=http%3A%2F%2Fcs229.stanford.edu%2Fproj2017%2Ffinal-reports%2F5229663.pdf&usg=AOvVaw1SAoqP8hAkRiRJH9lwmeEn)\n",
    "\n",
    "This notebook has been heavily unit tested, and as a result a lot of code has been removed from the notebook itself. I have demonstrated as much as possible through importing units and running them on example values.\n",
    "\n",
    "First the same setup as Experiment 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from protos import review_set_pb2, review_pb2\n",
    "review_set = review_set_pb2.ReviewSet()\n",
    "with open(\"data/yelpNYC\", 'rb') as f:\n",
    "  review_set.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp2_feature_extraction import find_words\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "num_each_class = 8141\n",
    "reviews = shuffle(review_set.reviews)\n",
    "\n",
    "i = 0\n",
    "fake_reviews = []\n",
    "for x in reviews:\n",
    "  if i == num_each_class:\n",
    "    break\n",
    "  if x.label:\n",
    "    fake_reviews.append(x)\n",
    "    i+=1\n",
    "\n",
    "i = 0\n",
    "genuine_reviews = []\n",
    "for x in reviews:\n",
    "  if i == num_each_class:\n",
    "    break\n",
    "  if x.label == False:\n",
    "    fake_reviews.append(x)\n",
    "    i+=1\n",
    "    \n",
    "all_reviews = [(x, find_words(x.review_content)) for x in shuffle(fake_reviews + genuine_reviews)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16282\n"
     ]
    }
   ],
   "source": [
    "print(len(all_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first features will be the structural features. These are:\n",
    "* Length of the review\n",
    "* Average word length\n",
    "* Number of sentences\n",
    "* Average sentence length\n",
    "* Percentage of numerals\n",
    "* percentage of capitalized words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 5.5, 2, 26.0, 0.25, 0.25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exp2_feature_extraction import structural_features\n",
    "\n",
    "review = review_pb2.Review()\n",
    "review.review_content = \"1 very horrible restaurant. Eat 10 Starbucks instead.\"\n",
    "structural_features((review, [\"1\", \"very\", \"horrible\", \"restaurant\", \"Eat\", \"10\", \"Starbucks\", \"instead\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_structural = [structural_features(x) for x in all_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the Part of Speech features. There are 36 part of speech categories. Descriptions can be found [here](https://medium.com/@gianpaul.r/tokenization-and-parts-of-speech-pos-tagging-in-pythons-nltk-library-2d30f70af13b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, '0.3333333333333333'),\n",
       " (11, '0.3333333333333333'),\n",
       " (35, '0.3333333333333333')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from exp2_feature_extraction import pos_features\n",
    "\n",
    "sample_pos_features = pos_features([\"Dog\", \"and\", \"beautiful\"], nltk)\n",
    "[(i, str(sample_pos_features[i])) for i in range(0, len(sample_pos_features)) if sample_pos_features[i] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here 5 is JJ, which is for adjective. This represents \"beautiful\" in the input. 11 is NNP, which is proper noun, which represents \"Dog\". 35 is CC which is coordinating conjuction, which is \"and\". These are given as percentages, where each here is one third."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pos = [pos_features(x[1], nltk) for x in all_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next are sentiment features. These will be:\n",
    "* Percentage of words that have positive sentiment\n",
    "* Percentage of words that have negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "none: 0.0\n",
      "good: 0.4404\n",
      "bad: -0.5423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/envs/lucas/lib/python3.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "print(\"Scores:\")\n",
    "print(\"none:\", sentiment_analyzer.polarity_scores(\"none\")[\"compound\"])\n",
    "print(\"good:\", sentiment_analyzer.polarity_scores(\"good\")[\"compound\"])\n",
    "print(\"bad:\", sentiment_analyzer.polarity_scores(\"bad\")[\"compound\"])\n",
    "\n",
    "from exp2_feature_extraction import sentiment_features\n",
    "sentiment_features([\"good\", \"good\", \"none\", \"bad\"], sentiment_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sentiment = [sentiment_features(x[1], sentiment_analyzer) for x in all_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the topic model features from LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform some data cleaning, which will improve our results when generating LDA topics. This cleaning is stemming and lemmatization, and removing words with three or less characters.\n",
    "\n",
    "### Stemming and Lemmatization\n",
    "\n",
    "Stemming will reduce a word to a 'stem' form, which can be used to normalise words that mean the same thing. For example 'cleanly' and 'cleanest' would be stemmed to 'clean'. Lemmatization uses a vocabulary and morphological analysis to more intelligently normalise words, for example 'car' and 'automobile' could go to 'vehicle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gonna', 'stay', 'coffe', 'littl', 'store', 'happili', 'surpris']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exp2_feature_extraction import preprocess_words\n",
    "preprocess_words([\"I\", \"was\", \"gonna\", \"just\", \"stay\", \"in\", \"for\", \"coffee\", \"but\", \"this\", \"little\", \"store\", \"happily\", \"surprised\", \"me\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "def get_topic_features_maker(reviews, num_topics=100, bigrams=False):\n",
    "  preprocessed_words = [preprocess_words(x[1], bigrams=bigrams) for x in reviews]\n",
    "  \n",
    "  dictionary = gensim.corpora.Dictionary(preprocessed_words)\n",
    "  dictionary.filter_extremes(no_below=15, no_above=0.33, keep_n=100000)\n",
    "  bow_corpus = [dictionary.doc2bow(doc) for doc in preprocessed_words]\n",
    "  lda_model = gensim.models.ldamodel.LdaModel(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=2)\n",
    "    \n",
    "  def make_topic_features(review_words):\n",
    "    topics = lda_model.get_document_topics(dictionary.doc2bow(preprocess_words(review_words, bigrams=bigrams)))\n",
    "    return topic_features(topics, num_topics)\n",
    "\n",
    "  def get_terms(topic_id):\n",
    "    return [dictionary.id2token[x[0]] + \" \" + str(x[1]) for x in lda_model.get_topic_terms(topic_id)]\n",
    "  return (make_topic_features, get_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/envs/lucas/lib/python3.7/site-packages/gensim/models/ldamodel.py:775: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    }
   ],
   "source": [
    "topic_features_maker, get_topic_terms = get_topic_features_maker(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topic_terms(term_frequencies, term_getter):\n",
    "  for topic_id in range(0, len(term_frequencies)):\n",
    "    if term_frequencies[topic_id] > 0:\n",
    "      print(\"----- Topic\", topic_id)\n",
    "      print(\"\\n\".join(term_getter(topic_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Topic 22\n",
      "noodl 0.096852325\n",
      "broth 0.05096265\n",
      "bowl 0.045923855\n",
      "pork 0.03812034\n",
      "flavor 0.028089475\n",
      "like 0.02164319\n",
      "soup 0.019695487\n",
      "cook 0.018089803\n",
      "beef 0.016119294\n",
      "textur 0.015956793\n",
      "----- Topic 51\n",
      "pizza 0.32059258\n",
      "crust 0.05568068\n",
      "slice 0.049427867\n",
      "artichok 0.029564379\n",
      "best 0.027534088\n",
      "oven 0.02168064\n",
      "chees 0.02072949\n",
      "fresh 0.015081689\n",
      "tast 0.014505719\n",
      "basil 0.014213047\n",
      "----- Topic 60\n",
      "ramen 0.16034897\n",
      "ippudo 0.049952243\n",
      "spici 0.048881866\n",
      "wait 0.043555398\n",
      "burrito 0.028100757\n",
      "mexican 0.025394771\n",
      "extra 0.022398656\n",
      "miso 0.020769633\n",
      "best 0.019556362\n",
      "worth 0.019325428\n",
      "----- Topic 63\n",
      "pasta 0.056896374\n",
      "ravioli 0.04104559\n",
      "risotto 0.035842206\n",
      "spaghetti 0.03391445\n",
      "foie 0.029736236\n",
      "gras 0.027632628\n",
      "gelato 0.022858901\n",
      "like 0.022318793\n",
      "sauc 0.02117488\n",
      "polenta 0.019895256\n"
     ]
    }
   ],
   "source": [
    "from exp2_feature_extraction import topic_features\n",
    "\n",
    "words = [\"Pizza\", \"Pasta\", \"Ramen\", \"Noodles\"]\n",
    "tf = topic_features_maker(words)\n",
    "print_topic_terms(tf, get_topic_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_unigram_topic = [topic_features_maker(x[1]) for x in all_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_topic_features_maker, get_topic_terms = get_topic_features_maker(all_reviews, bigrams=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Topic 5\n",
      "dish come 0.07545652\n",
      "good pizza 0.06775505\n",
      "leav hungri 0.060532913\n",
      "food recommend 0.042339265\n",
      "food spici 0.042271245\n",
      "moment walk 0.040766425\n",
      "place peopl 0.038288265\n",
      "reserv tabl 0.035552364\n",
      "look nice 0.034365393\n",
      "pizza brooklyn 0.033186343\n",
      "----- Topic 61\n",
      "fri chicken 0.24945906\n",
      "feel like 0.23236562\n",
      "scrambl egg 0.02751178\n",
      "poor servic 0.02662584\n",
      "walk door 0.02419437\n",
      "dinner drink 0.023946911\n",
      "hollandais sauc 0.021571178\n",
      "nice wine 0.019685354\n",
      "romant dinner 0.019272646\n",
      "like come 0.019226033\n"
     ]
    }
   ],
   "source": [
    "words = [\"Fried\", \"Chicken\", \"Pizza\", \"Slice\"]\n",
    "tf2 = bigram_topic_features_maker(words)\n",
    "print_topic_terms(tf2, get_topic_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_bigram_topic = [bigram_topic_features_maker(x[1]) for x in all_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will find the reviewer features. This includes:\n",
    "* The maximum number of reviews in a day\n",
    "* average review length\n",
    "* standard deviation of reviewer's ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6.0, 1.4142135623730951, 0.5, 0.5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exp2_feature_extraction import reviewer_features\n",
    "\n",
    "review1 = review_pb2.Review()\n",
    "review1.review_content=\"1234\"\n",
    "review1.date=\"2018-11-12\"\n",
    "review1.rating=2\n",
    "\n",
    "review2 = review_pb2.Review()\n",
    "review2.review_content=\"12345678\"\n",
    "review2.date=\"2018-11-12\"\n",
    "review2.rating=4\n",
    "\n",
    "user_id = 1234\n",
    "reviewer_map = {\n",
    "    user_id: [review1, review2]\n",
    "}\n",
    "\n",
    "reviewer_features(user_id, reviewer_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, our first feature is the number of reviews on this day (2), the average review length (6.0) and the standard devation of our ratings (1.41...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp2_feature_extraction import reviews_by_reviewer\n",
    "reviews_reviewer_map = reviews_by_reviewer([x[0] for x in all_reviews])\n",
    "features_reviewer = [reviewer_features(x[0].user_id, reviews_reviewer_map) for x in all_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put our features together:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "\n",
    "We normalise all our features to be between one and zero. We need to do this to suppress the mega features vs tiny features situation. Most classifiers use Euclidian distance, which has no knowledge of the units being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def features_row(review, reviews_reviewer_map, sentiment_analyzer, pos_tagger, make_topic_features):\n",
    "#  words = find_words(review.review_content)\n",
    "#  row = list(structural_features(review))\n",
    "#  row += list(sentiment_features(words, sentiment_analyzer))\n",
    "#  row += pos_features(words, pos_tagger)\n",
    "#  row += make_topic_features(words)\n",
    "#  row += list(reviewer_features(review, reviews_reviewer_map))\n",
    "#  return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I include a test to check my features are generated correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t():\n",
    "  \"\"\"\n",
    "from unittest.mock import Mock\n",
    "\n",
    "review = review_pb2.Review()\n",
    "review.review_content = \"1 really horrible restaurant. Drink 10 Starbucks instead.\"\n",
    "review.user_id = 1\n",
    "review.date = \"2011-07-28\"\n",
    "review.rating = 5\n",
    "\n",
    "review2 = review_pb2.Review()\n",
    "review2.review_content = \"example\"\n",
    "review2.user_id = 1\n",
    "review2.date = \"2011-07-28\"\n",
    "review2.rating = 4\n",
    "\n",
    "test_reviews_reviewer_map = {\n",
    "    1: [review, review2]\n",
    "}\n",
    "\n",
    "def analyze_sentiment(word):\n",
    "  score = 0.0\n",
    "  if word == \"1\":\n",
    "    score = 0.1\n",
    "  if word in [\"horrible\", \"instead\"]:\n",
    "    score = -0.5\n",
    "  return { \"compound\": score }\n",
    "\n",
    "test_sentiment_analyzer = Mock()\n",
    "test_sentiment_analyzer.polarity_scores = analyze_sentiment\n",
    "\n",
    "def tag(words):\n",
    "  tag_map = {\n",
    "    \"really\": \"CD\", \"horrible\": \"DT\", \"restaurant\": \"CD\", \"Drink\": \"FW\", \"Starbucks\": \"JJ\"\n",
    "  }\n",
    "  return [(x, tag_map[x]) for x in [y for y in words if y in tag_map] if x]\n",
    "\n",
    "test_pos_tagger = Mock()\n",
    "test_pos_tagger.pos_tag = tag\n",
    "\n",
    "test_make_topic_features = lambda x: [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "row = features_row(review, test_reviews_reviewer_map, test_sentiment_analyzer, test_pos_tagger, test_make_topic_features)\n",
    "\n",
    "# Structural features\n",
    "assert row[0] == 57\n",
    "assert row[1] == 6\n",
    "assert row[2] == 2\n",
    "assert row[3] == 28.0\n",
    "assert row[4] == 0.25\n",
    "assert row[5] == 0.25\n",
    "# Sentiment features\n",
    "assert row[6] == 0.125 # 1/8\n",
    "assert row[7] == 0.25  # 2/8\n",
    "# POS features\n",
    "assert row[8:44] == [0.4, 0.2, 0.0, 0.2, 0.0, 0.2] + [0.0] * 30\n",
    "# Topic features (This is not testing much as it doesn't use the real thing)\n",
    "assert row[44:49] == [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# Reviewer features\n",
    "assert row[49] == 2\n",
    "assert row[50] == 32\n",
    "assert float(\"%0.2f\"%row[51]**2) == 0.5\n",
    "  \"\"\"\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, hstack\n",
    "predictor_features = hstack([coo_matrix(features_structural), coo_matrix(features_sentiment), coo_matrix(features_pos),\n",
    "                             coo_matrix(features_unigram_topic), coo_matrix(features_bigram_topic),\n",
    "                             coo_matrix(features_reviewer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [x[0].label for x in all_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "cnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01776314, 0.01655006, 0.01647902, 0.01409626, 0.01379395]),\n",
       " 'score_time': array([0.00212693, 0.00185037, 0.00241184, 0.0020442 , 0.00201035]),\n",
       " 'test_score': array([0.60128913, 0.58998771, 0.5970516 , 0.60012285, 0.60042998])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cross_validate(cnb, predictor_features, targets, cv=5, return_train_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not seem to be able to replicate the results from the paper. Adding more topics for bigrams/unigrams seems to have virtually no difference. Using bigrams alone for lda topics seems to improve by 0.01. By splitting unigrams and bigrams to be modelled by different LDA we can get about + 0.005.\n",
    "\n",
    "Based on the paper, the possible differences are:\n",
    "\n",
    "* Structural features - Very clear, difficult to get wrong\n",
    "* POS Percentages - perhaps another POS tagger could improve results. We are using one from nltk, but there are alternatives\n",
    "* Semantic features - perhaps another Semantic tagger could improve results, but it's hard to imagine it being that much better at tagging\n",
    "* Unigram / Bigram features - It's not very obvious exactly what they're doing. Maybe a better LDA topic modeller could be used? The paper claims that high accuracy can be obtained through just unigrams and bigrams, so this could be tried too.\n",
    "* Reviewer features - all very clear, difficult to get this wrong.\n",
    "\n",
    "Let's try with just Unigrams/Bigrams to see how accurate we are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_accuracy(features):\n",
    "  predictor_features = hstack([coo_matrix(x) for x in features])\n",
    "  naive_bayes = MultinomialNB()\n",
    "  fold = 5\n",
    "  results = cross_validate(naive_bayes, predictor_features, targets, cv=fold, return_train_score=False)\n",
    "  return sum([x for x in results['test_score']])/fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111660505306914"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy([features_unigram_topic, features_bigram_topic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of interest, let's try training with only our other features to see how predictive they are alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.566699735898631"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy([features_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5937844549723004"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_features_structural_only = hstack([coo_matrix(features_structural)])\n",
    "cnb_structural_only = MultinomialNB()\n",
    "cross_validate(cnb_structural_only, predictor_features_structural_only, targets, cv=5, return_train_score=False)\n",
    "avg_accuracy([features_structural])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5205757364597143"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy([features_sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6142977105684289"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy([features_reviewer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears as though our best predicting features are the reviewer features. Let's try combining them with the next best features, unigrams/bigrams. To avoid swamping the reviewer features, we will reduce our topics to a small number, 10 each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Topic 0\n",
      "dish 0.04223491\n",
      "flavor 0.011829933\n",
      "thai 0.011820312\n",
      "order 0.010700842\n",
      "dessert 0.010402134\n",
      "delici 0.010185039\n",
      "perfect 0.009887086\n",
      "cook 0.009617706\n",
      "rice 0.009331908\n",
      "duck 0.008528771\n",
      "----- Topic 1\n",
      "wait 0.027837483\n",
      "ramen 0.026999397\n",
      "brunch 0.022529101\n",
      "pork 0.019509893\n",
      "noodl 0.016152045\n",
      "love 0.014694691\n",
      "soup 0.014545276\n",
      "egg 0.014516102\n",
      "come 0.0124907475\n",
      "delici 0.011654576\n",
      "----- Topic 2\n",
      "sandwich 0.026573358\n",
      "sauc 0.021678047\n",
      "fri 0.02104345\n",
      "pancak 0.014249963\n",
      "pork 0.013925266\n",
      "chicken 0.012638441\n",
      "delici 0.0113640465\n",
      "love 0.011248021\n",
      "like 0.010264614\n",
      "meat 0.009770032\n",
      "----- Topic 3\n",
      "servic 0.022240961\n",
      "friend 0.019313317\n",
      "restaur 0.018040491\n",
      "love 0.016207548\n",
      "nice 0.015208652\n",
      "wine 0.015053305\n",
      "atmospher 0.013252496\n",
      "menu 0.012698647\n",
      "staff 0.012097907\n",
      "dinner 0.01146572\n",
      "----- Topic 4\n",
      "chicken 0.01809943\n",
      "order 0.017613953\n",
      "like 0.014749082\n",
      "come 0.012905807\n",
      "fri 0.0097111445\n",
      "tast 0.009418359\n",
      "taco 0.009069484\n",
      "drink 0.0084821815\n",
      "corn 0.007956692\n",
      "sweet 0.0078054527\n",
      "----- Topic 5\n",
      "wait 0.017870381\n",
      "time 0.017798452\n",
      "tabl 0.01585257\n",
      "order 0.014176874\n",
      "come 0.012688164\n",
      "servic 0.011151708\n",
      "go 0.010650114\n",
      "like 0.0105502205\n",
      "restaur 0.009331289\n",
      "friend 0.009330949\n",
      "----- Topic 6\n",
      "burger 0.024335561\n",
      "like 0.013313211\n",
      "menu 0.010334335\n",
      "time 0.009495912\n",
      "order 0.008401024\n",
      "come 0.008051249\n",
      "think 0.00791511\n",
      "tast 0.007222467\n",
      "love 0.006861128\n",
      "chees 0.006519787\n",
      "----- Topic 7\n",
      "pizza 0.048954025\n",
      "bread 0.017075362\n",
      "chees 0.014669618\n",
      "fresh 0.013952094\n",
      "salad 0.0113954535\n",
      "order 0.010711593\n",
      "pasta 0.010516458\n",
      "best 0.0098081\n",
      "crust 0.00915868\n",
      "sauc 0.008634491\n",
      "----- Topic 8\n",
      "beer 0.024342062\n",
      "best 0.018284697\n",
      "pizza 0.017859913\n",
      "like 0.016525272\n",
      "chicken 0.010830705\n",
      "chees 0.009981123\n",
      "time 0.0099661825\n",
      "free 0.009775897\n",
      "cheap 0.009211761\n",
      "amaz 0.008947607\n",
      "----- Topic 9\n",
      "love 0.016956083\n",
      "delici 0.01239377\n",
      "night 0.012246195\n",
      "order 0.011548419\n",
      "sangria 0.010845142\n",
      "perfect 0.010772049\n",
      "friend 0.009862671\n",
      "meal 0.009409719\n",
      "lamb 0.008741963\n",
      "come 0.008383438\n"
     ]
    }
   ],
   "source": [
    "unigram_topic_features_predictive_maker, get_topic_terms = get_topic_features_maker(all_reviews, num_topics=10)\n",
    "\n",
    "words = [\"Fried\", \"Chicken\", \"Pizza\", \"Slice\"]\n",
    "unigram_topic_features_predictive = unigram_topic_features_predictive_maker(words)\n",
    "print_topic_terms(unigram_topic_features_predictive, get_topic_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_unigram_topic_predictive = [unigram_topic_features_predictive_maker(x[1]) for x in all_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Topic 0\n",
      "food good 0.02478526\n",
      "this place 0.020148406\n",
      "friday night 0.01274327\n",
      "good servic 0.01204978\n",
      "place good 0.009531203\n",
      "excel food 0.0089609\n",
      "good food 0.008449192\n",
      "italian restaur 0.007931107\n",
      "good friend 0.0072339\n",
      "servic good 0.0070772353\n",
      "----- Topic 1\n",
      "great place 0.02720957\n",
      "lunch dinner 0.012021749\n",
      "friend servic 0.009640679\n",
      "fri chicken 0.009593315\n",
      "nice place 0.0086197\n",
      "bread pud 0.007981123\n",
      "pretti good 0.007927147\n",
      "good good 0.007824834\n",
      "food good 0.0076706037\n",
      "foie gras 0.00701384\n",
      "----- Topic 2\n",
      "this place 0.021023594\n",
      "great price 0.009763191\n",
      "pita bread 0.009595114\n",
      "soup dumpl 0.008980876\n",
      "artichok pizza 0.00883899\n",
      "credit card 0.008277147\n",
      "arugula salad 0.008176162\n",
      "wine select 0.007947528\n",
      "bake bean 0.0072855265\n",
      "white sauc 0.007005657\n",
      "----- Topic 3\n",
      "tast like 0.012579144\n",
      "fri chicken 0.012534842\n",
      "feel like 0.011147479\n",
      "thai restaur 0.0091396\n",
      "tast menu 0.0066287043\n",
      "dish come 0.006467858\n",
      "food good 0.0063346084\n",
      "east villag 0.006318108\n",
      "pretti good 0.006038828\n",
      "crispi outsid 0.0059070545\n",
      "----- Topic 4\n",
      "french toast 0.015360724\n",
      "bloodi mari 0.0097361235\n",
      "goat chees 0.009352492\n",
      "egg benedict 0.008861114\n",
      "time go 0.008514823\n",
      "good food 0.008248142\n",
      "servic slow 0.008179277\n",
      "west villag 0.007515552\n",
      "brunch spot 0.006975066\n",
      "sunday brunch 0.0066743735\n",
      "----- Topic 5\n",
      "din experi 0.013761439\n",
      "pretti good 0.00765167\n",
      "addit neighborhood 0.007504253\n",
      "write review 0.007370089\n",
      "pull pork 0.006535758\n",
      "high recommend 0.0060645537\n",
      "minut later 0.0060221874\n",
      "pork sandwich 0.0059589567\n",
      "fri chicken 0.005839478\n",
      "date night 0.0054434068\n",
      "----- Topic 6\n",
      "pork belli 0.01305393\n",
      "friend want 0.008728091\n",
      "wait hour 0.008707855\n",
      "good food 0.008568339\n",
      "probabl best 0.00853775\n",
      "onion ring 0.0075015426\n",
      "food amaz 0.007136694\n",
      "best thing 0.0066880197\n",
      "avocado toast 0.0065681254\n",
      "high qualiti 0.006242438\n",
      "----- Topic 7\n",
      "worth wait 0.02000211\n",
      "best pizza 0.015338882\n",
      "definit worth 0.0112064555\n",
      "pork bun 0.010859857\n",
      "wait long 0.01030281\n",
      "wait minut 0.008839917\n",
      "high recommend 0.0077864225\n",
      "go place 0.006891769\n",
      "line long 0.0064558294\n",
      "this place 0.0063506793\n",
      "----- Topic 8\n",
      "great food 0.031231344\n",
      "love place 0.029640164\n",
      "food great 0.025065035\n",
      "high recommend 0.02109782\n",
      "great servic 0.019346446\n",
      "this place 0.015644198\n",
      "great atmospher 0.014534899\n",
      "food excel 0.014527259\n",
      "place great 0.012237741\n",
      "servic great 0.010135857\n",
      "----- Topic 9\n",
      "happi hour 0.017027482\n",
      "look like 0.011792934\n",
      "felt like 0.008612628\n",
      "food servic 0.008333912\n",
      "good valu 0.008037055\n",
      "short rib 0.007268891\n",
      "food this 0.006867092\n",
      "larg parti 0.0068168156\n",
      "wait time 0.0062848986\n",
      "place small 0.006264944\n"
     ]
    }
   ],
   "source": [
    "bigram_topic_features_predictive_maker, get_topic_terms = get_topic_features_maker(all_reviews, num_topics=10,\n",
    "                                                                                   bigrams=True)\n",
    "\n",
    "words = [\"Fried\", \"Chicken\", \"Pizza\", \"Slice\"]\n",
    "bigram_topic_features_predictive = bigram_topic_features_predictive_maker(words)\n",
    "print_topic_terms(bigram_topic_features_predictive, get_topic_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_bigram_topic_predictive = [bigram_topic_features_maker(x[1]) for x in all_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6197030028521742"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy([features_reviewer, features_unigram_topic, features_bigram_topic_predictive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6224051776537964"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy([features_reviewer, features_unigram_topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6222206762262011"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy([features_reviewer, features_unigram_topic_predictive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6202558284049997"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy([features_reviewer, features_unigram_topic_predictive, features_bigram_topic_predictive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6142365494575439"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy([features_reviewer, features_bigram_topic_predictive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6138679613817736"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy([features_reviewer, features_bigram_topic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try forgetting about LDA topic models and using bag of words to generate our features. Unigrams give the best accuracy, even just including bigrams drops the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [x[0].review_content for x in all_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "unigram_count_vect = CountVectorizer()\n",
    "features_ngram_bow = unigram_count_vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6695738179163594"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [features_reviewer for i in range(0, 4)]\n",
    "features.append(features_ngram_bow)\n",
    "#features.append(features_unigram_topic)\n",
    "avg_accuracy(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying it with Tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "features_ngram_tfidf = tfidf_transformer.fit_transform(features_ngram_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506573499667422"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [features_sentiment for i in range(0, 9)]\n",
    "features.append(features_ngram_tfidf)\n",
    "avg_accuracy(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
