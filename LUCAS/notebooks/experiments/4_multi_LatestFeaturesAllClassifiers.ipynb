{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4: Latest features on all statistical classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [x.label for x in concatted_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latest_feature_extraction import get_features_maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features = get_features_maker(concatted_reviews, 775)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_features = get_features(concatted_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can only make our bag of words features so big before we crash with memr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/envs/lucas/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/stefan/anaconda3/envs/lucas/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy\n",
    "linearDA = LinearDiscriminantAnalysis()\n",
    "results = cross_validate(linearDA, predictor_features.toarray(), numpy.asarray(targets), cv=2,\n",
    "                         return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6899020151921419"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x for x in results['test_score'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n",
    "\n",
    "We normalise all our features to be between one and zero. We need to do this to suppress the mega features vs tiny features situation. Most classifiers use Euclidian distance, which has no knowledge of the units being used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "##### Duplicated! #####\n",
    "#######################\n",
    "\n",
    "from protos import review_set_pb2, review_pb2\n",
    "review_set = review_set_pb2.ReviewSet()\n",
    "with open(\"data/yelpZip\", 'rb') as f:\n",
    "  review_set.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake: 80466\n",
      "real: 80467\n",
      "all: 160933\n",
      "unused real: 447665\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "##### Duplicated! #####\n",
    "#######################\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "fake_reviews = list(filter(lambda x: x.label, review_set.reviews))\n",
    "count_fake = len(fake_reviews)\n",
    "genuine_reviews = []\n",
    "unused_genuine_reviews = []\n",
    "counter_genuine = 0\n",
    "for review in shuffle(review_set.reviews):\n",
    "  if review.label == True:\n",
    "    continue\n",
    "  if counter_genuine <= count_fake:\n",
    "    genuine_reviews.append(review)\n",
    "    counter_genuine += 1\n",
    "  else:\n",
    "    unused_genuine_reviews.append(review)\n",
    "  \n",
    "concatted_reviews = shuffle(fake_reviews + genuine_reviews)\n",
    "print(\"fake:\", len(fake_reviews))\n",
    "print(\"real:\", len(genuine_reviews))\n",
    "print(\"all:\", len(concatted_reviews))\n",
    "print(\"unused real:\", len(unused_genuine_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 32000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our sparse features are problematic here because we need to convert our data to array for standardisation. Since we cannot do this with sparse data without MemoryErrors, we will use dense features for our bag of words from experiment 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latest_feature_extraction import dense_features_maker\n",
    "from exp2_feature_extraction import find_words\n",
    "\n",
    "corpus_words = [find_words(x.review_content) for x in concatted_reviews[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/anaconda3/envs/lucas/lib/python3.7/site-packages/gensim/models/ldamodel.py:775: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    }
   ],
   "source": [
    "dense_features_getter = dense_features_maker(corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_features_dense = [dense_features_getter(x) for x in corpus_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(predictor_features_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = scaler.transform(predictor_features_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "this takes so long to run with all the data that we could not get results for this. Instead we use a smaller data set of n=36000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latest_feature_extraction import get_features_maker # Already imported\n",
    "get_features2 = get_features_maker(concatted_reviews[:n], 775)\n",
    "predictor_features2 = get_features2(concatted_reviews[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should already be imported\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [x.label for x in concatted_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(svc, scaled_features, targets[:n], cv=2, return_train_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When attempting to use LDA topics to have more dense features for our SVM, we have a very low accuracy. For some reason it is ?% better to just use bag of words again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(svc, scaled_features, targets[:n], cv=2, return_train_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(knn_classifier, scaled_features, targets[:n], cv=2, return_train_score=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
