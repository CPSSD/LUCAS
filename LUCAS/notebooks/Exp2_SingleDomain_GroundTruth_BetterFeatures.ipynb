{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following experiment 1, we now want to try to find better features. This will take inspiration from existing research done at Stanford. We will derive the same features and attempt to replicate the same benchmark as them. [Paper here](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwjf1Pbo6ZveAhUKBsAKHbeSAicQFjAAegQIBhAC&url=http%3A%2F%2Fcs229.stanford.edu%2Fproj2017%2Ffinal-reports%2F5229663.pdf&usg=AOvVaw1SAoqP8hAkRiRJH9lwmeEn)\n",
    "\n",
    "First the same setup as Experiment 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "data_file_path = 'data/yelpNYC'\n",
    "from protos import review_set_pb2, review_pb2\n",
    "import nltk\n",
    "review_set = review_set_pb2.ReviewSet()\n",
    "with open(data_file_path, 'rb') as f:\n",
    "  review_set.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first features will be the structural features. These are length of the review, average word length, number of sentences, average sentence length, percentage of numerals, percentage of capitalized words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp2_feature_extraction import find_avg_token_length, find_numerals_ratio\n",
    "from exp2_feature_extraction import find_capitalised_word_ratio\n",
    "\n",
    "find_words = lambda text: nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "def structural_features(review):\n",
    "  review_content = review.review_content\n",
    "  length_of_review = len(review_content)\n",
    "  words = find_words(review_content)\n",
    "  avg_word_length = find_avg_token_length(words)\n",
    "  sentences = nltk.tokenize.sent_tokenize(review_content)\n",
    "  sentence_length_of_review = len(sentences)\n",
    "  avg_sentence_length = find_avg_token_length(sentences)\n",
    "  numerals_ratio = find_numerals_ratio(words)\n",
    "  capitalised_word_ratio = find_capitalised_word_ratio(words)\n",
    "  return (length_of_review, avg_word_length, sentence_length_of_review,\n",
    "          avg_sentence_length, numerals_ratio, capitalised_word_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the Part of Speech features. There are 36 part of speech categories. Descriptions can be found [here](https://medium.com/@gianpaul.r/tokenization-and-parts-of-speech-pos-tagging-in-pythons-nltk-library-2d30f70af13b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = lambda text: nltk.pos_tag(words(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next are semantic features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping right now, want to get an end to end first, to see how these features even matter.\n",
    "\n",
    "...\n",
    "\n",
    "Now we will find the reviewer features. This includes the maximum number of reviews in a day, *percentage of positive / negative reviews (MISSING)*, average review length, standard deviation of reviewer's ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp2_feature_extraction import find_capitalised_word_ratio\n",
    "from exp2_feature_extraction import max_date_occurrences\n",
    "import statistics\n",
    "import functools\n",
    "\n",
    "def reviewer_features(review, reviews_by_reviewer):\n",
    "  reviews = reviews_by_reviewer[review.user_id]\n",
    "  max_reviews_in_day = max_date_occurrences(reviews)\n",
    "  average_review_length = functools.reduce(lambda total, review: total + len(review.review_content), reviews, 0) / len(reviews)\n",
    "  ratings_stdev = 0 if len(reviews) == 1 else statistics.stdev([x.rating for x in reviews])\n",
    "  return (max_reviews_in_day, average_review_length, ratings_stdev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put our features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp2_feature_extraction import reviews_by_reviewer\n",
    "from sklearn.utils import shuffle\n",
    "reviews = shuffle(review_set.reviews)\n",
    "reviews_reviewer_map = reviews_by_reviewer(reviews)\n",
    "predictor_features = [list(structural_features(x)) + list(reviewer_features(x, reviews_reviewer_map)) for x in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [x.label for x in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "cnb = ComplementNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.44158745, 0.49054933, 0.53898025, 0.54834628, 0.62135291,\n",
       "        0.56310439, 0.66381502, 0.60599899, 0.67143273, 0.53081226]),\n",
       " 'score_time': array([0.04401064, 0.04098248, 0.05866456, 0.05319452, 0.08195329,\n",
       "        0.05859399, 0.05887151, 0.06138062, 0.0479188 , 0.05649495]),\n",
       " 'test_score': array([0.53305854, 0.53576004, 0.53676266, 0.53161032, 0.53381051,\n",
       "        0.52987049, 0.53488372, 0.53576203, 0.53428587, 0.53503788])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cross_validate(cnb, predictor_features, targets, cv=10, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
