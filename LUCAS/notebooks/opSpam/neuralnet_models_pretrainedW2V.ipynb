{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Neural Models on pretrained Word2Vec embeddings\n",
    "\n",
    "## Feedforward Neural Network\n",
    "\n",
    "Following an experiment to compare neural models, we discovered odd results showing that bag of words could outperform embeddings. This experiment attempts to tweak the embeddings to show the expected results under the assumption that the problem is not the amount of data. If the problem is the amount of data we will investigate this in another experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will show Bag of Words results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scripts import training_helpers\n",
    "from scripts.cross_validate import run_cross_validate\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Embedding, MaxPooling2D, LSTM\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from pandas import DataFrame\n",
    "from seaborn import boxplot\n",
    "from notebooks.yelp.metrics import auroc, f1\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "read_existing_embeddings = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded = tf.keras.utils.get_file(\n",
    "             fname=\"opspam.pkl\",\n",
    "             origin=\"https://storage.googleapis.com/lucas0/opspam.pkl\",\n",
    "             extract=False)\n",
    "data_frame = pd.read_pickle(downloaded).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "raw_features = data_frame['review']\n",
    "labels = [x for x in data_frame['deceptive']]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(raw_features)\n",
    "bow_features = tokenizer.texts_to_matrix(raw_features, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words = tokenizer.word_index\n",
    "corpus_vocab_size = len(corpus_words)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ff_bow_model():\n",
    "  model = Sequential([\n",
    "      Dense(16, activation=relu, input_shape=(corpus_vocab_size,), kernel_regularizer=l2(0.01)),\n",
    "      Dropout(0.25),\n",
    "      Dense(8, activation=relu, kernel_regularizer=l2(0.01)),\n",
    "      Dense(1, activation=sigmoid)\n",
    "  ])\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 497us/step - loss: 0.8263 - acc: 0.6672 - auroc: 0.7538 - f1: 0.6219 - val_loss: 0.6407 - val_acc: 0.8375 - val_auroc: 0.9231 - val_f1: 0.8379\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.4639 - acc: 0.9195 - auroc: 0.9695 - f1: 0.9164 - val_loss: 0.4904 - val_acc: 0.8750 - val_auroc: 0.9527 - val_f1: 0.8805\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.3079 - acc: 0.9789 - auroc: 0.9962 - f1: 0.9777 - val_loss: 0.4546 - val_acc: 0.8875 - val_auroc: 0.9554 - val_f1: 0.8835\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.2539 - acc: 0.9820 - auroc: 0.9989 - f1: 0.9821 - val_loss: 0.4448 - val_acc: 0.8750 - val_auroc: 0.9563 - val_f1: 0.8794\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.2207 - acc: 0.9930 - auroc: 1.0000 - f1: 0.9932 - val_loss: 0.4182 - val_acc: 0.8812 - val_auroc: 0.9605 - val_f1: 0.8755\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.2021 - acc: 0.9922 - auroc: 1.0000 - f1: 0.9925 - val_loss: 0.4433 - val_acc: 0.8656 - val_auroc: 0.9560 - val_f1: 0.8521\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 138us/step - loss: 0.1898 - acc: 0.9945 - auroc: 1.0000 - f1: 0.9943 - val_loss: 0.4289 - val_acc: 0.8781 - val_auroc: 0.9537 - val_f1: 0.8793\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 146us/step - loss: 0.1748 - acc: 0.9945 - auroc: 0.9999 - f1: 0.9946 - val_loss: 0.4420 - val_acc: 0.8719 - val_auroc: 0.9565 - val_f1: 0.8604\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.1623 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9984 - val_loss: 0.4128 - val_acc: 0.8844 - val_auroc: 0.9575 - val_f1: 0.8730\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.1614 - acc: 0.9953 - auroc: 1.0000 - f1: 0.9955 - val_loss: 0.4077 - val_acc: 0.8969 - val_auroc: 0.9583 - val_f1: 0.8927\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.1488 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9975 - val_loss: 0.4002 - val_acc: 0.8875 - val_auroc: 0.9627 - val_f1: 0.8764\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.1446 - acc: 0.9984 - auroc: 0.9999 - f1: 0.9984 - val_loss: 0.3789 - val_acc: 0.8844 - val_auroc: 0.9633 - val_f1: 0.8827\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.1376 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9972 - val_loss: 0.3960 - val_acc: 0.8781 - val_auroc: 0.9591 - val_f1: 0.8730\n",
      "Epoch 14/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.1327 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3802 - val_acc: 0.8844 - val_auroc: 0.9620 - val_f1: 0.8790\n",
      "Epoch 15/25\n",
      "1280/1280 [==============================] - 0s 138us/step - loss: 0.1337 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4076 - val_acc: 0.8750 - val_auroc: 0.9575 - val_f1: 0.8789\n",
      "Epoch 16/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1372 - acc: 0.9961 - auroc: 1.0000 - f1: 0.9961 - val_loss: 0.4190 - val_acc: 0.8656 - val_auroc: 0.9544 - val_f1: 0.8602\n",
      "Epoch 17/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1443 - acc: 0.9930 - auroc: 0.9999 - f1: 0.9925 - val_loss: 0.4411 - val_acc: 0.8656 - val_auroc: 0.9464 - val_f1: 0.8665\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 465us/step - loss: 0.8340 - acc: 0.6562 - auroc: 0.7198 - f1: 0.6277 - val_loss: 0.6291 - val_acc: 0.8438 - val_auroc: 0.9209 - val_f1: 0.8491\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 131us/step - loss: 0.4549 - acc: 0.9258 - auroc: 0.9779 - f1: 0.9219 - val_loss: 0.4795 - val_acc: 0.8875 - val_auroc: 0.9524 - val_f1: 0.8883\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 130us/step - loss: 0.3208 - acc: 0.9688 - auroc: 0.9936 - f1: 0.9684 - val_loss: 0.4427 - val_acc: 0.8875 - val_auroc: 0.9571 - val_f1: 0.8859\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 131us/step - loss: 0.2557 - acc: 0.9898 - auroc: 0.9996 - f1: 0.9903 - val_loss: 0.4240 - val_acc: 0.8875 - val_auroc: 0.9595 - val_f1: 0.8859\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 138us/step - loss: 0.2193 - acc: 0.9937 - auroc: 0.9998 - f1: 0.9942 - val_loss: 0.4202 - val_acc: 0.8969 - val_auroc: 0.9571 - val_f1: 0.8943\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 136us/step - loss: 0.2004 - acc: 0.9961 - auroc: 1.0000 - f1: 0.9959 - val_loss: 0.4449 - val_acc: 0.8625 - val_auroc: 0.9551 - val_f1: 0.8546\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 135us/step - loss: 0.1972 - acc: 0.9969 - auroc: 1.0000 - f1: 0.9963 - val_loss: 0.4392 - val_acc: 0.8656 - val_auroc: 0.9492 - val_f1: 0.8605\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 132us/step - loss: 0.1879 - acc: 0.9937 - auroc: 0.9999 - f1: 0.9929 - val_loss: 0.4063 - val_acc: 0.8781 - val_auroc: 0.9584 - val_f1: 0.8753\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 129us/step - loss: 0.1718 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9977 - val_loss: 0.4469 - val_acc: 0.8719 - val_auroc: 0.9525 - val_f1: 0.8590\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 135us/step - loss: 0.1622 - acc: 0.9977 - auroc: 0.9999 - f1: 0.9979 - val_loss: 0.4045 - val_acc: 0.8844 - val_auroc: 0.9564 - val_f1: 0.8791\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 129us/step - loss: 0.1599 - acc: 0.9984 - auroc: 0.9997 - f1: 0.9986 - val_loss: 0.4124 - val_acc: 0.8812 - val_auroc: 0.9559 - val_f1: 0.8705\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 130us/step - loss: 0.1519 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9975 - val_loss: 0.4028 - val_acc: 0.8906 - val_auroc: 0.9559 - val_f1: 0.8820\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 129us/step - loss: 0.1412 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9979 - val_loss: 0.3892 - val_acc: 0.8875 - val_auroc: 0.9579 - val_f1: 0.8817\n",
      "Epoch 14/25\n",
      "1280/1280 [==============================] - 0s 128us/step - loss: 0.1391 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9976 - val_loss: 0.3979 - val_acc: 0.8844 - val_auroc: 0.9581 - val_f1: 0.8812\n",
      "Epoch 15/25\n",
      "1280/1280 [==============================] - 0s 130us/step - loss: 0.1369 - acc: 0.9977 - auroc: 0.9998 - f1: 0.9973 - val_loss: 0.4192 - val_acc: 0.8750 - val_auroc: 0.9533 - val_f1: 0.8713\n",
      "Epoch 16/25\n",
      "1280/1280 [==============================] - 0s 134us/step - loss: 0.1332 - acc: 0.9977 - auroc: 0.9997 - f1: 0.9974 - val_loss: 0.4088 - val_acc: 0.8875 - val_auroc: 0.9542 - val_f1: 0.8833\n",
      "Epoch 17/25\n",
      "1280/1280 [==============================] - 0s 132us/step - loss: 0.1308 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9976 - val_loss: 0.4243 - val_acc: 0.8750 - val_auroc: 0.9461 - val_f1: 0.8689\n",
      "Epoch 18/25\n",
      "1280/1280 [==============================] - 0s 130us/step - loss: 0.1301 - acc: 0.9969 - auroc: 1.0000 - f1: 0.9972 - val_loss: 0.4000 - val_acc: 0.8750 - val_auroc: 0.9508 - val_f1: 0.8744\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 552us/step - loss: 0.8831 - acc: 0.5656 - auroc: 0.6334 - f1: 0.5023 - val_loss: 0.7587 - val_acc: 0.6500 - val_auroc: 0.8703 - val_f1: 0.4578\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 137us/step - loss: 0.6801 - acc: 0.7492 - auroc: 0.9118 - f1: 0.6542 - val_loss: 0.6554 - val_acc: 0.8406 - val_auroc: 0.9050 - val_f1: 0.8308\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 132us/step - loss: 0.5315 - acc: 0.9062 - auroc: 0.9819 - f1: 0.8971 - val_loss: 0.5946 - val_acc: 0.8625 - val_auroc: 0.9115 - val_f1: 0.8723\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 132us/step - loss: 0.4072 - acc: 0.9539 - auroc: 0.9879 - f1: 0.9503 - val_loss: 0.5104 - val_acc: 0.8438 - val_auroc: 0.9185 - val_f1: 0.8566\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 134us/step - loss: 0.3036 - acc: 0.9750 - auroc: 0.9955 - f1: 0.9731 - val_loss: 0.4818 - val_acc: 0.8625 - val_auroc: 0.9269 - val_f1: 0.8692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 138us/step - loss: 0.2514 - acc: 0.9844 - auroc: 0.9961 - f1: 0.9841 - val_loss: 0.4579 - val_acc: 0.8531 - val_auroc: 0.9328 - val_f1: 0.8540\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 133us/step - loss: 0.2242 - acc: 0.9891 - auroc: 0.9979 - f1: 0.9884 - val_loss: 0.4625 - val_acc: 0.8688 - val_auroc: 0.9316 - val_f1: 0.8723\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 130us/step - loss: 0.2005 - acc: 0.9922 - auroc: 0.9989 - f1: 0.9926 - val_loss: 0.4719 - val_acc: 0.8625 - val_auroc: 0.9328 - val_f1: 0.8652\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 130us/step - loss: 0.1923 - acc: 0.9922 - auroc: 0.9988 - f1: 0.9925 - val_loss: 0.4735 - val_acc: 0.8594 - val_auroc: 0.9389 - val_f1: 0.8569\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 130us/step - loss: 0.1741 - acc: 0.9930 - auroc: 0.9997 - f1: 0.9928 - val_loss: 0.4571 - val_acc: 0.8625 - val_auroc: 0.9409 - val_f1: 0.8643\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 132us/step - loss: 0.1536 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9986 - val_loss: 0.4580 - val_acc: 0.8531 - val_auroc: 0.9408 - val_f1: 0.8520\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 133us/step - loss: 0.1502 - acc: 0.9953 - auroc: 0.9997 - f1: 0.9952 - val_loss: 0.4493 - val_acc: 0.8562 - val_auroc: 0.9413 - val_f1: 0.8591\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 130us/step - loss: 0.1501 - acc: 0.9969 - auroc: 1.0000 - f1: 0.9969 - val_loss: 0.4945 - val_acc: 0.8719 - val_auroc: 0.9308 - val_f1: 0.8762\n",
      "Epoch 14/25\n",
      "1280/1280 [==============================] - 0s 127us/step - loss: 0.1497 - acc: 0.9969 - auroc: 0.9999 - f1: 0.9970 - val_loss: 0.4783 - val_acc: 0.8625 - val_auroc: 0.9344 - val_f1: 0.8714\n",
      "Epoch 15/25\n",
      "1280/1280 [==============================] - 0s 132us/step - loss: 0.1510 - acc: 0.9945 - auroc: 1.0000 - f1: 0.9946 - val_loss: 0.5011 - val_acc: 0.8594 - val_auroc: 0.9271 - val_f1: 0.8656\n",
      "Epoch 16/25\n",
      "1280/1280 [==============================] - 0s 127us/step - loss: 0.1492 - acc: 0.9961 - auroc: 0.9998 - f1: 0.9957 - val_loss: 0.5193 - val_acc: 0.8531 - val_auroc: 0.9245 - val_f1: 0.8566\n",
      "Epoch 17/25\n",
      "1280/1280 [==============================] - 0s 131us/step - loss: 0.1404 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9981 - val_loss: 0.5622 - val_acc: 0.8313 - val_auroc: 0.9157 - val_f1: 0.8398\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 568us/step - loss: 0.8249 - acc: 0.6703 - auroc: 0.7473 - f1: 0.6543 - val_loss: 0.5752 - val_acc: 0.8969 - val_auroc: 0.9609 - val_f1: 0.8968\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.4363 - acc: 0.9250 - auroc: 0.9775 - f1: 0.9225 - val_loss: 0.4611 - val_acc: 0.9031 - val_auroc: 0.9682 - val_f1: 0.8922\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.2929 - acc: 0.9805 - auroc: 0.9976 - f1: 0.9800 - val_loss: 0.4245 - val_acc: 0.9031 - val_auroc: 0.9638 - val_f1: 0.8958\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.2449 - acc: 0.9930 - auroc: 0.9998 - f1: 0.9931 - val_loss: 0.4076 - val_acc: 0.9062 - val_auroc: 0.9616 - val_f1: 0.9028\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.2137 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9986 - val_loss: 0.3859 - val_acc: 0.9000 - val_auroc: 0.9628 - val_f1: 0.8970\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 138us/step - loss: 0.1957 - acc: 0.9953 - auroc: 0.9998 - f1: 0.9954 - val_loss: 0.3764 - val_acc: 0.8938 - val_auroc: 0.9655 - val_f1: 0.8912\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.1893 - acc: 0.9977 - auroc: 0.9998 - f1: 0.9977 - val_loss: 0.3856 - val_acc: 0.8906 - val_auroc: 0.9589 - val_f1: 0.8871\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 137us/step - loss: 0.1726 - acc: 0.9969 - auroc: 1.0000 - f1: 0.9967 - val_loss: 0.3703 - val_acc: 0.9062 - val_auroc: 0.9625 - val_f1: 0.9022\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 138us/step - loss: 0.1720 - acc: 0.9945 - auroc: 0.9997 - f1: 0.9946 - val_loss: 0.4050 - val_acc: 0.8812 - val_auroc: 0.9516 - val_f1: 0.8760\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.1650 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9984 - val_loss: 0.3933 - val_acc: 0.9000 - val_auroc: 0.9554 - val_f1: 0.9013\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1523 - acc: 0.9992 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.3829 - val_acc: 0.8938 - val_auroc: 0.9518 - val_f1: 0.8903\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.1519 - acc: 0.9969 - auroc: 0.9999 - f1: 0.9966 - val_loss: 0.3928 - val_acc: 0.8906 - val_auroc: 0.9498 - val_f1: 0.8860\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 137us/step - loss: 0.1410 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3714 - val_acc: 0.8906 - val_auroc: 0.9540 - val_f1: 0.8866\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 682us/step - loss: 0.8322 - acc: 0.6609 - auroc: 0.7320 - f1: 0.6262 - val_loss: 0.6478 - val_acc: 0.8406 - val_auroc: 0.9186 - val_f1: 0.8436\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.4572 - acc: 0.9211 - auroc: 0.9720 - f1: 0.9194 - val_loss: 0.4870 - val_acc: 0.8844 - val_auroc: 0.9447 - val_f1: 0.8766\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.2934 - acc: 0.9734 - auroc: 0.9973 - f1: 0.9734 - val_loss: 0.4731 - val_acc: 0.8719 - val_auroc: 0.9443 - val_f1: 0.8637\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.2373 - acc: 0.9930 - auroc: 0.9995 - f1: 0.9929 - val_loss: 0.4668 - val_acc: 0.8688 - val_auroc: 0.9447 - val_f1: 0.8613\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 135us/step - loss: 0.2078 - acc: 0.9945 - auroc: 1.0000 - f1: 0.9944 - val_loss: 0.4637 - val_acc: 0.8812 - val_auroc: 0.9427 - val_f1: 0.8791\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 138us/step - loss: 0.1885 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9978 - val_loss: 0.4522 - val_acc: 0.8750 - val_auroc: 0.9438 - val_f1: 0.8675\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 138us/step - loss: 0.1766 - acc: 0.9961 - auroc: 0.9998 - f1: 0.9963 - val_loss: 0.4464 - val_acc: 0.8844 - val_auroc: 0.9455 - val_f1: 0.8780\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 135us/step - loss: 0.1641 - acc: 0.9984 - auroc: 0.9999 - f1: 0.9987 - val_loss: 0.4625 - val_acc: 0.8625 - val_auroc: 0.9403 - val_f1: 0.8528\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1549 - acc: 0.9984 - auroc: 0.9999 - f1: 0.9985 - val_loss: 0.4616 - val_acc: 0.8625 - val_auroc: 0.9399 - val_f1: 0.8567\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.1482 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9983 - val_loss: 0.4849 - val_acc: 0.8500 - val_auroc: 0.9367 - val_f1: 0.8377\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.1445 - acc: 0.9953 - auroc: 1.0000 - f1: 0.9947 - val_loss: 0.4668 - val_acc: 0.8594 - val_auroc: 0.9410 - val_f1: 0.8447\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1401 - acc: 0.9969 - auroc: 1.0000 - f1: 0.9967 - val_loss: 0.4599 - val_acc: 0.8594 - val_auroc: 0.9406 - val_f1: 0.8482\n"
     ]
    }
   ],
   "source": [
    "def evaluate_ffnn_model(train_X, train_y, test_X, test_y):\n",
    "    ffnn_model = get_ff_bow_model()\n",
    "    return ffnn_model.fit(train_X, train_y, epochs=25, batch_size=32, verbose=1, shuffle=False,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "                   validation_data=(test_X, test_y))\n",
    "\n",
    "ff_bow_scores = run_cross_validate(evaluate_ffnn_model, bow_features, labels, splitter, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we will get results for embeddings. This time I will use pretrained Word2Vec. Although this was not trained directly on words from our dataset, the Word2Vec has a higher dimensionality (making it harder to run on our machines) and so may show better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(scores):\n",
    "    bests = []\n",
    "    for his in scores:\n",
    "        best = None\n",
    "        min_val_loss = 99999\n",
    "        h = his.history\n",
    "        for i, val_loss in enumerate(h['val_loss']):\n",
    "            if val_loss < min_val_loss:\n",
    "                min_val_loss = val_loss\n",
    "                best = { 'val_loss': val_loss, 'val_accuracy': h['val_acc'][i], 'val_auroc': h['auroc'][i], 'val_f1': h['val_f1'][i]}\n",
    "        bests.append(best)\n",
    "    return bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests = results(ff_bow_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'val_accuracy': 0.884375,\n",
       "   'val_auroc': 0.9999019607843138,\n",
       "   'val_f1': 0.88272345662117,\n",
       "   'val_loss': 0.37886111736297606},\n",
       "  {'val_accuracy': 0.8875,\n",
       "   'val_auroc': 1.0,\n",
       "   'val_f1': 0.8816700756549836,\n",
       "   'val_loss': 0.3891655921936035},\n",
       "  {'val_accuracy': 0.85625,\n",
       "   'val_auroc': 0.9997023809523811,\n",
       "   'val_f1': 0.8591303348541259,\n",
       "   'val_loss': 0.4492654412984848},\n",
       "  {'val_accuracy': 0.90625,\n",
       "   'val_auroc': 1.0,\n",
       "   'val_f1': 0.9021806597709656,\n",
       "   'val_loss': 0.3703372567892075},\n",
       "  {'val_accuracy': 0.884375,\n",
       "   'val_auroc': 0.9998015873015873,\n",
       "   'val_f1': 0.8780216753482819,\n",
       "   'val_loss': 0.44638331830501554}],\n",
       " 0.88375)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests, statistics.mean([x['val_accuracy'] for x in bests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = None\n",
    "embedding_length = 0\n",
    "\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(\"../../data/GoogleNews-vectors-negative300.bin\",\n",
    "                                                                 binary=True)\n",
    "embedding_length = word_vectors.vector_size\n",
    "    \n",
    "embedding_matrix = np.zeros((corpus_vocab_size, embedding_length))\n",
    "for word, index in corpus_words.items():\n",
    "  if word in word_vectors.vocab:\n",
    "    embedding_matrix[index] = np.array(word_vectors[word], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ff_wv_model():\n",
    "  model_ff_wv = Sequential([\n",
    "      Embedding(corpus_vocab_size, embedding_length, weights=[embedding_matrix], trainable=False,\n",
    "                input_length=corpus_vocab_size),\n",
    "      Flatten(),\n",
    "      Dense(16, activation=relu, kernel_regularizer=l2(0.01)),\n",
    "      Dropout(0.25),\n",
    "      Dense(8, activation=relu, kernel_regularizer=l2(0.01)),\n",
    "      Dense(1, activation=sigmoid)\n",
    "  ])\n",
    "  model_ff_wv.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', auroc, f1])\n",
    "  return model_ff_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 28s 22ms/step - loss: 0.9973 - acc: 0.6195 - auroc: 0.6722 - f1: 0.5729 - val_loss: 1.0940 - val_acc: 0.7031 - val_auroc: 0.7920 - val_f1: 0.7294\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 22s 17ms/step - loss: 1.0975 - acc: 0.7445 - auroc: 0.8168 - f1: 0.7329 - val_loss: 1.0851 - val_acc: 0.7500 - val_auroc: 0.8062 - val_f1: 0.7496\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 22s 17ms/step - loss: 1.0668 - acc: 0.7578 - auroc: 0.8548 - f1: 0.7580 - val_loss: 1.1508 - val_acc: 0.7188 - val_auroc: 0.8104 - val_f1: 0.7224\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 22s 17ms/step - loss: 1.0529 - acc: 0.7797 - auroc: 0.8618 - f1: 0.7728 - val_loss: 1.0844 - val_acc: 0.7281 - val_auroc: 0.8150 - val_f1: 0.7400\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 22s 18ms/step - loss: 1.0437 - acc: 0.7906 - auroc: 0.8772 - f1: 0.7882 - val_loss: 1.1422 - val_acc: 0.7188 - val_auroc: 0.7752 - val_f1: 0.7325\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 23s 18ms/step - loss: 1.0609 - acc: 0.8047 - auroc: 0.8904 - f1: 0.8022 - val_loss: 1.2352 - val_acc: 0.7281 - val_auroc: 0.7939 - val_f1: 0.7209\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 22s 17ms/step - loss: 1.1466 - acc: 0.7875 - auroc: 0.8803 - f1: 0.7895 - val_loss: 1.3340 - val_acc: 0.7156 - val_auroc: 0.7886 - val_f1: 0.7331\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 22s 18ms/step - loss: 1.1100 - acc: 0.8031 - auroc: 0.8976 - f1: 0.8017 - val_loss: 1.1633 - val_acc: 0.7063 - val_auroc: 0.7911 - val_f1: 0.7041\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 22s 17ms/step - loss: 1.0670 - acc: 0.7992 - auroc: 0.8850 - f1: 0.7978 - val_loss: 1.1901 - val_acc: 0.6969 - val_auroc: 0.7759 - val_f1: 0.6968\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "  32/1280 [..............................] - ETA: 4:08 - loss: 1.1300 - acc: 0.5938 - auroc: 0.6431 - f1: 0.6486"
     ]
    }
   ],
   "source": [
    "def evaluate_ffnn_model(train_X, train_y, test_X, test_y):\n",
    "    ffnn_model = get_ff_wv_model()\n",
    "    return ffnn_model.fit(train_X, train_y, epochs=25, batch_size=32, verbose=1, shuffle=False,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "                   validation_data=(test_X, test_y))\n",
    "\n",
    "ff_wv_scores = run_cross_validate(evaluate_ffnn_model, bow_features, labels, splitter, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_wv_bests = results(ff_wv_scores)\n",
    "ff_wv_bests, statistics.mean([x['val_accuracy'] for x in ff_wv_bests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_scores_entries =[('Bag of Words', x['val_accuracy']) for x in bests] + [('Word Vectors', x['val_accuracy']) for x in ff_wv_bests]\n",
    "ff_scores_data_frame = DataFrame(ff_scores_entries, columns=['input type', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(x='input type', y='accuracy', data=ff_scores_data_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like word vectors are doing better now! Although they should be more accurate than Bag of Words, unless this is an exceptional case. The next step here is to investigate how BoW and word vectors perform on more data, since a small amount of data is a case known to cause results like this. It is also very unlikely Bag of Words will perform as well on a large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research has shown that word embeddings perform better than Bag of Words (Convolutional Neural Networks for Sentence Classification, Yoon Kim 2014). We will use our convolutional network on pretrained Word2Vec embeddings to see if we obtain an improved accuracy. First we will obtain results for bag of words again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 1, 9839, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = 1600\n",
    "convolutional_data = np.array(np.split(np.array([[[y] for y in z] for z in bow_features]), batches))\n",
    "convolutional_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_bow_model():\n",
    "  model = Sequential([\n",
    "      Conv2D(\n",
    "          filters=50,\n",
    "          kernel_size=(1, 10),\n",
    "          data_format=\"channels_last\",\n",
    "          input_shape=(1, corpus_vocab_size, 1),\n",
    "          activation=relu),\n",
    "      MaxPooling2D(pool_size=(1, 10)),\n",
    "      Dropout(0.2),\n",
    "      Flatten(),\n",
    "      Dense(2, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_conv_model(train_X, train_y, test_X, test_y):\n",
    "    conv_model = get_conv_bow_model()\n",
    "    return conv_model.fit(train_X, train_y, epochs=25, batch_size=34, verbose=1, shuffle=False,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=6)],\n",
    "                   validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 5s 4ms/step - loss: 0.6530 - acc: 0.6118 - auroc: 0.6639 - f1: 0.6118 - val_loss: 0.6233 - val_acc: 0.6750 - val_auroc: 0.7363 - val_f1: 0.6750\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4274 - acc: 0.8076 - auroc: 0.9109 - f1: 0.8076 - val_loss: 0.7974 - val_acc: 0.6125 - val_auroc: 0.7172 - val_f1: 0.6125\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3384 - acc: 0.8667 - auroc: 0.9532 - f1: 0.8667 - val_loss: 0.7050 - val_acc: 0.6562 - val_auroc: 0.7076 - val_f1: 0.6562\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3342 - acc: 0.8500 - auroc: 0.9686 - f1: 0.8500 - val_loss: 0.8529 - val_acc: 0.6625 - val_auroc: 0.7191 - val_f1: 0.6625\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3481 - acc: 0.8389 - auroc: 0.9722 - f1: 0.8389 - val_loss: 0.7475 - val_acc: 0.6687 - val_auroc: 0.7479 - val_f1: 0.6687\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2079 - acc: 0.9243 - auroc: 0.9874 - f1: 0.9243 - val_loss: 0.8684 - val_acc: 0.6562 - val_auroc: 0.7217 - val_f1: 0.6562\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1866 - acc: 0.9278 - auroc: 0.9934 - f1: 0.9278 - val_loss: 0.9594 - val_acc: 0.6813 - val_auroc: 0.7283 - val_f1: 0.6812\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.6804 - acc: 0.5972 - auroc: 0.6401 - f1: 0.5972 - val_loss: 0.6401 - val_acc: 0.6437 - val_auroc: 0.6989 - val_f1: 0.6437\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4953 - acc: 0.7590 - auroc: 0.8972 - f1: 0.7590 - val_loss: 0.6350 - val_acc: 0.6812 - val_auroc: 0.7402 - val_f1: 0.6812\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3897 - acc: 0.8354 - auroc: 0.9366 - f1: 0.8354 - val_loss: 0.7599 - val_acc: 0.6438 - val_auroc: 0.7533 - val_f1: 0.6437\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3235 - acc: 0.8618 - auroc: 0.9608 - f1: 0.8618 - val_loss: 0.8295 - val_acc: 0.6688 - val_auroc: 0.7127 - val_f1: 0.6687\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3164 - acc: 0.8604 - auroc: 0.9729 - f1: 0.8604 - val_loss: 0.8001 - val_acc: 0.7000 - val_auroc: 0.7515 - val_f1: 0.7000\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3646 - acc: 0.8396 - auroc: 0.9740 - f1: 0.8396 - val_loss: 0.7449 - val_acc: 0.7188 - val_auroc: 0.7547 - val_f1: 0.7187\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2848 - acc: 0.8743 - auroc: 0.9830 - f1: 0.8743 - val_loss: 0.8716 - val_acc: 0.6625 - val_auroc: 0.7810 - val_f1: 0.6625\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1949 - acc: 0.9250 - auroc: 0.9909 - f1: 0.9250 - val_loss: 0.7491 - val_acc: 0.7000 - val_auroc: 0.7795 - val_f1: 0.7000\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.6525 - acc: 0.6222 - auroc: 0.6726 - f1: 0.6222 - val_loss: 0.6532 - val_acc: 0.6062 - val_auroc: 0.6714 - val_f1: 0.6062\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4133 - acc: 0.8243 - auroc: 0.9117 - f1: 0.8243 - val_loss: 0.7201 - val_acc: 0.5875 - val_auroc: 0.6631 - val_f1: 0.5875\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3312 - acc: 0.8736 - auroc: 0.9531 - f1: 0.8736 - val_loss: 0.8184 - val_acc: 0.6187 - val_auroc: 0.6555 - val_f1: 0.6187\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3115 - acc: 0.8611 - auroc: 0.9697 - f1: 0.8611 - val_loss: 0.7847 - val_acc: 0.6313 - val_auroc: 0.7094 - val_f1: 0.6312\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2875 - acc: 0.8840 - auroc: 0.9801 - f1: 0.8840 - val_loss: 0.9403 - val_acc: 0.6063 - val_auroc: 0.6755 - val_f1: 0.6062\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2299 - acc: 0.9076 - auroc: 0.9875 - f1: 0.9076 - val_loss: 1.0769 - val_acc: 0.6250 - val_auroc: 0.6824 - val_f1: 0.6250\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 2ms/step - loss: 0.1778 - acc: 0.9250 - auroc: 0.9920 - f1: 0.9250 - val_loss: 1.2379 - val_acc: 0.6375 - val_auroc: 0.6961 - val_f1: 0.6375\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.6628 - acc: 0.6069 - auroc: 0.6634 - f1: 0.6069 - val_loss: 0.6349 - val_acc: 0.6625 - val_auroc: 0.7238 - val_f1: 0.6625\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4478 - acc: 0.8007 - auroc: 0.8968 - f1: 0.8007 - val_loss: 0.6850 - val_acc: 0.6937 - val_auroc: 0.7322 - val_f1: 0.6937\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3813 - acc: 0.8285 - auroc: 0.9435 - f1: 0.8285 - val_loss: 0.8402 - val_acc: 0.6250 - val_auroc: 0.7194 - val_f1: 0.6250\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4069 - acc: 0.8083 - auroc: 0.9562 - f1: 0.8083 - val_loss: 0.7626 - val_acc: 0.6375 - val_auroc: 0.7644 - val_f1: 0.6375\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3256 - acc: 0.8687 - auroc: 0.9711 - f1: 0.8687 - val_loss: 0.6719 - val_acc: 0.6875 - val_auroc: 0.7487 - val_f1: 0.6875\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1816 - acc: 0.9417 - auroc: 0.9897 - f1: 0.9417 - val_loss: 0.7458 - val_acc: 0.6688 - val_auroc: 0.7557 - val_f1: 0.6687\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1339 - acc: 0.9625 - auroc: 0.9950 - f1: 0.9625 - val_loss: 0.8542 - val_acc: 0.6500 - val_auroc: 0.7533 - val_f1: 0.6500\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.6588 - acc: 0.6222 - auroc: 0.6704 - f1: 0.6222 - val_loss: 0.6655 - val_acc: 0.7062 - val_auroc: 0.7008 - val_f1: 0.7062\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4389 - acc: 0.8118 - auroc: 0.9016 - f1: 0.8118 - val_loss: 0.7038 - val_acc: 0.6437 - val_auroc: 0.7087 - val_f1: 0.6437\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3177 - acc: 0.8646 - auroc: 0.9537 - f1: 0.8646 - val_loss: 0.7278 - val_acc: 0.6813 - val_auroc: 0.7234 - val_f1: 0.6812\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2678 - acc: 0.8896 - auroc: 0.9732 - f1: 0.8896 - val_loss: 1.2422 - val_acc: 0.5875 - val_auroc: 0.6972 - val_f1: 0.5875\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3123 - acc: 0.8729 - auroc: 0.9727 - f1: 0.8729 - val_loss: 1.0824 - val_acc: 0.6000 - val_auroc: 0.6929 - val_f1: 0.6000\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3605 - acc: 0.8576 - auroc: 0.9811 - f1: 0.8576 - val_loss: 0.8409 - val_acc: 0.6375 - val_auroc: 0.7293 - val_f1: 0.6375\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2731 - acc: 0.8778 - auroc: 0.9869 - f1: 0.8778 - val_loss: 0.8702 - val_acc: 0.6438 - val_auroc: 0.7547 - val_f1: 0.6437\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.6512 - acc: 0.6035 - auroc: 0.6720 - f1: 0.6035 - val_loss: 0.6304 - val_acc: 0.6688 - val_auroc: 0.7377 - val_f1: 0.6687\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4331 - acc: 0.8069 - auroc: 0.9082 - f1: 0.8069 - val_loss: 0.7438 - val_acc: 0.6625 - val_auroc: 0.7461 - val_f1: 0.6625\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3685 - acc: 0.8431 - auroc: 0.9460 - f1: 0.8431 - val_loss: 0.9361 - val_acc: 0.6438 - val_auroc: 0.7111 - val_f1: 0.6437\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3657 - acc: 0.8451 - auroc: 0.9660 - f1: 0.8451 - val_loss: 0.7817 - val_acc: 0.6625 - val_auroc: 0.7486 - val_f1: 0.6625\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3495 - acc: 0.8618 - auroc: 0.9715 - f1: 0.8618 - val_loss: 0.7462 - val_acc: 0.6938 - val_auroc: 0.7582 - val_f1: 0.6937\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2491 - acc: 0.8979 - auroc: 0.9861 - f1: 0.8979 - val_loss: 0.8643 - val_acc: 0.6875 - val_auroc: 0.7425 - val_f1: 0.6875\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1797 - acc: 0.9410 - auroc: 0.9908 - f1: 0.9410 - val_loss: 1.1985 - val_acc: 0.6063 - val_auroc: 0.7090 - val_f1: 0.6062\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.6580 - acc: 0.6160 - auroc: 0.6715 - f1: 0.6160 - val_loss: 0.6661 - val_acc: 0.6313 - val_auroc: 0.6852 - val_f1: 0.6312\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4687 - acc: 0.7736 - auroc: 0.9029 - f1: 0.7736 - val_loss: 0.7100 - val_acc: 0.6438 - val_auroc: 0.6762 - val_f1: 0.6437\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3935 - acc: 0.8319 - auroc: 0.9463 - f1: 0.8319 - val_loss: 0.9866 - val_acc: 0.5438 - val_auroc: 0.6598 - val_f1: 0.5437\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3101 - acc: 0.8660 - auroc: 0.9689 - f1: 0.8660 - val_loss: 0.8532 - val_acc: 0.6188 - val_auroc: 0.6645 - val_f1: 0.6187\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3043 - acc: 0.8694 - auroc: 0.9764 - f1: 0.8694 - val_loss: 1.0053 - val_acc: 0.5813 - val_auroc: 0.6472 - val_f1: 0.5812\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3920 - acc: 0.8139 - auroc: 0.9736 - f1: 0.8139 - val_loss: 0.9282 - val_acc: 0.5813 - val_auroc: 0.6621 - val_f1: 0.5812\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2581 - acc: 0.8965 - auroc: 0.9827 - f1: 0.8965 - val_loss: 0.9007 - val_acc: 0.6000 - val_auroc: 0.6717 - val_f1: 0.6000\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.6776 - acc: 0.5938 - auroc: 0.6468 - f1: 0.5937 - val_loss: 0.6252 - val_acc: 0.6813 - val_auroc: 0.7478 - val_f1: 0.6812\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4548 - acc: 0.8007 - auroc: 0.8921 - f1: 0.8007 - val_loss: 0.5913 - val_acc: 0.7125 - val_auroc: 0.7996 - val_f1: 0.7125\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3575 - acc: 0.8410 - auroc: 0.9440 - f1: 0.8410 - val_loss: 0.5900 - val_acc: 0.7063 - val_auroc: 0.7993 - val_f1: 0.7062\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2959 - acc: 0.8812 - auroc: 0.9643 - f1: 0.8812 - val_loss: 1.0550 - val_acc: 0.6250 - val_auroc: 0.7915 - val_f1: 0.6250\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3046 - acc: 0.8708 - auroc: 0.9726 - f1: 0.8708 - val_loss: 0.6244 - val_acc: 0.7313 - val_auroc: 0.8020 - val_f1: 0.7312\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3570 - acc: 0.8465 - auroc: 0.9805 - f1: 0.8465 - val_loss: 0.6995 - val_acc: 0.7125 - val_auroc: 0.8146 - val_f1: 0.7125\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3526 - acc: 0.8431 - auroc: 0.9785 - f1: 0.8431 - val_loss: 0.5992 - val_acc: 0.7500 - val_auroc: 0.8204 - val_f1: 0.7500\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2189 - acc: 0.9062 - auroc: 0.9892 - f1: 0.9062 - val_loss: 0.8459 - val_acc: 0.6688 - val_auroc: 0.8076 - val_f1: 0.6687\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1462 - acc: 0.9458 - auroc: 0.9952 - f1: 0.9458 - val_loss: 0.6970 - val_acc: 0.7062 - val_auroc: 0.8139 - val_f1: 0.7062\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.6452 - acc: 0.6229 - auroc: 0.6895 - f1: 0.6229 - val_loss: 0.6535 - val_acc: 0.6563 - val_auroc: 0.6727 - val_f1: 0.6562\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4247 - acc: 0.8208 - auroc: 0.9057 - f1: 0.8208 - val_loss: 0.7020 - val_acc: 0.6188 - val_auroc: 0.6805 - val_f1: 0.6187\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3454 - acc: 0.8514 - auroc: 0.9481 - f1: 0.8514 - val_loss: 0.7310 - val_acc: 0.6125 - val_auroc: 0.6887 - val_f1: 0.6125\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3491 - acc: 0.8382 - auroc: 0.9637 - f1: 0.8382 - val_loss: 0.9472 - val_acc: 0.5813 - val_auroc: 0.6657 - val_f1: 0.5812\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2623 - acc: 0.8931 - auroc: 0.9800 - f1: 0.8931 - val_loss: 0.8771 - val_acc: 0.6187 - val_auroc: 0.7104 - val_f1: 0.6187\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2167 - acc: 0.9201 - auroc: 0.9857 - f1: 0.9201 - val_loss: 1.0768 - val_acc: 0.6687 - val_auroc: 0.6664 - val_f1: 0.6687\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3064 - acc: 0.8611 - auroc: 0.9845 - f1: 0.8611 - val_loss: 1.1261 - val_acc: 0.6563 - val_auroc: 0.6794 - val_f1: 0.6562\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.6509 - acc: 0.6243 - auroc: 0.6751 - f1: 0.6243 - val_loss: 0.6542 - val_acc: 0.6938 - val_auroc: 0.7068 - val_f1: 0.6937\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4149 - acc: 0.8257 - auroc: 0.9111 - f1: 0.8257 - val_loss: 0.7610 - val_acc: 0.6750 - val_auroc: 0.7360 - val_f1: 0.6750\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 2ms/step - loss: 0.3305 - acc: 0.8576 - auroc: 0.9522 - f1: 0.8576 - val_loss: 0.7721 - val_acc: 0.6813 - val_auroc: 0.7281 - val_f1: 0.6812\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2992 - acc: 0.8743 - auroc: 0.9729 - f1: 0.8743 - val_loss: 0.9029 - val_acc: 0.6688 - val_auroc: 0.7336 - val_f1: 0.6687\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3187 - acc: 0.8653 - auroc: 0.9747 - f1: 0.8653 - val_loss: 1.0666 - val_acc: 0.6375 - val_auroc: 0.7374 - val_f1: 0.6375\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2460 - acc: 0.8972 - auroc: 0.9876 - f1: 0.8972 - val_loss: 1.0551 - val_acc: 0.6625 - val_auroc: 0.7191 - val_f1: 0.6625\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2812 - acc: 0.8632 - auroc: 0.9895 - f1: 0.8632 - val_loss: 1.0073 - val_acc: 0.6188 - val_auroc: 0.6891 - val_f1: 0.6187\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "conv_bow_scores = run_cross_validate(evaluate_conv_model, convolutional_data, labels, splitter, cv=5, categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'val_accuracy': 0.6750000074505806,\n",
       "   'val_auroc': 0.6639380869097562,\n",
       "   'val_f1': 0.6749999567866325,\n",
       "   'val_loss': 0.6233259193599224},\n",
       "  {'val_accuracy': 0.6812499977648259,\n",
       "   'val_auroc': 0.897156350173233,\n",
       "   'val_f1': 0.6812499381601811,\n",
       "   'val_loss': 0.6350157566368579},\n",
       "  {'val_accuracy': 0.6062499970197678,\n",
       "   'val_auroc': 0.6725833104099161,\n",
       "   'val_f1': 0.606249937415123,\n",
       "   'val_loss': 0.6531951859593391},\n",
       "  {'val_accuracy': 0.6625000074505806,\n",
       "   'val_auroc': 0.6633828478918455,\n",
       "   'val_f1': 0.6624999478459358,\n",
       "   'val_loss': 0.6348572403192521},\n",
       "  {'val_accuracy': 0.7062499992549419,\n",
       "   'val_auroc': 0.6704178936125917,\n",
       "   'val_f1': 0.7062499485909939,\n",
       "   'val_loss': 0.6655074551701545},\n",
       "  {'val_accuracy': 0.6687500059604645,\n",
       "   'val_auroc': 0.6719984018270785,\n",
       "   'val_f1': 0.6687499463558197,\n",
       "   'val_loss': 0.6304114423692226},\n",
       "  {'val_accuracy': 0.6312500081956387,\n",
       "   'val_auroc': 0.6715457780372343,\n",
       "   'val_f1': 0.6312499485909939,\n",
       "   'val_loss': 0.6661339655518532},\n",
       "  {'val_accuracy': 0.7062500089406967,\n",
       "   'val_auroc': 0.9440360841088878,\n",
       "   'val_f1': 0.7062499493360519,\n",
       "   'val_loss': 0.5899709276854992},\n",
       "  {'val_accuracy': 0.6562500119209289,\n",
       "   'val_auroc': 0.689514959713152,\n",
       "   'val_f1': 0.6562499523162841,\n",
       "   'val_loss': 0.653499910235405},\n",
       "  {'val_accuracy': 0.6937500052154064,\n",
       "   'val_auroc': 0.6750996550179229,\n",
       "   'val_f1': 0.6937499456107616,\n",
       "   'val_loss': 0.6541507199406624}],\n",
       " 0.6687500049173832)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_bow_bests = results(conv_bow_scores)\n",
    "conv_bow_bests, statistics.mean([x['val_accuracy'] for x in conv_bow_bests])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter out reviews with more than 300 words because a small number have an exceptionally large number of words and dramatically increase the memory requirements. These reviews are rare and are not expected to provide much value, while also preventing this experiment from being run on a normal machine, so I will filter them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_words = []\n",
    "conv_wv_labels = []\n",
    "for i, raw_feature in enumerate(raw_features):\n",
    "    word_sequence = text_to_word_sequence(raw_feature)\n",
    "    if len(word_sequence) > 320:\n",
    "        continue\n",
    "    conv_wv_labels.append(labels[i])\n",
    "    reviews_words.append(word_sequence)\n",
    "max_review_len = max([len(x) for x in reviews_words])\n",
    "\n",
    "vectorized_reviews = np.zeros((len(reviews_words), max_review_len, 300, 1))\n",
    "for i, review in enumerate(reviews_words):\n",
    "    for j, word in enumerate(review):\n",
    "        vectorized_reviews[i][j] = [[x] for x in embedding_matrix[corpus_words[word]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_conv_wv_model():\n",
    "  model = Sequential([\n",
    "      Conv2D(\n",
    "          filters=50,\n",
    "          kernel_size=(10, 300),\n",
    "          data_format=\"channels_last\",\n",
    "          input_shape=(320, 300, 1),\n",
    "          activation=relu),\n",
    "      MaxPooling2D(strides=(1, 1), pool_size=(2, 1), data_format=\"channels_last\"),\n",
    "      Dropout(0.2),\n",
    "      Flatten(),\n",
    "      Dense(2, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_conv_wv_model(train_X, train_y, test_X, test_y):\n",
    "    conv_model = get_conv_wv_model()\n",
    "    return conv_model.fit(train_X, train_y, epochs=25, batch_size=34, verbose=1, shuffle=False,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=6)],\n",
    "                   validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.6420 - acc: 0.6142 - auroc: 0.7063 - f1: 0.6142 - val_loss: 0.6276 - val_acc: 0.6667 - val_auroc: 0.7695 - val_f1: 0.6667\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.4445 - acc: 0.7936 - auroc: 0.9236 - f1: 0.7936 - val_loss: 0.4769 - val_acc: 0.7647 - val_auroc: 0.8440 - val_f1: 0.7647\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2649 - acc: 0.9015 - auroc: 0.9823 - f1: 0.9015 - val_loss: 0.5798 - val_acc: 0.7386 - val_auroc: 0.8558 - val_f1: 0.7386\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1641 - acc: 0.9577 - auroc: 0.9974 - f1: 0.9577 - val_loss: 0.5319 - val_acc: 0.7320 - val_auroc: 0.8396 - val_f1: 0.7320\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1039 - acc: 0.9810 - auroc: 0.9997 - f1: 0.9810 - val_loss: 1.2543 - val_acc: 0.6405 - val_auroc: 0.7984 - val_f1: 0.6405\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1403 - acc: 0.9555 - auroc: 0.9998 - f1: 0.9555 - val_loss: 0.6233 - val_acc: 0.6797 - val_auroc: 0.7979 - val_f1: 0.6797\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0467 - acc: 0.9927 - auroc: 1.0000 - f1: 0.9927 - val_loss: 0.6262 - val_acc: 0.6928 - val_auroc: 0.8201 - val_f1: 0.6928\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0165 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.6532 - val_acc: 0.7255 - val_auroc: 0.8140 - val_f1: 0.7255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f170ea5d898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skennedy/jupiter/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/skennedy/jupiter/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: No such callable handle: 94915988648672\n",
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f16683b8b70>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skennedy/jupiter/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/skennedy/jupiter/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: No such callable handle: 94916301607504\n",
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f1644629ef0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skennedy/jupiter/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/skennedy/jupiter/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: No such callable handle: 94916756992176\n",
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f16387bec50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skennedy/jupiter/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/skennedy/jupiter/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: No such callable handle: 94916251038672\n",
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f16382b7a20>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/skennedy/jupiter/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/home/skennedy/jupiter/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: No such callable handle: 94916448227824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.6463 - acc: 0.6163 - auroc: 0.7069 - f1: 0.6163 - val_loss: 0.5587 - val_acc: 0.6863 - val_auroc: 0.8042 - val_f1: 0.6863\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.4195 - acc: 0.8082 - auroc: 0.9209 - f1: 0.8082 - val_loss: 0.4839 - val_acc: 0.7712 - val_auroc: 0.8521 - val_f1: 0.7712\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2698 - acc: 0.8950 - auroc: 0.9868 - f1: 0.8950 - val_loss: 0.4718 - val_acc: 0.7778 - val_auroc: 0.8665 - val_f1: 0.7778\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1625 - acc: 0.9482 - auroc: 0.9987 - f1: 0.9482 - val_loss: 0.6015 - val_acc: 0.7255 - val_auroc: 0.8589 - val_f1: 0.7255\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1067 - acc: 0.9759 - auroc: 0.9995 - f1: 0.9759 - val_loss: 1.1558 - val_acc: 0.6078 - val_auroc: 0.8377 - val_f1: 0.6078\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1329 - acc: 0.9570 - auroc: 1.0000 - f1: 0.9570 - val_loss: 0.5777 - val_acc: 0.7255 - val_auroc: 0.8245 - val_f1: 0.7255\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0500 - acc: 0.9927 - auroc: 1.0000 - f1: 0.9927 - val_loss: 0.6943 - val_acc: 0.7386 - val_auroc: 0.8473 - val_f1: 0.7386\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0236 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.5873 - val_acc: 0.7712 - val_auroc: 0.8402 - val_f1: 0.7712\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0137 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.6008 - val_acc: 0.7647 - val_auroc: 0.8425 - val_f1: 0.7647\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 5s 3ms/step - loss: 0.6605 - acc: 0.6076 - auroc: 0.6869 - f1: 0.6076 - val_loss: 0.5185 - val_acc: 0.7647 - val_auroc: 0.8498 - val_f1: 0.7647\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.4487 - acc: 0.7936 - auroc: 0.8935 - f1: 0.7936 - val_loss: 0.4056 - val_acc: 0.8039 - val_auroc: 0.9021 - val_f1: 0.8039\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2712 - acc: 0.9008 - auroc: 0.9694 - f1: 0.9008 - val_loss: 0.3821 - val_acc: 0.8235 - val_auroc: 0.9075 - val_f1: 0.8235\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1641 - acc: 0.9519 - auroc: 0.9969 - f1: 0.9519 - val_loss: 0.3664 - val_acc: 0.8170 - val_auroc: 0.9087 - val_f1: 0.8170\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2091 - acc: 0.9147 - auroc: 0.9990 - f1: 0.9147 - val_loss: 0.5768 - val_acc: 0.7190 - val_auroc: 0.8950 - val_f1: 0.7190\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1025 - acc: 0.9788 - auroc: 1.0000 - f1: 0.9788 - val_loss: 0.4886 - val_acc: 0.7908 - val_auroc: 0.8857 - val_f1: 0.7908\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0387 - acc: 0.9978 - auroc: 1.0000 - f1: 0.9978 - val_loss: 0.5442 - val_acc: 0.7778 - val_auroc: 0.8906 - val_f1: 0.7778\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0241 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4690 - val_acc: 0.8170 - val_auroc: 0.8960 - val_f1: 0.8170\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0168 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.5184 - val_acc: 0.8105 - val_auroc: 0.8930 - val_f1: 0.8105\n",
      "Epoch 10/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0132 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4718 - val_acc: 0.8170 - val_auroc: 0.9001 - val_f1: 0.8170\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 5s 3ms/step - loss: 0.6368 - acc: 0.6317 - auroc: 0.7305 - f1: 0.6317 - val_loss: 0.5536 - val_acc: 0.7059 - val_auroc: 0.8142 - val_f1: 0.7059\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.3943 - acc: 0.8155 - auroc: 0.9222 - f1: 0.8155 - val_loss: 0.5696 - val_acc: 0.7386 - val_auroc: 0.8977 - val_f1: 0.7386\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2880 - acc: 0.8877 - auroc: 0.9821 - f1: 0.8877 - val_loss: 0.4267 - val_acc: 0.8170 - val_auroc: 0.8962 - val_f1: 0.8170\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2276 - acc: 0.9139 - auroc: 0.9958 - f1: 0.9139 - val_loss: 0.4028 - val_acc: 0.8170 - val_auroc: 0.9055 - val_f1: 0.8170\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0883 - acc: 0.9869 - auroc: 0.9997 - f1: 0.9869 - val_loss: 0.4196 - val_acc: 0.8235 - val_auroc: 0.9073 - val_f1: 0.8235\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0478 - acc: 0.9942 - auroc: 1.0000 - f1: 0.9942 - val_loss: 0.4560 - val_acc: 0.8039 - val_auroc: 0.9136 - val_f1: 0.8039\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0296 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.6338 - val_acc: 0.7190 - val_auroc: 0.9008 - val_f1: 0.7190\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0232 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.4351 - val_acc: 0.8105 - val_auroc: 0.9148 - val_f1: 0.8105\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0139 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.5075 - val_acc: 0.7974 - val_auroc: 0.9103 - val_f1: 0.7974\n",
      "Epoch 10/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0140 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4614 - val_acc: 0.8235 - val_auroc: 0.9157 - val_f1: 0.8235\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 5s 3ms/step - loss: 0.6594 - acc: 0.5952 - auroc: 0.6755 - f1: 0.5952 - val_loss: 0.5194 - val_acc: 0.7386 - val_auroc: 0.8360 - val_f1: 0.7386\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.4299 - acc: 0.8045 - auroc: 0.9097 - f1: 0.8045 - val_loss: 0.3868 - val_acc: 0.8170 - val_auroc: 0.9145 - val_f1: 0.8170\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2774 - acc: 0.8906 - auroc: 0.9776 - f1: 0.8906 - val_loss: 0.3989 - val_acc: 0.7908 - val_auroc: 0.9199 - val_f1: 0.7908\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2145 - acc: 0.9168 - auroc: 0.9966 - f1: 0.9168 - val_loss: 0.4911 - val_acc: 0.7647 - val_auroc: 0.9098 - val_f1: 0.7647\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1077 - acc: 0.9803 - auroc: 0.9990 - f1: 0.9803 - val_loss: 0.4060 - val_acc: 0.8105 - val_auroc: 0.9137 - val_f1: 0.8105\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0503 - acc: 0.9934 - auroc: 1.0000 - f1: 0.9934 - val_loss: 0.3983 - val_acc: 0.8105 - val_auroc: 0.9217 - val_f1: 0.8105\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0357 - acc: 0.9978 - auroc: 1.0000 - f1: 0.9978 - val_loss: 0.4517 - val_acc: 0.7778 - val_auroc: 0.9086 - val_f1: 0.7778\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0166 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3936 - val_acc: 0.7974 - val_auroc: 0.9173 - val_f1: 0.7974\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 5s 3ms/step - loss: 0.6535 - acc: 0.6280 - auroc: 0.6919 - f1: 0.6280 - val_loss: 0.5779 - val_acc: 0.6928 - val_auroc: 0.7695 - val_f1: 0.6928\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.4177 - acc: 0.8118 - auroc: 0.9172 - f1: 0.8118 - val_loss: 0.5332 - val_acc: 0.7451 - val_auroc: 0.8126 - val_f1: 0.7451\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2707 - acc: 0.8972 - auroc: 0.9764 - f1: 0.8972 - val_loss: 0.6068 - val_acc: 0.7386 - val_auroc: 0.8126 - val_f1: 0.7386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2079 - acc: 0.9103 - auroc: 0.9959 - f1: 0.9103 - val_loss: 0.8328 - val_acc: 0.6340 - val_auroc: 0.8073 - val_f1: 0.6340\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1072 - acc: 0.9767 - auroc: 0.9991 - f1: 0.9767 - val_loss: 0.7317 - val_acc: 0.7059 - val_auroc: 0.8010 - val_f1: 0.7059\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0398 - acc: 0.9949 - auroc: 1.0000 - f1: 0.9949 - val_loss: 0.6924 - val_acc: 0.7516 - val_auroc: 0.8095 - val_f1: 0.7516\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0207 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.8565 - val_acc: 0.7386 - val_auroc: 0.8080 - val_f1: 0.7386\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0150 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.8619 - val_acc: 0.7320 - val_auroc: 0.8087 - val_f1: 0.7320\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 5s 3ms/step - loss: 0.6541 - acc: 0.5981 - auroc: 0.7028 - f1: 0.5981 - val_loss: 0.5000 - val_acc: 0.7843 - val_auroc: 0.8725 - val_f1: 0.7843\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.4068 - acc: 0.8308 - auroc: 0.9204 - f1: 0.8308 - val_loss: 0.4028 - val_acc: 0.8235 - val_auroc: 0.9122 - val_f1: 0.8235\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2835 - acc: 0.8840 - auroc: 0.9851 - f1: 0.8840 - val_loss: 0.3894 - val_acc: 0.8431 - val_auroc: 0.9122 - val_f1: 0.8431\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1639 - acc: 0.9504 - auroc: 0.9977 - f1: 0.9504 - val_loss: 0.5166 - val_acc: 0.7712 - val_auroc: 0.9139 - val_f1: 0.7712\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0709 - acc: 0.9920 - auroc: 0.9999 - f1: 0.9920 - val_loss: 0.7128 - val_acc: 0.7059 - val_auroc: 0.8997 - val_f1: 0.7059\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0654 - acc: 0.9934 - auroc: 1.0000 - f1: 0.9934 - val_loss: 0.3959 - val_acc: 0.8301 - val_auroc: 0.9106 - val_f1: 0.8301\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0510 - acc: 0.9956 - auroc: 1.0000 - f1: 0.9956 - val_loss: 0.4056 - val_acc: 0.8497 - val_auroc: 0.9099 - val_f1: 0.8497\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0161 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.5031 - val_acc: 0.8301 - val_auroc: 0.9073 - val_f1: 0.8301\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0115 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4279 - val_acc: 0.8431 - val_auroc: 0.9112 - val_f1: 0.8431\n",
      "Train on 1373 samples, validate on 151 samples\n",
      "Epoch 1/25\n",
      "1373/1373 [==============================] - 5s 3ms/step - loss: 0.6533 - acc: 0.6103 - auroc: 0.7040 - f1: 0.6103 - val_loss: 0.5473 - val_acc: 0.7682 - val_auroc: 0.8168 - val_f1: 0.7682\n",
      "Epoch 2/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.4184 - acc: 0.8128 - auroc: 0.9255 - f1: 0.8128 - val_loss: 0.4474 - val_acc: 0.8146 - val_auroc: 0.8891 - val_f1: 0.8146\n",
      "Epoch 3/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.2638 - acc: 0.8951 - auroc: 0.9821 - f1: 0.8951 - val_loss: 0.4144 - val_acc: 0.8013 - val_auroc: 0.8925 - val_f1: 0.8013\n",
      "Epoch 4/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.1421 - acc: 0.9563 - auroc: 0.9977 - f1: 0.9563 - val_loss: 0.4554 - val_acc: 0.7748 - val_auroc: 0.8894 - val_f1: 0.7748\n",
      "Epoch 5/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0980 - acc: 0.9832 - auroc: 1.0000 - f1: 0.9832 - val_loss: 0.4659 - val_acc: 0.7815 - val_auroc: 0.8957 - val_f1: 0.7815\n",
      "Epoch 6/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0446 - acc: 0.9949 - auroc: 1.0000 - f1: 0.9949 - val_loss: 0.5009 - val_acc: 0.8079 - val_auroc: 0.8961 - val_f1: 0.8079\n",
      "Epoch 7/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0386 - acc: 0.9978 - auroc: 1.0000 - f1: 0.9978 - val_loss: 0.4721 - val_acc: 0.8013 - val_auroc: 0.8960 - val_f1: 0.8013\n",
      "Epoch 8/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0193 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.5076 - val_acc: 0.7815 - val_auroc: 0.8914 - val_f1: 0.7815\n",
      "Epoch 9/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0121 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.5286 - val_acc: 0.7748 - val_auroc: 0.8899 - val_f1: 0.7748\n",
      "Train on 1373 samples, validate on 151 samples\n",
      "Epoch 1/25\n",
      "1373/1373 [==============================] - 5s 4ms/step - loss: 0.6524 - acc: 0.5885 - auroc: 0.6870 - f1: 0.5885 - val_loss: 0.5184 - val_acc: 0.7748 - val_auroc: 0.8630 - val_f1: 0.7748\n",
      "Epoch 2/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.4308 - acc: 0.7997 - auroc: 0.9076 - f1: 0.7997 - val_loss: 0.3979 - val_acc: 0.8278 - val_auroc: 0.9252 - val_f1: 0.8278\n",
      "Epoch 3/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.2510 - acc: 0.9090 - auroc: 0.9861 - f1: 0.9090 - val_loss: 0.3564 - val_acc: 0.8609 - val_auroc: 0.9378 - val_f1: 0.8609\n",
      "Epoch 4/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.2141 - acc: 0.9206 - auroc: 0.9976 - f1: 0.9206 - val_loss: 0.3624 - val_acc: 0.8344 - val_auroc: 0.9289 - val_f1: 0.8344\n",
      "Epoch 5/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.1027 - acc: 0.9869 - auroc: 0.9990 - f1: 0.9869 - val_loss: 0.4760 - val_acc: 0.7881 - val_auroc: 0.9264 - val_f1: 0.7881\n",
      "Epoch 6/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0484 - acc: 0.9964 - auroc: 1.0000 - f1: 0.9964 - val_loss: 0.3791 - val_acc: 0.8477 - val_auroc: 0.9218 - val_f1: 0.8477\n",
      "Epoch 7/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0307 - acc: 0.9978 - auroc: 1.0000 - f1: 0.9978 - val_loss: 0.5830 - val_acc: 0.7748 - val_auroc: 0.9217 - val_f1: 0.7748\n",
      "Epoch 8/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0273 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.6345 - val_acc: 0.7417 - val_auroc: 0.9160 - val_f1: 0.7417\n",
      "Epoch 9/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0303 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3918 - val_acc: 0.8477 - val_auroc: 0.9242 - val_f1: 0.8477\n",
      "Train on 1373 samples, validate on 151 samples\n",
      "Epoch 1/25\n",
      "1373/1373 [==============================] - 6s 4ms/step - loss: 0.6396 - acc: 0.6184 - auroc: 0.7197 - f1: 0.6184 - val_loss: 0.5829 - val_acc: 0.6954 - val_auroc: 0.7923 - val_f1: 0.6954\n",
      "Epoch 2/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.3849 - acc: 0.8288 - auroc: 0.9285 - f1: 0.8288 - val_loss: 0.5825 - val_acc: 0.7550 - val_auroc: 0.8444 - val_f1: 0.7550\n",
      "Epoch 3/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.2690 - acc: 0.8995 - auroc: 0.9870 - f1: 0.8995 - val_loss: 0.5404 - val_acc: 0.7550 - val_auroc: 0.8487 - val_f1: 0.7550\n",
      "Epoch 4/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.2024 - acc: 0.9228 - auroc: 0.9968 - f1: 0.9228 - val_loss: 0.5786 - val_acc: 0.7219 - val_auroc: 0.8306 - val_f1: 0.7219\n",
      "Epoch 5/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0931 - acc: 0.9825 - auroc: 0.9994 - f1: 0.9825 - val_loss: 0.6818 - val_acc: 0.7682 - val_auroc: 0.8467 - val_f1: 0.7682\n",
      "Epoch 6/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0503 - acc: 0.9956 - auroc: 1.0000 - f1: 0.9956 - val_loss: 0.6385 - val_acc: 0.7616 - val_auroc: 0.8561 - val_f1: 0.7616\n",
      "Epoch 7/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0366 - acc: 0.9971 - auroc: 1.0000 - f1: 0.9971 - val_loss: 0.7177 - val_acc: 0.6887 - val_auroc: 0.8474 - val_f1: 0.6887\n",
      "Epoch 8/25\n",
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0178 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.6943 - val_acc: 0.7417 - val_auroc: 0.8563 - val_f1: 0.7417\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373/1373 [==============================] - 4s 3ms/step - loss: 0.0109 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.8291 - val_acc: 0.7881 - val_auroc: 0.8510 - val_f1: 0.7881\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "conv_wv_scores = run_cross_validate(evaluate_conv_wv_model, vectorized_reviews, conv_wv_labels, splitter, cv=5, categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'val_accuracy': 0.7647058831320869,\n",
       "   'val_auroc': 0.923649985482691,\n",
       "   'val_f1': 0.7647058235274421,\n",
       "   'val_loss': 0.4768942395846049},\n",
       "  {'val_accuracy': 0.7777777711550394,\n",
       "   'val_auroc': 0.9867663568264303,\n",
       "   'val_f1': 0.7777777115503947,\n",
       "   'val_loss': 0.47183707025316024},\n",
       "  {'val_accuracy': 0.8169934484693739,\n",
       "   'val_auroc': 0.9969400230426679,\n",
       "   'val_f1': 0.8169934021102058,\n",
       "   'val_loss': 0.3663615584373474},\n",
       "  {'val_accuracy': 0.8169934683375888,\n",
       "   'val_auroc': 0.9957537389386208,\n",
       "   'val_f1': 0.816993408732944,\n",
       "   'val_loss': 0.40283940566910637},\n",
       "  {'val_accuracy': 0.8169934617148505,\n",
       "   'val_auroc': 0.9097047619062407,\n",
       "   'val_f1': 0.8169934021102058,\n",
       "   'val_loss': 0.38680093155966866},\n",
       "  {'val_accuracy': 0.7450980411635505,\n",
       "   'val_auroc': 0.9172405781157582,\n",
       "   'val_f1': 0.7450979815589057,\n",
       "   'val_loss': 0.5332120921876695},\n",
       "  {'val_accuracy': 0.843137244383494,\n",
       "   'val_auroc': 0.9850870576961452,\n",
       "   'val_f1': 0.8431371980243259,\n",
       "   'val_loss': 0.3894093963834975},\n",
       "  {'val_accuracy': 0.8013244950218706,\n",
       "   'val_auroc': 0.9820581163682807,\n",
       "   'val_f1': 0.801324441338217,\n",
       "   'val_loss': 0.4143622138642317},\n",
       "  {'val_accuracy': 0.8609271606072685,\n",
       "   'val_auroc': 0.9860513320583862,\n",
       "   'val_f1': 0.8609271010026237,\n",
       "   'val_loss': 0.35635328075743666},\n",
       "  {'val_accuracy': 0.7549668886014168,\n",
       "   'val_auroc': 0.9869896820524978,\n",
       "   'val_f1': 0.754966828996772,\n",
       "   'val_loss': 0.5403926846207372}],\n",
       " 0.799891786258654)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_wv_bests = results(conv_wv_scores)\n",
    "conv_wv_bests, statistics.mean([x['val_accuracy'] for x in conv_wv_bests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_scores_entries =[('Bag of Words', x['val_accuracy']) for x in conv_bow_bests] + [('Word Vectors', x['val_accuracy']) for x in conv_wv_bests]\n",
    "conv_scores_data_frame = DataFrame(conv_scores_entries, columns=['input type', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGi1JREFUeJzt3Xu0nXV95/H3h0MhoZSLEF1jMARJEHAxQk1pFW21Cs3YWux0RoO6xEulN2O0rR2cOspgq6gdbUwZR3RQtBVErZgqAwsUbxAlh4tGUpRTVMzRahpQQa5JvvPH8xyyc0jy7GB29g7n/Vprr7Of334u35Pssz/79/z2/j2pKiRJ2pG9hl2AJGn0GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjrtPewCdpVDDz205s+fP+wyJGmPct111/17Vc3pWu8RExbz589nfHx82GVI0h4lyXf7Wc/TUJKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSer0iPmehaTBWrFiBRMTE8Mug8nJSQDmzp071DoWLFjA0qVLh1rD7mRYSNqj3HPPPcMuYUYyLCT1ZVTeRS9btgyA5cuXD7mSmcUxC0lSJ8NCktTJsJAkdRpoWCRZnOSbSSaSnLmNx+cluSrJDUm+nuQ5bfv8JPckubG9/Z9B1ilJ2rGBDXAnGQPOBU4G1gGrk6ysqrU9q70BuLiq3pPkWOBSYH772L9W1fGDqk+S1L9B9ixOBCaq6taquh+4CDh12joFHNDePxD4/gDrkSQ9TIMMi7nA93qW17Vtvc4CXpxkHU2vovezeUe0p6e+kOTpA6xTktRh2APcpwEfrKrDgOcAH06yF/ADYF5VnQD8GfCRJAdM3zjJGUnGk4yvX79+txYuSTPJIMNiEnhcz/JhbVuvVwAXA1TVKmAWcGhV3VdVG9r264B/BY6afoCqOq+qFlXVojlzOi8hK0l6mAYZFquBhUmOSLIPsARYOW2d24BnASQ5hiYs1ieZ0w6Qk+TxwELg1gHWKknagYF9GqqqNiZ5FXA5MAacX1U3JTkbGK+qlcCfA+9L8lqawe6XVlUl+XXg7CQPAJuBP6qq2wdVqyRpxwY6N1RVXUozcN3b9sae+2uBk7ax3SeATwyyNklS/4Y9wC1J2gMYFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSp00CvwS1p11ixYgUTExPDLmMkTP07LFu2bMiVjIYFCxawdOnSgR/HsJD2ABMTE9xy0w3M23/TsEsZun0eaE6I3Pfd8SFXMny33TW2245lWEh7iHn7b+K///JPh12GRshbrj9gtx3LMQtJUifDQpLUybCQJHVyzELaA0xOTvKzO8d26zlqjb7v3jnGL05O7pZj2bOQJHWyZyHtAebOnct9G3/gp6G0lbdcfwD7zp27W45lz0KS1MmwkCR1GmhYJFmc5JtJJpKcuY3H5yW5KskNSb6e5Dk9j72+3e6bSX5rkHVKknZsYGMWScaAc4GTgXXA6iQrq2ptz2pvAC6uqvckORa4FJjf3l8CPBF4LHBlkqOqyrkOJGkIBtmzOBGYqKpbq+p+4CLg1GnrFDD1WcADge+3908FLqqq+6rq28BEuz9J0hAMMizmAt/rWV7XtvU6C3hxknU0vYqpqRP72VaStJsMe4D7NOCDVXUY8Bzgw0n6rinJGUnGk4yvX79+YEVK0kw3yLCYBB7Xs3xY29brFcDFAFW1CpgFHNrntlTVeVW1qKoWzZkzZxeWLknqNciwWA0sTHJEkn1oBqxXTlvnNuBZAEmOoQmL9e16S5Lsm+QIYCFw7QBrlSTtwMA+DVVVG5O8CrgcGAPOr6qbkpwNjFfVSuDPgfcleS3NYPdLq6qAm5JcDKwFNgJ/6iehJGl4BjrdR1VdSjNw3dv2xp77a4GTtrPt3wB/M8j6JEn9GfYAtyRpD2BYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOg30sqqSdp3b7hrjLdcfMOwyhu6HdzfvcR+z3+YhVzJ8t901xsLddCzDQtoDLFiwYNgljIz7JyYA2Pdw/00WsvueG4aFtAdYunTpsEsYGcuWLQNg+fLlQ65kZnHMQpLUybCQJHUyLCRJnQwLSVInw0KS1KmvsEjyT0l+O4nhIkkzUL8v/v8beCFwS5JzkjxhgDVJkkZMX2FRVVdW1YuAXwa+A1yZ5JokL0vyC4MsUJI0fH2fVkpyCPBS4A+AG4DlNOFxxUAqkySNjL6+wZ3kk8ATgA8Dz62qH7QPfTTJ+A62W0wTKmPA+6vqnGmPvwt4Zru4H/DoqjqofWwTsKZ97Laq+t3+fiVJ0q7W73Qf766qq7b1QFUt2lZ7kjHgXOBkYB2wOsnKqlrbs+1re9ZfCpzQs4t7qur4PuuTJA1Qv6ehjk1y0NRCkoOT/EnHNicCE1V1a1XdD1wEnLqD9U8DLuyzHknSbtRvWLyyqn48tVBVdwCv7NhmLvC9nuV1bdtDJDkcOAL4XE/zrCTjSb6S5Hnb2e6Mdp3x9evX9/N7SJIehn7DYixJphbaU0z77MI6lgAfr6pNPW2Ht6e4Xgj8XZIjp29UVedV1aKqWjRnzpxdWI4kqVe/YXEZzWD2s5I8i+Z00WUd20wCj+tZPqxt25YlTDsFVVWT7c9bgc+z9XiGJGk36neA+78Bfwj8cbt8BfD+jm1WAwuTHEETEktoeglbSXI0cDCwqqftYODuqrovyaHAScDb+6xV0gCsWLGCifbCQ8M0VcPUdS2GZcGCBTPqOiN9hUVVbQbe0976UlUbk7wKuJzmo7PnV9VNSc4GxqtqZbvqEuCiqqqezY8B3ptkM03v55zeT1FJmrlmz5497BJmpGz9Gr2dlZKFwFuBY4FZU+1V9fjBlbZzFi1aVOPj2/3KhyRpG5Jct72vQPTqd8ziAzS9io00X6L7EPAPD788SdKepN+wmF1Vn6XpiXy3qs4CfntwZUmSRkm/A9z3tdOT39KOQ0wC+w+uLEnSKOm3Z7GMZu6mVwNPBl4MnD6ooiRJo6WzZ9F+Ae8FVfUXwF3AywZelSRppHT2LNpvVT9tN9QiSRpR/Y5Z3JBkJfAx4GdTjVX1TwOpSpI0UvoNi1nABuA3e9oKMCwkaQbo9xvcjlNI0gzW75XyPkDTk9hKVb18l1ckSRo5/Z6G+nTP/VnA7wHf3/XlSJJGUb+noT7Ru5zkQuDLA6lIkjRy+v1S3nQLgUfvykIkSaOr3zGLO9l6zOLfaK5xIUmaAfo9DfVLgy5EkjS6+joNleT3khzYs3xQkucNrixJ0ijpd8ziTVX1k6mFqvox8KbBlCRJGjX9hsW21uv3Y7eSpD1cv2ExnuSdSY5sb+8ErhtkYZKk0dFvWCwF7gc+ClwE3Av86aCKkiSNln4/DfUz4MwB1yJJGlH9fhrqiiQH9SwfnOTywZUlSRol/Z6GOrT9BBQAVXUHfoNbkmaMfsNic5J5UwtJ5rONWWglSY9M/X789a+ALyf5AhDg6cAZA6tKkjRS+h3gvizJIpqAuAG4BLhnkIVJkkZHvxMJ/gGwDDgMuBH4NWAVW19mVZL0CNXvaahlwK8AX6mqZyY5GnjL4MqauVasWMHExMRQa5icnARg7ty5Q60DYMGCBSxdunTYZUgzXr9hcW9V3ZuEJPtW1c1JnjDQyjQ099zjGUZJW+s3LNa137O4BLgiyR3Ad7s2SrIYWA6MAe+vqnOmPf4u4Jnt4n7Ao6vqoPax04E3tI/9dVVd0Gete7RReBe9bNkyAJYvXz7kSiSNin4HuH+vvXtWkquAA4HLdrRNkjHgXOBkYB2wOsnKqlrbs9/X9qy/FDihvf8omlltF9F8RPe6dts7+v3FJEm7zk5fVrWqvlBVK6vq/o5VTwQmqurWdt2LgFN3sP5pwIXt/d8Crqiq29uAuAJYvLO1SpJ2jYd7De5+zAW+17O8rm17iCSHA0cAn9vZbSVJgzfIsNgZS4CPV9WmndkoyRlJxpOMr1+/fkClSZIGGRaTwON6lg9r27ZlCVtOQfW9bVWdV1WLqmrRnDlzfs5yJUnbM8iwWA0sTHJEkn1oAmHl9JXa72wcTPMlvymXA6e0s9seDJzStkmShmBgl0atqo1JXkXzIj8GnF9VNyU5GxivqqngWAJcVFXVs+3tSd5MEzgAZ1fV7YOqVZK0YwO9jnZVXQpcOq3tjdOWz9rOtucD5w+sOElS30ZlgFuSNMIG2rPYk4zCnEyjYurfYeqb3DOd81NJhsWDJiYmuPEb/8Km/R417FKGbq/7m+Gj62794ZArGb6xux0qk8Cw2Mqm/R7FPUc/Z9hlaITMvvnS7pWkGcAxC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ2cSLA1OTnJ2N0/ceI4bWXs7g1MTm4cdhnS0NmzkCR1smfRmjt3Lv92395OUa6tzL75UubOfcywy5CGzp6FJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROfimvx9jdtzvdB7DXvT8FYPOsA4ZcyfCN3X074JfyJMOitWDBgmGXMDImJu4EYMHjfZGEx/jckDAsHrR06dJhlzAyli1bBsDy5cuHXImkUTHQMYski5N8M8lEkjO3s87zk6xNclOSj/S0b0pyY3tbOcg6JUk7NrCeRZIx4FzgZGAdsDrJyqpa27POQuD1wElVdUeSR/fs4p6qOn5Q9UmS+jfInsWJwERV3VpV9wMXAadOW+eVwLlVdQdAVf1ogPVIkh6mQYbFXOB7Pcvr2rZeRwFHJbk6yVeSLO55bFaS8bb9eQOsU5LUYdgD3HsDC4FnAIcBX0xyXFX9GDi8qiaTPB74XJI1VfWvvRsnOQM4A2DevHm7t3JJmkEG2bOYBB7Xs3xY29ZrHbCyqh6oqm8D36IJD6pqsv15K/B54ITpB6iq86pqUVUtmjNnzq7/DSRJwGDDYjWwMMkRSfYBlgDTP9V0CU2vgiSH0pyWujXJwUn27Wk/CViLJGkoBnYaqqo2JnkVcDkwBpxfVTclORsYr6qV7WOnJFkLbAJeV1UbkjwVeG+SzTSBdk7vp6gkSbvXQMcsqupS4NJpbW/suV/An7W33nWuAY4bZG2SpP45kaAkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSp07BnndU0K1asYGJiYqg1TB1/6vKqw7RgwQIveSuNAMNCDzF79uxhlyBpxBgWI8Z30ZJGkWMWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUeYsOGDbz61a9mw4YNwy5F0ogwLPQQF1xwAWvWrOFDH/rQsEuRNCIMC21lw4YNXHbZZVQVl112mb0LSYBhoWkuuOACNm/eDMCmTZvsXUgCDAtNc+WVV7Jx40YANm7cyBVXXDHkiiSNgoGGRZLFSb6ZZCLJmdtZ5/lJ1ia5KclHetpPT3JLezt9kHVqi2c/+9nsvXdztd29996bk08+ecgVSRoFAwuLJGPAucB/Ao4FTkty7LR1FgKvB06qqicCr2nbHwW8CfhV4ETgTUkOHlSt2uL0009nr72ap8XY2BgveclLhlyRpFEwyJ7FicBEVd1aVfcDFwGnTlvnlcC5VXUHQFX9qG3/LeCKqrq9fewKYPEAa1XrkEMOYfHixSRh8eLFHHLIIcMuSdIIGGRYzAW+17O8rm3rdRRwVJKrk3wlyeKd2FYDcvrpp3PcccfZq5D0oL1H4PgLgWcAhwFfTHJcvxsnOQM4A2DevHmDqG9GOuSQQ3j3u9897DIkjZBB9iwmgcf1LB/WtvVaB6ysqgeq6tvAt2jCo59tqarzqmpRVS2aM2fOLi1ekrTFIMNiNbAwyRFJ9gGWACunrXMJTa+CJIfSnJa6FbgcOCXJwe3A9iltmyRpCAZ2GqqqNiZ5Fc2L/BhwflXdlORsYLyqVrIlFNYCm4DXVdUGgCRvpgkcgLOr6vZB1SpJ2rFU1bBr2CUWLVpU4+Pjwy5DkvYoSa6rqkWd6z1SwiLJeuC7w67jEeRQ4N+HXYS0HT4/d53Dq6pz0PcRExbatZKM9/NuQxoGn5+7n3NDSZI6GRaSpE6GhbbnvGEXIO2Az8/dzDELSVInexaSpE6GxYhKsinJjUm+luT6JE8d8PHmJPlqkhuSPL2n/dQkl/Qsvz7JRM/yc5NM/2b+zhz3GUk+/fAr1+6U5F1JXtOzfHmS9/cs/68kf/Zz7P+sJH8xre03kqya1rZ3kh8meexO7v+gJH/ycOubyQyL0XVPVR1fVU+iuebHWwd8vGcBa6rqhKr6Uk/7NcCv9Sw/Bfhpkke3y09t1+lLe50T7bmupvk/J8leNN93eGLP430/H5L0O4PEl4DDkhze0/Zs4Kaq+n6f+5hyELBTYbETdT6iGRZ7hgOAOwCS7J/ks21vY02SB68RkuR/tFcm/HKSC6e/Q2vXmZ/kc0m+3u5nXpLjgbcDp7a9mdlT61fVeppwWNA2zQU+QfuC0f68ut33aW1N30jytp5j3tW+4/wa8JT2Coo3J7ke+M896/1Ge/wb2x7OL+2Sfz3tStfQvGGAJiS+AdzZzuO2L3AMcH0a72ifC2uSvAAe7El+qe2Nrm3b/irJt5J8GXjC9ANW1WbgYpr55aYsAS5stz8yyWVJrmv3fXTb/pgkn2x7519re+fnAEe2z7F39Ftnkl9M8pl2P9+YWm9GqSpvI3ijmSvrRuBm4CfAk9v2vYED2vuHAhNAgF9p158F/BJwC/AX29jvPwOnt/dfDlzS3n8p8PfbqeUDwEto/pAvoumFvL2t5cftMR8L3AbMads/Bzyv3b6A57f3Z9Fcq2RhW/fFwKd7ajupvb8/sPew/x+8bfP58G1gHvCHwB8BbwaeA5wEfKld5/dpLlo2BjymfW78B5qJQ38GHNGu92RgDbAfzZuiie08bxcBN7T39wV+BDyqXf4ssLC9/6vA59r7HwVe094fAw4E5gPf6Nlvv3X+PvC+nu0OHPb/w+6+2bMYXVOnoY6muUrgh5KE5gX2LUm+DlxJ807/MTR/qJ+qqnur6k6aF95teQowda3zDwNP66OWa2h6EE8FVgHX0vxRngDcXFX30oTV56tqfVVtBP4R+PV2+000vRGAo4FvV9Ut1fzV/UPPca4G3pnk1cBB7X40eqY/H1b1LF/drvM04MKq2lRVPwS+QPMcAbi2mksSADwd+GRV3V1VP+WhM1MDUFXjwP5JnkBzqeavVtXtSfZvj/uxJDcC76V5sQf4TeA97fabquon29h1v3WuAU5O8rYkT9/Ovh7RDIs9QFWtoulFzAFe1P58clUdD/yQ5t36IE2dp34qsKoNo1k07776OT99b1Vt6lqpqs4B/gCYDVw9dTpBI2fq+XAczWmor9C8Cel3vOJnD/O4F9KcfnrwFBTNa9iP2zdWU7djHub+p3uwzqr6FvDLNKHx10neuIuOsccwLPYA7YvmGLCBpiv9o6p6IMkzgalBv6uB5yaZ1b7b+p3t7O4atpz7fRHN4GGXf6E5zfQ04Ia27UaaUxBT7ySvBX4jyaHtIPZpNO/SprsZmJ/kyHb5tJ7f88iqWlNVb6OZnt6wGE3X0Dy/bm/fkd9OM3D8FLaExZeAFyQZSzKHppd57Tb29UXgeUlmt2NUz93BcS8EXkzTY/gUQNsb+XaS/wrQjkE8qV3/s8Aft+1jSQ4E7qQ5TTulrzrbT13dXVX/ALyDJjhmFEf5R9fstlsNzamn06tqU5J/BP45yRpgnObFl6pa3Q7GfZ2mt7GGZqxjuqXAB5K8DlgPvKyrkKqqJF+lOU/7QNu8iuaStte06/wgyZnAVW29n6mqT21jX/emuRzuZ5LcTfPHOvXH+5o2ADcDNwH/r6s2DcUamp7uR6a17V9VUzPBfpImPL5GM2b1l1X1b9N7i1V1fZKPtuv9iC3XsHmIqvqXJD8Drquq3t7Ji4D3JHkD8As042pfA5YB5yV5Bc2p0D+uqlVJrk7yDZrn11/2UydNL+odSTYDD9CG0EziN7gfQZLsX1V3JdmP5h3bGVV1/bDrkrTns2fxyHJekmNpxhMuMCgk7Sr2LCRJnRzgliR1MiwkSZ0MC0lSJ8NCM16SvidC3Il9zk/ywp19TBpVhoVmvKoaxPTv84HtBcKOHpNGkmGhGS/JXe3PZyT5fJKPt7Pi/mM7HxdJvpPk7e3MpNemnYU3yQeT/Jfp+6KZ3fTp7eymr512yK0eS/LFNDP/Tu3jy0melObaDh9OsirJLUle2bPO65KsTjN78P8czL+MtIVhIW3tBOA1wLHA42kmaJzyk6o6Dvh74O869nMmzQysx1fVuzoe+780s/6S5ChgVlV9rV33P9JMb/EU4I1JHpvkFJpZe08EjgeenOTXkQbIsJC2dm1VravmGgo30pwymnJhz8+nTN/w5/Ax4HeS/ALNtPEf7HnsU1V1TzuNxlU0AXFKe7sBuJ5mDq2Fu7Ae6SH8Bre0tft67m9i67+R2sb9jbRvutJcOW6fnT1gVd2d5ArgVOD5NNd42NYxp5YDvLWq3ruzx5IeLnsWUv9e0PNz6prQ32HLi/vv0kxkBw+d3bTXth57P/BuYHVV3dHTfmo7k/AhNFPCrwYuB17ezi5MkrnZcplbaSDsWUj9O7i96NR9bJla/X3Ap9JcMvYytlwD4evAprb9g9PGLR7yWFVdl+SnNFclZNq6V9HM8vrmaq45/f0kxwCr2vH3u2im7v7RLv59pQc5N5TUhyTfARb1TMG9q/f/WODzwNHteAlJzgLuqqq/HcQxpZ3haShpyJK8BPgq8FdTQSGNGnsWkqRO9iwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUqf/D45IGCWMIoyaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(x='input type', y='accuracy', data=conv_scores_data_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again our results look better. If this continues to be consistent we know that Word2Vec has some property that is beneficial, which may be training on more data, or it may be the higher vector dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final experiment we will run to test the results of using pretrained Word2Vec embeddings will be our LSTM network. \n",
    "In the previous test we did with word embeddings, our accuracy was 50%, so simply a random guess. Following the trend above of pretrained embeddings giving us better accuracies, we will run a test and see if this can give any improvements for the LSTM network.\n",
    "\n",
    "First, let's get our BOW accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 1600\n",
    "padded = pad_sequences(bow_features)\n",
    "rnn_bow = np.array(np.split(padded, batches))\n",
    "max_len_bow = max([len(x) for x in padded])\n",
    "rnn_bow_targets = np.array([[x] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_bow_model():\n",
    "  model = Sequential([\n",
    "      LSTM(20, input_shape=(1, max_len_bow)),\n",
    "      Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_model(train_X, train_y, test_X, test_y):\n",
    "    lstm_model = get_rnn_bow_model()\n",
    "    return lstm_model.fit(train_X, train_y, epochs=25, batch_size=32, verbose=1, shuffle=False,\n",
    "                          callbacks=[EarlyStopping(monitor='val_loss', patience=6)], validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.5215 - acc: 0.7861 - auroc: 0.8588 - f1: 0.8026 - val_loss: 0.3013 - val_acc: 0.8750 - val_auroc: 0.9549 - val_f1: 0.8610\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 253us/step - loss: 0.1077 - acc: 0.9778 - auroc: 0.9980 - f1: 0.9771 - val_loss: 0.2464 - val_acc: 0.8812 - val_auroc: 0.9629 - val_f1: 0.8701\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 249us/step - loss: 0.0362 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9994 - val_loss: 0.2582 - val_acc: 0.8812 - val_auroc: 0.9566 - val_f1: 0.8701\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 253us/step - loss: 0.0186 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9994 - val_loss: 0.2700 - val_acc: 0.8812 - val_auroc: 0.9550 - val_f1: 0.8701\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 259us/step - loss: 0.0116 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2802 - val_acc: 0.8812 - val_auroc: 0.9558 - val_f1: 0.8701\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 251us/step - loss: 0.0081 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2878 - val_acc: 0.8875 - val_auroc: 0.9558 - val_f1: 0.8769\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 248us/step - loss: 0.0060 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2946 - val_acc: 0.8938 - val_auroc: 0.9550 - val_f1: 0.8848\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 254us/step - loss: 0.0046 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3007 - val_acc: 0.8938 - val_auroc: 0.9550 - val_f1: 0.8848\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 5s 3ms/step - loss: 0.5424 - acc: 0.7722 - auroc: 0.8450 - f1: 0.7885 - val_loss: 0.3533 - val_acc: 0.8688 - val_auroc: 0.9433 - val_f1: 0.8559\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 261us/step - loss: 0.1278 - acc: 0.9729 - auroc: 0.9970 - f1: 0.9724 - val_loss: 0.2699 - val_acc: 0.8875 - val_auroc: 0.9472 - val_f1: 0.8838\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 262us/step - loss: 0.0445 - acc: 0.9965 - auroc: 0.9999 - f1: 0.9964 - val_loss: 0.2680 - val_acc: 0.8875 - val_auroc: 0.9481 - val_f1: 0.8838\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 268us/step - loss: 0.0237 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9994 - val_loss: 0.2782 - val_acc: 0.8750 - val_auroc: 0.9469 - val_f1: 0.8697\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 262us/step - loss: 0.0150 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2863 - val_acc: 0.8750 - val_auroc: 0.9477 - val_f1: 0.8697\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.0104 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2949 - val_acc: 0.8750 - val_auroc: 0.9493 - val_f1: 0.8697\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 254us/step - loss: 0.0078 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3030 - val_acc: 0.8812 - val_auroc: 0.9483 - val_f1: 0.8764\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 253us/step - loss: 0.0061 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3103 - val_acc: 0.8875 - val_auroc: 0.9456 - val_f1: 0.8824\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 0s 248us/step - loss: 0.0050 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3170 - val_acc: 0.8812 - val_auroc: 0.9456 - val_f1: 0.8776\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 5s 3ms/step - loss: 0.5188 - acc: 0.7875 - auroc: 0.8531 - f1: 0.7964 - val_loss: 0.3555 - val_acc: 0.8812 - val_auroc: 0.9459 - val_f1: 0.8724\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 258us/step - loss: 0.0998 - acc: 0.9833 - auroc: 0.9981 - f1: 0.9826 - val_loss: 0.2980 - val_acc: 0.8500 - val_auroc: 0.9455 - val_f1: 0.8444\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 254us/step - loss: 0.0331 - acc: 0.9986 - auroc: 1.0000 - f1: 0.9985 - val_loss: 0.2990 - val_acc: 0.8625 - val_auroc: 0.9439 - val_f1: 0.8571\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 253us/step - loss: 0.0171 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3059 - val_acc: 0.8688 - val_auroc: 0.9414 - val_f1: 0.8655\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 257us/step - loss: 0.0106 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3110 - val_acc: 0.8688 - val_auroc: 0.9406 - val_f1: 0.8655\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 251us/step - loss: 0.0074 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3168 - val_acc: 0.8625 - val_auroc: 0.9398 - val_f1: 0.8582\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 251us/step - loss: 0.0055 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3225 - val_acc: 0.8625 - val_auroc: 0.9390 - val_f1: 0.8582\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 250us/step - loss: 0.0043 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3278 - val_acc: 0.8625 - val_auroc: 0.9374 - val_f1: 0.8582\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.5488 - acc: 0.7764 - auroc: 0.8537 - f1: 0.7956 - val_loss: 0.3789 - val_acc: 0.8875 - val_auroc: 0.9445 - val_f1: 0.8755\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.1480 - acc: 0.9722 - auroc: 0.9966 - f1: 0.9716 - val_loss: 0.2952 - val_acc: 0.8875 - val_auroc: 0.9477 - val_f1: 0.8871\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 255us/step - loss: 0.0554 - acc: 0.9965 - auroc: 0.9998 - f1: 0.9965 - val_loss: 0.2955 - val_acc: 0.8812 - val_auroc: 0.9414 - val_f1: 0.8815\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 255us/step - loss: 0.0296 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9995 - val_loss: 0.3078 - val_acc: 0.8750 - val_auroc: 0.9351 - val_f1: 0.8751\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 255us/step - loss: 0.0188 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3212 - val_acc: 0.8688 - val_auroc: 0.9336 - val_f1: 0.8677\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 256us/step - loss: 0.0131 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3339 - val_acc: 0.8438 - val_auroc: 0.9296 - val_f1: 0.8408\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 257us/step - loss: 0.0098 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3455 - val_acc: 0.8438 - val_auroc: 0.9288 - val_f1: 0.8408\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 255us/step - loss: 0.0077 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3561 - val_acc: 0.8438 - val_auroc: 0.9280 - val_f1: 0.8408\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.5330 - acc: 0.7812 - auroc: 0.8481 - f1: 0.7962 - val_loss: 0.3339 - val_acc: 0.8938 - val_auroc: 0.9513 - val_f1: 0.8874\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 268us/step - loss: 0.1206 - acc: 0.9764 - auroc: 0.9975 - f1: 0.9760 - val_loss: 0.2754 - val_acc: 0.8875 - val_auroc: 0.9498 - val_f1: 0.8873\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 254us/step - loss: 0.0418 - acc: 0.9972 - auroc: 1.0000 - f1: 0.9972 - val_loss: 0.2756 - val_acc: 0.8875 - val_auroc: 0.9482 - val_f1: 0.8873\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 256us/step - loss: 0.0221 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2827 - val_acc: 0.8875 - val_auroc: 0.9482 - val_f1: 0.8898\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 260us/step - loss: 0.0139 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2894 - val_acc: 0.8875 - val_auroc: 0.9474 - val_f1: 0.8873\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 253us/step - loss: 0.0097 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2974 - val_acc: 0.8812 - val_auroc: 0.9459 - val_f1: 0.8824\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 257us/step - loss: 0.0072 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3048 - val_acc: 0.8750 - val_auroc: 0.9458 - val_f1: 0.8764\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 255us/step - loss: 0.0057 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3118 - val_acc: 0.8750 - val_auroc: 0.9458 - val_f1: 0.8764\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.5300 - acc: 0.7597 - auroc: 0.8574 - f1: 0.7862 - val_loss: 0.3678 - val_acc: 0.8688 - val_auroc: 0.9434 - val_f1: 0.8539\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 267us/step - loss: 0.1234 - acc: 0.9750 - auroc: 0.9972 - f1: 0.9735 - val_loss: 0.2985 - val_acc: 0.8938 - val_auroc: 0.9452 - val_f1: 0.8765\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 257us/step - loss: 0.0441 - acc: 0.9951 - auroc: 0.9999 - f1: 0.9951 - val_loss: 0.2961 - val_acc: 0.8875 - val_auroc: 0.9459 - val_f1: 0.8707\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 250us/step - loss: 0.0235 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9994 - val_loss: 0.2983 - val_acc: 0.9000 - val_auroc: 0.9434 - val_f1: 0.8845\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 253us/step - loss: 0.0146 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3062 - val_acc: 0.8750 - val_auroc: 0.9418 - val_f1: 0.8590\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 256us/step - loss: 0.0101 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3138 - val_acc: 0.8750 - val_auroc: 0.9410 - val_f1: 0.8645\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 258us/step - loss: 0.0075 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3208 - val_acc: 0.8750 - val_auroc: 0.9394 - val_f1: 0.8645\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 257us/step - loss: 0.0058 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3274 - val_acc: 0.8750 - val_auroc: 0.9386 - val_f1: 0.8645\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.0047 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3335 - val_acc: 0.8688 - val_auroc: 0.9378 - val_f1: 0.8567\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 5ms/step - loss: 0.5509 - acc: 0.7542 - auroc: 0.8325 - f1: 0.7807 - val_loss: 0.4192 - val_acc: 0.8438 - val_auroc: 0.9023 - val_f1: 0.8203\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 267us/step - loss: 0.1264 - acc: 0.9757 - auroc: 0.9981 - f1: 0.9752 - val_loss: 0.3751 - val_acc: 0.8625 - val_auroc: 0.9096 - val_f1: 0.8598\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 261us/step - loss: 0.0445 - acc: 0.9958 - auroc: 1.0000 - f1: 0.9956 - val_loss: 0.3833 - val_acc: 0.8625 - val_auroc: 0.9104 - val_f1: 0.8598\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.0237 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9994 - val_loss: 0.3930 - val_acc: 0.8688 - val_auroc: 0.9088 - val_f1: 0.8683\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 262us/step - loss: 0.0149 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4057 - val_acc: 0.8688 - val_auroc: 0.9081 - val_f1: 0.8683\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 257us/step - loss: 0.0104 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4166 - val_acc: 0.8688 - val_auroc: 0.9081 - val_f1: 0.8683\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 261us/step - loss: 0.0078 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4265 - val_acc: 0.8688 - val_auroc: 0.9097 - val_f1: 0.8683\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.0061 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4354 - val_acc: 0.8688 - val_auroc: 0.9097 - val_f1: 0.8683\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.5351 - acc: 0.7694 - auroc: 0.8404 - f1: 0.7801 - val_loss: 0.3323 - val_acc: 0.8938 - val_auroc: 0.9526 - val_f1: 0.8839\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 266us/step - loss: 0.1207 - acc: 0.9764 - auroc: 0.9984 - f1: 0.9756 - val_loss: 0.2471 - val_acc: 0.9062 - val_auroc: 0.9636 - val_f1: 0.9026\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 259us/step - loss: 0.0425 - acc: 0.9972 - auroc: 1.0000 - f1: 0.9973 - val_loss: 0.2299 - val_acc: 0.8938 - val_auroc: 0.9692 - val_f1: 0.8939\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.0225 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9994 - val_loss: 0.2271 - val_acc: 0.9000 - val_auroc: 0.9699 - val_f1: 0.9018\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.0141 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2280 - val_acc: 0.8938 - val_auroc: 0.9675 - val_f1: 0.8939\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 260us/step - loss: 0.0098 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2304 - val_acc: 0.8938 - val_auroc: 0.9675 - val_f1: 0.8939\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 258us/step - loss: 0.0072 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2331 - val_acc: 0.8938 - val_auroc: 0.9691 - val_f1: 0.8939\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 255us/step - loss: 0.0056 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2360 - val_acc: 0.8938 - val_auroc: 0.9699 - val_f1: 0.8939\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 0s 260us/step - loss: 0.0045 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2389 - val_acc: 0.9000 - val_auroc: 0.9707 - val_f1: 0.9007\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 0s 258us/step - loss: 0.0038 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2417 - val_acc: 0.9000 - val_auroc: 0.9707 - val_f1: 0.9007\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.5131 - acc: 0.7868 - auroc: 0.8572 - f1: 0.8015 - val_loss: 0.3558 - val_acc: 0.8375 - val_auroc: 0.9395 - val_f1: 0.8217\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.1038 - acc: 0.9792 - auroc: 0.9973 - f1: 0.9784 - val_loss: 0.2886 - val_acc: 0.8625 - val_auroc: 0.9506 - val_f1: 0.8573\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 267us/step - loss: 0.0343 - acc: 0.9979 - auroc: 1.0000 - f1: 0.9979 - val_loss: 0.2895 - val_acc: 0.8688 - val_auroc: 0.9458 - val_f1: 0.8618\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 269us/step - loss: 0.0177 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9994 - val_loss: 0.2976 - val_acc: 0.8625 - val_auroc: 0.9458 - val_f1: 0.8578\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.0110 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3046 - val_acc: 0.8500 - val_auroc: 0.9450 - val_f1: 0.8407\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 270us/step - loss: 0.0076 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3112 - val_acc: 0.8625 - val_auroc: 0.9442 - val_f1: 0.8531\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.0057 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3172 - val_acc: 0.8625 - val_auroc: 0.9426 - val_f1: 0.8531\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.0044 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3228 - val_acc: 0.8625 - val_auroc: 0.9426 - val_f1: 0.8531\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.5369 - acc: 0.7618 - auroc: 0.8469 - f1: 0.7801 - val_loss: 0.3797 - val_acc: 0.8688 - val_auroc: 0.9542 - val_f1: 0.8474\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 269us/step - loss: 0.1244 - acc: 0.9799 - auroc: 0.9975 - f1: 0.9792 - val_loss: 0.3020 - val_acc: 0.9000 - val_auroc: 0.9534 - val_f1: 0.8871\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.0422 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.2936 - val_acc: 0.9125 - val_auroc: 0.9526 - val_f1: 0.9056\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.0220 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2964 - val_acc: 0.9187 - val_auroc: 0.9534 - val_f1: 0.9121\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.0139 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3044 - val_acc: 0.9062 - val_auroc: 0.9510 - val_f1: 0.8978\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.0097 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3100 - val_acc: 0.9000 - val_auroc: 0.9518 - val_f1: 0.8927\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 262us/step - loss: 0.0073 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3155 - val_acc: 0.8938 - val_auroc: 0.9510 - val_f1: 0.8866\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 259us/step - loss: 0.0057 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3208 - val_acc: 0.8938 - val_auroc: 0.9502 - val_f1: 0.8866\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 0s 260us/step - loss: 0.0046 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3259 - val_acc: 0.9000 - val_auroc: 0.9502 - val_f1: 0.8927\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "rnn_bow_scores = run_cross_validate(evaluate_lstm_model, rnn_bow, rnn_bow_targets, splitter, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'val_accuracy': 0.88125,\n",
       "   'val_auroc': 0.9980491264769515,\n",
       "   'val_f1': 0.87011159658432,\n",
       "   'val_loss': 0.24641295075416564},\n",
       "  {'val_accuracy': 0.8875,\n",
       "   'val_auroc': 0.9999128540305011,\n",
       "   'val_f1': 0.8837914228439331,\n",
       "   'val_loss': 0.26799827814102173},\n",
       "  {'val_accuracy': 0.85,\n",
       "   'val_auroc': 0.9980598192943394,\n",
       "   'val_f1': 0.8444301128387451,\n",
       "   'val_loss': 0.2980100452899933},\n",
       "  {'val_accuracy': 0.8875,\n",
       "   'val_auroc': 0.996636531420458,\n",
       "   'val_f1': 0.8871279716491699,\n",
       "   'val_loss': 0.2951516032218933},\n",
       "  {'val_accuracy': 0.8875,\n",
       "   'val_auroc': 0.9975079734435383,\n",
       "   'val_f1': 0.8872607111930847,\n",
       "   'val_loss': 0.2753987699747086},\n",
       "  {'val_accuracy': 0.8875,\n",
       "   'val_auroc': 0.9999128540305011,\n",
       "   'val_f1': 0.8707250356674194,\n",
       "   'val_loss': 0.2961113005876541},\n",
       "  {'val_accuracy': 0.8625,\n",
       "   'val_auroc': 0.9981494636016051,\n",
       "   'val_f1': 0.8597959280014038,\n",
       "   'val_loss': 0.3750558733940125},\n",
       "  {'val_accuracy': 0.9,\n",
       "   'val_auroc': 1.0,\n",
       "   'val_f1': 0.9018311142921448,\n",
       "   'val_loss': 0.22706974744796754},\n",
       "  {'val_accuracy': 0.8625,\n",
       "   'val_auroc': 0.9973462974277281,\n",
       "   'val_f1': 0.8572858929634094,\n",
       "   'val_loss': 0.2886282533407211},\n",
       "  {'val_accuracy': 0.9125,\n",
       "   'val_auroc': 1.0,\n",
       "   'val_f1': 0.9056196093559266,\n",
       "   'val_loss': 0.293578690290451}],\n",
       " 0.881875)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_bow_bests = results(rnn_bow_scores)\n",
    "rnn_bow_bests, statistics.mean([x['val_accuracy'] for x in rnn_bow_bests])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW again gives us astoundingly good accuracies, but of course, because it's over a tiny amount of data.\n",
    "\n",
    "Now let's try our pretrained Word2Vec embeddings, and compare it to our previous OpSpam embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_sequences = pad_sequences(tokenizer.texts_to_sequences(raw_features))\n",
    "max_len = max([len(x) for x in predictors_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_wv_model():\n",
    "  model = Sequential([\n",
    "        Embedding(corpus_vocab_size, embedding_length, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
    "        LSTM(10),\n",
    "        Dense(1, activation=sigmoid)\n",
    "  ])\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_model(train_X, train_y, test_X, test_y):\n",
    "    lstm_model = get_lstm_wv_model()\n",
    "    return lstm_model.fit(train_X, train_y, epochs=25, batch_size=32, verbose=1, shuffle=False,\n",
    "                          callbacks=[EarlyStopping(monitor='val_loss', patience=6)],\n",
    "                          validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 35s 25ms/step - loss: 0.6877 - acc: 0.5465 - auroc: 0.5736 - f1: 0.6144 - val_loss: 0.6772 - val_acc: 0.6062 - val_auroc: 0.6574 - val_f1: 0.5762\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.6691 - acc: 0.6146 - auroc: 0.6557 - f1: 0.6030 - val_loss: 0.6608 - val_acc: 0.6000 - val_auroc: 0.6692 - val_f1: 0.4732\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.6280 - acc: 0.6493 - auroc: 0.7293 - f1: 0.6220 - val_loss: 0.6355 - val_acc: 0.5938 - val_auroc: 0.6833 - val_f1: 0.5922\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.5590 - acc: 0.7104 - auroc: 0.8026 - f1: 0.7032 - val_loss: 0.6440 - val_acc: 0.6687 - val_auroc: 0.7627 - val_f1: 0.7034\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.5454 - acc: 0.7590 - auroc: 0.8292 - f1: 0.7587 - val_loss: 0.5679 - val_acc: 0.7125 - val_auroc: 0.7786 - val_f1: 0.6922\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.7232 - acc: 0.5528 - auroc: 0.7336 - f1: 0.6875 - val_loss: 0.6714 - val_acc: 0.5563 - val_auroc: 0.6691 - val_f1: 0.6589\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.6165 - acc: 0.7042 - auroc: 0.7919 - f1: 0.6793 - val_loss: 0.6221 - val_acc: 0.7000 - val_auroc: 0.7581 - val_f1: 0.6748\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.6076 - acc: 0.6826 - auroc: 0.8067 - f1: 0.7197 - val_loss: 0.6581 - val_acc: 0.6000 - val_auroc: 0.7004 - val_f1: 0.7037\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.5482 - acc: 0.7361 - auroc: 0.8298 - f1: 0.7394 - val_loss: 0.6428 - val_acc: 0.6937 - val_auroc: 0.7400 - val_f1: 0.6547\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.5313 - acc: 0.7486 - auroc: 0.8547 - f1: 0.7280 - val_loss: 0.5895 - val_acc: 0.6937 - val_auroc: 0.7691 - val_f1: 0.6913\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.5228 - acc: 0.7507 - auroc: 0.8479 - f1: 0.7432 - val_loss: 0.5981 - val_acc: 0.7188 - val_auroc: 0.7503 - val_f1: 0.6886\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 34s 24ms/step - loss: 0.6907 - acc: 0.5146 - auroc: 0.5612 - f1: 0.5515 - val_loss: 0.6848 - val_acc: 0.5625 - val_auroc: 0.5980 - val_f1: 0.5425\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.6722 - acc: 0.6097 - auroc: 0.6555 - f1: 0.6037 - val_loss: 0.6796 - val_acc: 0.5813 - val_auroc: 0.5980 - val_f1: 0.5230\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6406 - acc: 0.6542 - auroc: 0.7015 - f1: 0.6282 - val_loss: 0.6708 - val_acc: 0.5875 - val_auroc: 0.6532 - val_f1: 0.4839\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6006 - acc: 0.6868 - auroc: 0.7668 - f1: 0.6745 - val_loss: 0.6375 - val_acc: 0.6438 - val_auroc: 0.7131 - val_f1: 0.6010\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5672 - acc: 0.7062 - auroc: 0.8117 - f1: 0.6986 - val_loss: 0.5956 - val_acc: 0.6750 - val_auroc: 0.7462 - val_f1: 0.6927\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5761 - acc: 0.6924 - auroc: 0.8115 - f1: 0.7006 - val_loss: 0.6629 - val_acc: 0.5687 - val_auroc: 0.6613 - val_f1: 0.3598\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5534 - acc: 0.7208 - auroc: 0.8223 - f1: 0.7018 - val_loss: 0.6787 - val_acc: 0.6500 - val_auroc: 0.7401 - val_f1: 0.4810\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5330 - acc: 0.7438 - auroc: 0.8381 - f1: 0.7318 - val_loss: 0.5591 - val_acc: 0.7250 - val_auroc: 0.8127 - val_f1: 0.6827\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.5432 - acc: 0.7250 - auroc: 0.8320 - f1: 0.6327 - val_loss: 0.6677 - val_acc: 0.6000 - val_auroc: 0.6664 - val_f1: 0.4377\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5846 - acc: 0.7007 - auroc: 0.7699 - f1: 0.6878 - val_loss: 0.6516 - val_acc: 0.6125 - val_auroc: 0.7043 - val_f1: 0.5360\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5622 - acc: 0.7049 - auroc: 0.7972 - f1: 0.6844 - val_loss: 0.6487 - val_acc: 0.6188 - val_auroc: 0.7421 - val_f1: 0.5360\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5296 - acc: 0.7375 - auroc: 0.8232 - f1: 0.7287 - val_loss: 0.5995 - val_acc: 0.6813 - val_auroc: 0.7749 - val_f1: 0.6392\n",
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5069 - acc: 0.7639 - auroc: 0.8393 - f1: 0.7574 - val_loss: 0.5823 - val_acc: 0.7188 - val_auroc: 0.7929 - val_f1: 0.6815\n",
      "Epoch 14/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4812 - acc: 0.7722 - auroc: 0.8619 - f1: 0.7641 - val_loss: 0.5927 - val_acc: 0.7063 - val_auroc: 0.8142 - val_f1: 0.6409\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 35s 25ms/step - loss: 0.6884 - acc: 0.5201 - auroc: 0.5597 - f1: 0.5853 - val_loss: 0.6778 - val_acc: 0.5625 - val_auroc: 0.6021 - val_f1: 0.4510\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6635 - acc: 0.6083 - auroc: 0.6776 - f1: 0.5726 - val_loss: 0.6560 - val_acc: 0.6188 - val_auroc: 0.6780 - val_f1: 0.4757\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6231 - acc: 0.6500 - auroc: 0.7495 - f1: 0.6144 - val_loss: 0.6316 - val_acc: 0.6813 - val_auroc: 0.7127 - val_f1: 0.6003\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5889 - acc: 0.6937 - auroc: 0.7932 - f1: 0.6657 - val_loss: 0.5796 - val_acc: 0.7188 - val_auroc: 0.7687 - val_f1: 0.6940\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6779 - acc: 0.6271 - auroc: 0.7838 - f1: 0.6666 - val_loss: 0.6994 - val_acc: 0.5437 - val_auroc: 0.6909 - val_f1: 0.6851\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6260 - acc: 0.6562 - auroc: 0.8015 - f1: 0.6081 - val_loss: 0.5936 - val_acc: 0.7438 - val_auroc: 0.7517 - val_f1: 0.6822\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5391 - acc: 0.7611 - auroc: 0.8387 - f1: 0.7608 - val_loss: 0.5430 - val_acc: 0.7500 - val_auroc: 0.7996 - val_f1: 0.7369\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5535 - acc: 0.7174 - auroc: 0.8396 - f1: 0.7519 - val_loss: 0.5353 - val_acc: 0.7500 - val_auroc: 0.8001 - val_f1: 0.7762\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6773 - acc: 0.5819 - auroc: 0.7830 - f1: 0.6717 - val_loss: 0.6858 - val_acc: 0.5437 - val_auroc: 0.6661 - val_f1: 0.6809\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6419 - acc: 0.6396 - auroc: 0.7535 - f1: 0.6927 - val_loss: 0.6557 - val_acc: 0.5750 - val_auroc: 0.6614 - val_f1: 0.5739\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6186 - acc: 0.6972 - auroc: 0.7638 - f1: 0.7016 - val_loss: 0.6372 - val_acc: 0.6000 - val_auroc: 0.6876 - val_f1: 0.5775\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5671 - acc: 0.7181 - auroc: 0.8023 - f1: 0.7152 - val_loss: 0.5326 - val_acc: 0.7500 - val_auroc: 0.8013 - val_f1: 0.7265\n",
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5639 - acc: 0.6958 - auroc: 0.8236 - f1: 0.7296 - val_loss: 0.6307 - val_acc: 0.6188 - val_auroc: 0.7126 - val_f1: 0.6709\n",
      "Epoch 14/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5695 - acc: 0.7389 - auroc: 0.8194 - f1: 0.7328 - val_loss: 0.5866 - val_acc: 0.7000 - val_auroc: 0.7490 - val_f1: 0.6610\n",
      "Epoch 15/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5140 - acc: 0.7569 - auroc: 0.8543 - f1: 0.7356 - val_loss: 0.6078 - val_acc: 0.6813 - val_auroc: 0.7670 - val_f1: 0.5631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4876 - acc: 0.7771 - auroc: 0.8618 - f1: 0.7684 - val_loss: 0.5477 - val_acc: 0.7375 - val_auroc: 0.7930 - val_f1: 0.6912\n",
      "Epoch 17/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5026 - acc: 0.7549 - auroc: 0.8714 - f1: 0.7516 - val_loss: 0.5946 - val_acc: 0.7250 - val_auroc: 0.7811 - val_f1: 0.6437\n",
      "Epoch 18/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5175 - acc: 0.7500 - auroc: 0.8612 - f1: 0.6573 - val_loss: 0.8247 - val_acc: 0.5125 - val_auroc: 0.6902 - val_f1: 0.0421\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 35s 24ms/step - loss: 0.6897 - acc: 0.5375 - auroc: 0.5786 - f1: 0.5908 - val_loss: 0.6821 - val_acc: 0.6125 - val_auroc: 0.6344 - val_f1: 0.5801\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6729 - acc: 0.6097 - auroc: 0.6643 - f1: 0.5827 - val_loss: 0.6566 - val_acc: 0.5938 - val_auroc: 0.6975 - val_f1: 0.4458\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6283 - acc: 0.6604 - auroc: 0.7339 - f1: 0.6470 - val_loss: 0.5524 - val_acc: 0.7438 - val_auroc: 0.7852 - val_f1: 0.7407\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5916 - acc: 0.6937 - auroc: 0.7835 - f1: 0.6816 - val_loss: 0.5594 - val_acc: 0.7438 - val_auroc: 0.7953 - val_f1: 0.7274\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5777 - acc: 0.7083 - auroc: 0.8002 - f1: 0.6973 - val_loss: 0.5795 - val_acc: 0.7125 - val_auroc: 0.7885 - val_f1: 0.7363\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5271 - acc: 0.7542 - auroc: 0.8301 - f1: 0.7524 - val_loss: 0.5432 - val_acc: 0.7312 - val_auroc: 0.8285 - val_f1: 0.7559\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4818 - acc: 0.7799 - auroc: 0.8709 - f1: 0.7829 - val_loss: 0.4710 - val_acc: 0.8000 - val_auroc: 0.8578 - val_f1: 0.8062\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5106 - acc: 0.7639 - auroc: 0.8603 - f1: 0.7744 - val_loss: 0.5179 - val_acc: 0.7500 - val_auroc: 0.8333 - val_f1: 0.7594\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4851 - acc: 0.7833 - auroc: 0.8791 - f1: 0.7614 - val_loss: 0.9293 - val_acc: 0.5500 - val_auroc: 0.6913 - val_f1: 0.1783\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6086 - acc: 0.7042 - auroc: 0.8381 - f1: 0.5957 - val_loss: 0.5133 - val_acc: 0.7688 - val_auroc: 0.8539 - val_f1: 0.7246\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4682 - acc: 0.7979 - auroc: 0.8796 - f1: 0.7775 - val_loss: 0.4861 - val_acc: 0.7875 - val_auroc: 0.8551 - val_f1: 0.7718\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.7992 - acc: 0.5625 - auroc: 0.7361 - f1: 0.6909 - val_loss: 0.7431 - val_acc: 0.5125 - val_auroc: 0.6681 - val_f1: 0.6662\n",
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5630 - acc: 0.7160 - auroc: 0.8403 - f1: 0.7613 - val_loss: 0.5257 - val_acc: 0.7562 - val_auroc: 0.8245 - val_f1: 0.7764\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 36s 25ms/step - loss: 0.6815 - acc: 0.5507 - auroc: 0.6129 - f1: 0.5774 - val_loss: 0.6832 - val_acc: 0.5250 - val_auroc: 0.6095 - val_f1: 0.3063\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6367 - acc: 0.6431 - auroc: 0.7112 - f1: 0.6216 - val_loss: 0.6212 - val_acc: 0.6750 - val_auroc: 0.7385 - val_f1: 0.6922\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5772 - acc: 0.6993 - auroc: 0.7897 - f1: 0.7028 - val_loss: 0.6573 - val_acc: 0.6312 - val_auroc: 0.7461 - val_f1: 0.7089\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.6930 - acc: 0.6069 - auroc: 0.7512 - f1: 0.5172 - val_loss: 0.6536 - val_acc: 0.6125 - val_auroc: 0.7042 - val_f1: 0.6035\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.6390 - acc: 0.6757 - auroc: 0.7777 - f1: 0.6989 - val_loss: 0.6942 - val_acc: 0.6312 - val_auroc: 0.7483 - val_f1: 0.7078\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5885 - acc: 0.6861 - auroc: 0.8029 - f1: 0.7317 - val_loss: 0.5881 - val_acc: 0.6875 - val_auroc: 0.7755 - val_f1: 0.7177\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5699 - acc: 0.7424 - auroc: 0.8347 - f1: 0.7041 - val_loss: 0.6719 - val_acc: 0.5938 - val_auroc: 0.7637 - val_f1: 0.3749\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5684 - acc: 0.7125 - auroc: 0.8273 - f1: 0.6496 - val_loss: 0.6308 - val_acc: 0.6500 - val_auroc: 0.7664 - val_f1: 0.5402\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6700 - acc: 0.6229 - auroc: 0.7709 - f1: 0.6977 - val_loss: 0.7229 - val_acc: 0.5000 - val_auroc: 0.6589 - val_f1: 0.6577\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6534 - acc: 0.6201 - auroc: 0.7261 - f1: 0.6679 - val_loss: 0.6652 - val_acc: 0.5813 - val_auroc: 0.6656 - val_f1: 0.5109\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6295 - acc: 0.6708 - auroc: 0.7382 - f1: 0.6633 - val_loss: 0.6542 - val_acc: 0.5938 - val_auroc: 0.6819 - val_f1: 0.5540\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6019 - acc: 0.6819 - auroc: 0.7561 - f1: 0.6701 - val_loss: 0.6386 - val_acc: 0.6125 - val_auroc: 0.7173 - val_f1: 0.5322\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 36s 25ms/step - loss: 0.6832 - acc: 0.5486 - auroc: 0.5955 - f1: 0.5955 - val_loss: 0.6800 - val_acc: 0.5563 - val_auroc: 0.6182 - val_f1: 0.4060\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6597 - acc: 0.6181 - auroc: 0.6797 - f1: 0.5877 - val_loss: 0.6465 - val_acc: 0.6188 - val_auroc: 0.7173 - val_f1: 0.4942\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6190 - acc: 0.6583 - auroc: 0.7359 - f1: 0.6334 - val_loss: 0.6037 - val_acc: 0.6875 - val_auroc: 0.7375 - val_f1: 0.6384\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.5671 - acc: 0.7049 - auroc: 0.8016 - f1: 0.6956 - val_loss: 0.5881 - val_acc: 0.7063 - val_auroc: 0.7765 - val_f1: 0.6326\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5350 - acc: 0.7361 - auroc: 0.8326 - f1: 0.7290 - val_loss: 0.5874 - val_acc: 0.7000 - val_auroc: 0.7929 - val_f1: 0.6139\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4941 - acc: 0.7674 - auroc: 0.8695 - f1: 0.7536 - val_loss: 0.5207 - val_acc: 0.7625 - val_auroc: 0.8287 - val_f1: 0.7369\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4561 - acc: 0.7944 - auroc: 0.8833 - f1: 0.7910 - val_loss: 0.4847 - val_acc: 0.8063 - val_auroc: 0.8485 - val_f1: 0.7925\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4729 - acc: 0.7924 - auroc: 0.8945 - f1: 0.7900 - val_loss: 0.5159 - val_acc: 0.7688 - val_auroc: 0.8383 - val_f1: 0.7725\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5216 - acc: 0.7674 - auroc: 0.8760 - f1: 0.7539 - val_loss: 0.4817 - val_acc: 0.7875 - val_auroc: 0.8727 - val_f1: 0.7584\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4507 - acc: 0.8042 - auroc: 0.9009 - f1: 0.7936 - val_loss: 0.4698 - val_acc: 0.7812 - val_auroc: 0.8627 - val_f1: 0.7832\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4386 - acc: 0.8201 - auroc: 0.9071 - f1: 0.8003 - val_loss: 0.4803 - val_acc: 0.7937 - val_auroc: 0.8660 - val_f1: 0.7949\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4931 - acc: 0.7764 - auroc: 0.8989 - f1: 0.7492 - val_loss: 0.4812 - val_acc: 0.7937 - val_auroc: 0.8576 - val_f1: 0.7921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4058 - acc: 0.8326 - auroc: 0.9139 - f1: 0.8251 - val_loss: 0.5143 - val_acc: 0.7750 - val_auroc: 0.8689 - val_f1: 0.8004\n",
      "Epoch 14/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4078 - acc: 0.8340 - auroc: 0.9108 - f1: 0.8281 - val_loss: 0.4798 - val_acc: 0.7875 - val_auroc: 0.8723 - val_f1: 0.7526\n",
      "Epoch 15/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.3602 - acc: 0.8646 - auroc: 0.9254 - f1: 0.8644 - val_loss: 0.4697 - val_acc: 0.7875 - val_auroc: 0.8774 - val_f1: 0.7710\n",
      "Epoch 16/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4743 - acc: 0.7889 - auroc: 0.9062 - f1: 0.7555 - val_loss: 0.4558 - val_acc: 0.7937 - val_auroc: 0.8824 - val_f1: 0.7985\n",
      "Epoch 17/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.7680 - acc: 0.6694 - auroc: 0.8105 - f1: 0.7271 - val_loss: 1.0079 - val_acc: 0.5000 - val_auroc: 0.6876 - val_f1: 0.6646\n",
      "Epoch 18/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.8009 - acc: 0.5042 - auroc: 0.7363 - f1: 0.6649 - val_loss: 0.6925 - val_acc: 0.5188 - val_auroc: 0.7485 - val_f1: 0.6700\n",
      "Epoch 19/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6464 - acc: 0.5931 - auroc: 0.7701 - f1: 0.6994 - val_loss: 0.6242 - val_acc: 0.6625 - val_auroc: 0.7662 - val_f1: 0.7202\n",
      "Epoch 20/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6024 - acc: 0.6931 - auroc: 0.7807 - f1: 0.7171 - val_loss: 0.5966 - val_acc: 0.7188 - val_auroc: 0.7754 - val_f1: 0.6890\n",
      "Epoch 21/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5677 - acc: 0.7167 - auroc: 0.8013 - f1: 0.7108 - val_loss: 0.5489 - val_acc: 0.7375 - val_auroc: 0.8221 - val_f1: 0.6905\n",
      "Epoch 22/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5142 - acc: 0.7535 - auroc: 0.8578 - f1: 0.7683 - val_loss: 0.6027 - val_acc: 0.6813 - val_auroc: 0.7966 - val_f1: 0.7549\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 37s 26ms/step - loss: 0.6824 - acc: 0.5611 - auroc: 0.6152 - f1: 0.6240 - val_loss: 0.6847 - val_acc: 0.5437 - val_auroc: 0.5697 - val_f1: 0.3938\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6410 - acc: 0.6431 - auroc: 0.7133 - f1: 0.6217 - val_loss: 0.6476 - val_acc: 0.6438 - val_auroc: 0.6958 - val_f1: 0.5286\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5914 - acc: 0.6910 - auroc: 0.7730 - f1: 0.6726 - val_loss: 0.5543 - val_acc: 0.7500 - val_auroc: 0.7958 - val_f1: 0.7068\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6671 - acc: 0.6090 - auroc: 0.7771 - f1: 0.3957 - val_loss: 0.6604 - val_acc: 0.6188 - val_auroc: 0.6601 - val_f1: 0.4403\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6032 - acc: 0.6882 - auroc: 0.7719 - f1: 0.6566 - val_loss: 0.6312 - val_acc: 0.6250 - val_auroc: 0.6901 - val_f1: 0.5911\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.5758 - acc: 0.7222 - auroc: 0.7872 - f1: 0.7020 - val_loss: 0.5949 - val_acc: 0.6687 - val_auroc: 0.7496 - val_f1: 0.6491\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5372 - acc: 0.7396 - auroc: 0.8134 - f1: 0.7125 - val_loss: 0.5251 - val_acc: 0.7625 - val_auroc: 0.8034 - val_f1: 0.7486\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5138 - acc: 0.7451 - auroc: 0.8410 - f1: 0.7104 - val_loss: 0.5261 - val_acc: 0.7562 - val_auroc: 0.8087 - val_f1: 0.7199\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4908 - acc: 0.7687 - auroc: 0.8494 - f1: 0.7447 - val_loss: 0.5117 - val_acc: 0.7625 - val_auroc: 0.8282 - val_f1: 0.7323\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4774 - acc: 0.7799 - auroc: 0.8592 - f1: 0.7619 - val_loss: 0.4926 - val_acc: 0.7937 - val_auroc: 0.8368 - val_f1: 0.7772\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4772 - acc: 0.7771 - auroc: 0.8617 - f1: 0.7525 - val_loss: 0.5373 - val_acc: 0.7375 - val_auroc: 0.8070 - val_f1: 0.7007\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4468 - acc: 0.8042 - auroc: 0.8834 - f1: 0.7827 - val_loss: 0.4481 - val_acc: 0.8375 - val_auroc: 0.8627 - val_f1: 0.8267\n",
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5061 - acc: 0.7542 - auroc: 0.8615 - f1: 0.7194 - val_loss: 0.4788 - val_acc: 0.7937 - val_auroc: 0.8584 - val_f1: 0.7972\n",
      "Epoch 14/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4154 - acc: 0.8236 - auroc: 0.8967 - f1: 0.8112 - val_loss: 0.4317 - val_acc: 0.8250 - val_auroc: 0.8849 - val_f1: 0.8199\n",
      "Epoch 15/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6549 - acc: 0.7028 - auroc: 0.8384 - f1: 0.7486 - val_loss: 0.8088 - val_acc: 0.5000 - val_auroc: 0.6414 - val_f1: 0.6652\n",
      "Epoch 16/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6897 - acc: 0.5368 - auroc: 0.5753 - f1: 0.6254 - val_loss: 0.6632 - val_acc: 0.5500 - val_auroc: 0.6028 - val_f1: 0.4959\n",
      "Epoch 17/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6017 - acc: 0.6444 - auroc: 0.7265 - f1: 0.6363 - val_loss: 0.5393 - val_acc: 0.7562 - val_auroc: 0.8328 - val_f1: 0.7342\n",
      "Epoch 18/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5111 - acc: 0.7722 - auroc: 0.8455 - f1: 0.7917 - val_loss: 0.4500 - val_acc: 0.8313 - val_auroc: 0.8561 - val_f1: 0.8414\n",
      "Epoch 19/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6285 - acc: 0.6722 - auroc: 0.8122 - f1: 0.7251 - val_loss: 0.6008 - val_acc: 0.6687 - val_auroc: 0.7589 - val_f1: 0.7473\n",
      "Epoch 20/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5333 - acc: 0.7201 - auroc: 0.8248 - f1: 0.7690 - val_loss: 0.5487 - val_acc: 0.7562 - val_auroc: 0.8082 - val_f1: 0.7623\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 37s 25ms/step - loss: 0.6913 - acc: 0.5090 - auroc: 0.5429 - f1: 0.6275 - val_loss: 0.6836 - val_acc: 0.6250 - val_auroc: 0.6468 - val_f1: 0.6549\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6753 - acc: 0.6111 - auroc: 0.6538 - f1: 0.6006 - val_loss: 0.6576 - val_acc: 0.6250 - val_auroc: 0.7219 - val_f1: 0.5202\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6284 - acc: 0.6590 - auroc: 0.7309 - f1: 0.6349 - val_loss: 0.5678 - val_acc: 0.7188 - val_auroc: 0.7908 - val_f1: 0.7047\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5762 - acc: 0.7104 - auroc: 0.7866 - f1: 0.6970 - val_loss: 0.5949 - val_acc: 0.6687 - val_auroc: 0.8011 - val_f1: 0.7295\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5601 - acc: 0.7222 - auroc: 0.8121 - f1: 0.7114 - val_loss: 0.5051 - val_acc: 0.7562 - val_auroc: 0.8512 - val_f1: 0.7821\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5375 - acc: 0.7347 - auroc: 0.8298 - f1: 0.7306 - val_loss: 0.5055 - val_acc: 0.7438 - val_auroc: 0.8449 - val_f1: 0.7732\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6817 - acc: 0.5792 - auroc: 0.7411 - f1: 0.7015 - val_loss: 0.6659 - val_acc: 0.6188 - val_auroc: 0.7310 - val_f1: 0.6998\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6536 - acc: 0.6736 - auroc: 0.7414 - f1: 0.6582 - val_loss: 0.6376 - val_acc: 0.7250 - val_auroc: 0.7783 - val_f1: 0.7115\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6001 - acc: 0.7097 - auroc: 0.7999 - f1: 0.6850 - val_loss: 0.5656 - val_acc: 0.7375 - val_auroc: 0.8239 - val_f1: 0.7003\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6226 - acc: 0.6431 - auroc: 0.7936 - f1: 0.6871 - val_loss: 0.5558 - val_acc: 0.7688 - val_auroc: 0.8511 - val_f1: 0.7220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.7777 - acc: 0.5868 - auroc: 0.7597 - f1: 0.2525 - val_loss: 0.8042 - val_acc: 0.5000 - val_auroc: 0.6808 - val_f1: 0.0000e+00\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 38s 26ms/step - loss: 0.6850 - acc: 0.5472 - auroc: 0.5986 - f1: 0.6327 - val_loss: 0.6840 - val_acc: 0.5875 - val_auroc: 0.6178 - val_f1: 0.4723\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6535 - acc: 0.6347 - auroc: 0.6975 - f1: 0.5945 - val_loss: 0.6273 - val_acc: 0.6562 - val_auroc: 0.7272 - val_f1: 0.7022\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6264 - acc: 0.6549 - auroc: 0.7500 - f1: 0.6859 - val_loss: 0.6099 - val_acc: 0.6813 - val_auroc: 0.7572 - val_f1: 0.6253\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6094 - acc: 0.6785 - auroc: 0.7705 - f1: 0.6874 - val_loss: 0.6127 - val_acc: 0.6813 - val_auroc: 0.7581 - val_f1: 0.6074\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5904 - acc: 0.6896 - auroc: 0.7938 - f1: 0.7171 - val_loss: 0.5988 - val_acc: 0.7000 - val_auroc: 0.7737 - val_f1: 0.6469\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6191 - acc: 0.6549 - auroc: 0.7729 - f1: 0.6808 - val_loss: 0.6764 - val_acc: 0.5563 - val_auroc: 0.6817 - val_f1: 0.6807\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6258 - acc: 0.6653 - auroc: 0.7546 - f1: 0.6908 - val_loss: 0.6291 - val_acc: 0.7063 - val_auroc: 0.7277 - val_f1: 0.6587\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5876 - acc: 0.7069 - auroc: 0.7894 - f1: 0.6904 - val_loss: 0.5722 - val_acc: 0.7250 - val_auroc: 0.7904 - val_f1: 0.6885\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5461 - acc: 0.7194 - auroc: 0.8273 - f1: 0.7321 - val_loss: 0.5504 - val_acc: 0.7188 - val_auroc: 0.8149 - val_f1: 0.6886\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5204 - acc: 0.7479 - auroc: 0.8384 - f1: 0.7445 - val_loss: 0.5336 - val_acc: 0.7312 - val_auroc: 0.8385 - val_f1: 0.6903\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5340 - acc: 0.7319 - auroc: 0.8369 - f1: 0.7543 - val_loss: 0.6133 - val_acc: 0.7312 - val_auroc: 0.8345 - val_f1: 0.6581\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5505 - acc: 0.7278 - auroc: 0.8382 - f1: 0.7283 - val_loss: 0.5012 - val_acc: 0.7562 - val_auroc: 0.8480 - val_f1: 0.7681\n",
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5122 - acc: 0.7368 - auroc: 0.8527 - f1: 0.7647 - val_loss: 0.5434 - val_acc: 0.7188 - val_auroc: 0.8016 - val_f1: 0.7656\n",
      "Epoch 14/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4833 - acc: 0.7924 - auroc: 0.8735 - f1: 0.7970 - val_loss: 0.5402 - val_acc: 0.7625 - val_auroc: 0.8614 - val_f1: 0.7034\n",
      "Epoch 15/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4719 - acc: 0.7812 - auroc: 0.8814 - f1: 0.7761 - val_loss: 0.4808 - val_acc: 0.8000 - val_auroc: 0.8677 - val_f1: 0.7973\n",
      "Epoch 16/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4314 - acc: 0.8222 - auroc: 0.8929 - f1: 0.8215 - val_loss: 0.4819 - val_acc: 0.7875 - val_auroc: 0.8929 - val_f1: 0.7446\n",
      "Epoch 17/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4365 - acc: 0.8007 - auroc: 0.8954 - f1: 0.7988 - val_loss: 0.5094 - val_acc: 0.7875 - val_auroc: 0.8505 - val_f1: 0.7924\n",
      "Epoch 18/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.7072 - acc: 0.5951 - auroc: 0.7117 - f1: 0.2540 - val_loss: 0.6923 - val_acc: 0.5250 - val_auroc: 0.5928 - val_f1: 0.1919\n",
      "Epoch 19/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6742 - acc: 0.5958 - auroc: 0.6692 - f1: 0.5258 - val_loss: 0.6731 - val_acc: 0.6062 - val_auroc: 0.6312 - val_f1: 0.5956\n",
      "Epoch 20/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6436 - acc: 0.6750 - auroc: 0.7409 - f1: 0.6551 - val_loss: 0.6264 - val_acc: 0.6750 - val_auroc: 0.7406 - val_f1: 0.6247\n",
      "Epoch 21/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5936 - acc: 0.6792 - auroc: 0.8026 - f1: 0.6936 - val_loss: 0.6718 - val_acc: 0.5687 - val_auroc: 0.6604 - val_f1: 0.6737\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 38s 26ms/step - loss: 0.6869 - acc: 0.5340 - auroc: 0.5659 - f1: 0.5984 - val_loss: 0.6748 - val_acc: 0.5375 - val_auroc: 0.6204 - val_f1: 0.4519\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6610 - acc: 0.6049 - auroc: 0.6722 - f1: 0.5706 - val_loss: 0.6477 - val_acc: 0.5813 - val_auroc: 0.6656 - val_f1: 0.5007\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6194 - acc: 0.6576 - auroc: 0.7408 - f1: 0.6346 - val_loss: 0.6284 - val_acc: 0.6250 - val_auroc: 0.7022 - val_f1: 0.5329\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5729 - acc: 0.7083 - auroc: 0.7912 - f1: 0.6951 - val_loss: 0.5438 - val_acc: 0.7312 - val_auroc: 0.8003 - val_f1: 0.7422\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5409 - acc: 0.7403 - auroc: 0.8292 - f1: 0.7386 - val_loss: 0.5188 - val_acc: 0.7562 - val_auroc: 0.8338 - val_f1: 0.7688\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6822 - acc: 0.6708 - auroc: 0.7881 - f1: 0.7006 - val_loss: 0.7263 - val_acc: 0.5938 - val_auroc: 0.7598 - val_f1: 0.7003\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6492 - acc: 0.6410 - auroc: 0.7915 - f1: 0.6470 - val_loss: 0.7895 - val_acc: 0.5000 - val_auroc: 0.6784 - val_f1: 0.6636\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.7317 - acc: 0.5007 - auroc: 0.7096 - f1: 0.6640 - val_loss: 0.7057 - val_acc: 0.5000 - val_auroc: 0.6506 - val_f1: 0.6636\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6792 - acc: 0.5278 - auroc: 0.7089 - f1: 0.6723 - val_loss: 0.6832 - val_acc: 0.5312 - val_auroc: 0.6445 - val_f1: 0.6621\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6674 - acc: 0.6056 - auroc: 0.7141 - f1: 0.6832 - val_loss: 0.6768 - val_acc: 0.5938 - val_auroc: 0.6477 - val_f1: 0.6590\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6611 - acc: 0.6424 - auroc: 0.7194 - f1: 0.6751 - val_loss: 0.6711 - val_acc: 0.5875 - val_auroc: 0.6572 - val_f1: 0.6315\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "rnn_wv_scores = run_cross_validate(evaluate_lstm_model, predictors_sequences, labels, splitter, cv=5, verbose=1, epochs=12, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'val_accuracy': 0.7125,\n",
       "   'val_auroc': 0.8292466592181185,\n",
       "   'val_f1': 0.6921764373779297,\n",
       "   'val_loss': 0.5679287433624267},\n",
       "  {'val_accuracy': 0.725,\n",
       "   'val_auroc': 0.8380520032095434,\n",
       "   'val_f1': 0.6826789379119873,\n",
       "   'val_loss': 0.5591347813606262},\n",
       "  {'val_accuracy': 0.75,\n",
       "   'val_auroc': 0.8023204462412087,\n",
       "   'val_f1': 0.726509940624237,\n",
       "   'val_loss': 0.5326450049877167},\n",
       "  {'val_accuracy': 0.8,\n",
       "   'val_auroc': 0.870895269441935,\n",
       "   'val_f1': 0.8061766386032104,\n",
       "   'val_loss': 0.4710432469844818},\n",
       "  {'val_accuracy': 0.6875,\n",
       "   'val_auroc': 0.8028961450402692,\n",
       "   'val_f1': 0.7177204012870788,\n",
       "   'val_loss': 0.5881128549575806},\n",
       "  {'val_accuracy': 0.79375,\n",
       "   'val_auroc': 0.906195003916076,\n",
       "   'val_f1': 0.7984665274620056,\n",
       "   'val_loss': 0.4557736277580261},\n",
       "  {'val_accuracy': 0.825,\n",
       "   'val_auroc': 0.8966731104465266,\n",
       "   'val_f1': 0.8199194669723511,\n",
       "   'val_loss': 0.43167304396629336},\n",
       "  {'val_accuracy': 0.75625,\n",
       "   'val_auroc': 0.8121317108697788,\n",
       "   'val_f1': 0.7821115493774414,\n",
       "   'val_loss': 0.5050936102867126},\n",
       "  {'val_accuracy': 0.8,\n",
       "   'val_auroc': 0.8813883575324173,\n",
       "   'val_f1': 0.7973414182662963,\n",
       "   'val_loss': 0.48075479865074155},\n",
       "  {'val_accuracy': 0.75625,\n",
       "   'val_auroc': 0.8292426894284476,\n",
       "   'val_f1': 0.7688484430313111,\n",
       "   'val_loss': 0.5187554836273194}],\n",
       " 0.760625)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_wv_bests = results(rnn_wv_scores)\n",
    "rnn_wv_bests, statistics.mean([x['val_accuracy'] for x in rnn_wv_bests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_scores_entries =[('Bag of Words', x['val_accuracy']) for x in rnn_bow_bests] + [('Word Vectors', x['val_accuracy']) for x in rnn_wv_bests]\n",
    "rnn_scores_data_frame = DataFrame(rnn_scores_entries, columns=['input type', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(x='input type', y='accuracy', data=rnn_scores_data_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are still seeing much higher results for BOW, however our pretrained vectors are doing better than the custom ones trained on the OpSpam dataset. This shows us conclusively that word embeddings do have some value, though perhaps not on a dataset as small as this. When we test over our full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

