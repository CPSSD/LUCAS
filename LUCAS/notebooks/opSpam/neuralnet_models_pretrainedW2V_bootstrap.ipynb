{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Neural Models on pretrained Word2Vec embeddings\n",
    "\n",
    "## Feedforward Neural Network\n",
    "\n",
    "Following an experiment to compare neural models, we discovered odd results showing that bag of words could outperform embeddings. This experiment attempts to tweak the embeddings to show the expected results under the assumption that the problem is not the amount of data. If the problem is the amount of data we will investigate this in another experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will show Bag of Words results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scripts import training_helpers\n",
    "from scripts.cross_validate import run_cross_validate\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Embedding, MaxPooling2D, LSTM\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, StratifiedShuffleSplit\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from pandas import DataFrame\n",
    "from seaborn import boxplot\n",
    "from notebooks.yelp.metrics import auroc, f1\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "read_existing_embeddings = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded = tf.keras.utils.get_file(\n",
    "             fname=\"opspam.pkl\",\n",
    "             origin=\"https://storage.googleapis.com/lucas0/opspam.pkl\",\n",
    "             extract=False)\n",
    "data_frame = pd.read_pickle(downloaded).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "raw_features = data_frame['review']\n",
    "labels = [x for x in data_frame['deceptive']]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(raw_features)\n",
    "bow_features = tokenizer.texts_to_matrix(raw_features, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words = tokenizer.word_index\n",
    "corpus_vocab_size = len(corpus_words)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=10, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ff_bow_model():\n",
    "  model = Sequential([\n",
    "      Dense(16, activation=relu, input_shape=(corpus_vocab_size,), kernel_regularizer=l2(0.01)),\n",
    "      Dropout(0.25),\n",
    "      Dense(8, activation=relu, kernel_regularizer=l2(0.01)),\n",
    "      Dense(1, activation=sigmoid)\n",
    "  ])\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 523us/step - loss: 0.8211 - acc: 0.6805 - auroc: 0.7416 - f1: 0.6451 - val_loss: 0.5986 - val_acc: 0.8688 - val_auroc: 0.9378 - val_f1: 0.8602\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.4457 - acc: 0.9117 - auroc: 0.9755 - f1: 0.9071 - val_loss: 0.5149 - val_acc: 0.8750 - val_auroc: 0.9429 - val_f1: 0.8806\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.3148 - acc: 0.9742 - auroc: 0.9959 - f1: 0.9729 - val_loss: 0.4764 - val_acc: 0.8812 - val_auroc: 0.9430 - val_f1: 0.8843\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.2541 - acc: 0.9867 - auroc: 0.9991 - f1: 0.9870 - val_loss: 0.4489 - val_acc: 0.8875 - val_auroc: 0.9478 - val_f1: 0.8846\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.2263 - acc: 0.9883 - auroc: 0.9995 - f1: 0.9872 - val_loss: 0.4552 - val_acc: 0.8844 - val_auroc: 0.9430 - val_f1: 0.8854\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.1966 - acc: 0.9945 - auroc: 0.9995 - f1: 0.9950 - val_loss: 0.4586 - val_acc: 0.8844 - val_auroc: 0.9390 - val_f1: 0.8853\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1844 - acc: 0.9930 - auroc: 1.0000 - f1: 0.9934 - val_loss: 0.4493 - val_acc: 0.8719 - val_auroc: 0.9394 - val_f1: 0.8745\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1729 - acc: 0.9945 - auroc: 1.0000 - f1: 0.9942 - val_loss: 0.4581 - val_acc: 0.8656 - val_auroc: 0.9374 - val_f1: 0.8697\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.1601 - acc: 0.9961 - auroc: 1.0000 - f1: 0.9962 - val_loss: 0.4599 - val_acc: 0.8656 - val_auroc: 0.9354 - val_f1: 0.8698\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 544us/step - loss: 0.8067 - acc: 0.6914 - auroc: 0.7603 - f1: 0.7342 - val_loss: 0.5933 - val_acc: 0.8719 - val_auroc: 0.9344 - val_f1: 0.8697\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.4323 - acc: 0.9250 - auroc: 0.9838 - f1: 0.9255 - val_loss: 0.4865 - val_acc: 0.8875 - val_auroc: 0.9503 - val_f1: 0.8861\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.2987 - acc: 0.9820 - auroc: 0.9980 - f1: 0.9817 - val_loss: 0.4641 - val_acc: 0.8812 - val_auroc: 0.9523 - val_f1: 0.8787\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 146us/step - loss: 0.2500 - acc: 0.9898 - auroc: 0.9996 - f1: 0.9896 - val_loss: 0.4697 - val_acc: 0.8688 - val_auroc: 0.9511 - val_f1: 0.8668\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.2260 - acc: 0.9906 - auroc: 0.9998 - f1: 0.9915 - val_loss: 0.4679 - val_acc: 0.8781 - val_auroc: 0.9475 - val_f1: 0.8748\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.2045 - acc: 0.9992 - auroc: 0.9999 - f1: 0.9993 - val_loss: 0.4582 - val_acc: 0.8844 - val_auroc: 0.9488 - val_f1: 0.8793\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.1886 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9976 - val_loss: 0.4586 - val_acc: 0.8688 - val_auroc: 0.9434 - val_f1: 0.8568\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1767 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9973 - val_loss: 0.4610 - val_acc: 0.8656 - val_auroc: 0.9457 - val_f1: 0.8545\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1698 - acc: 0.9945 - auroc: 0.9999 - f1: 0.9946 - val_loss: 0.4577 - val_acc: 0.8719 - val_auroc: 0.9470 - val_f1: 0.8599\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1689 - acc: 0.9961 - auroc: 0.9999 - f1: 0.9962 - val_loss: 0.4503 - val_acc: 0.8656 - val_auroc: 0.9403 - val_f1: 0.8652\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 138us/step - loss: 0.1603 - acc: 0.9961 - auroc: 1.0000 - f1: 0.9960 - val_loss: 0.4491 - val_acc: 0.8781 - val_auroc: 0.9498 - val_f1: 0.8734\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.1541 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9977 - val_loss: 0.4511 - val_acc: 0.8688 - val_auroc: 0.9493 - val_f1: 0.8567\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1498 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9979 - val_loss: 0.4275 - val_acc: 0.8750 - val_auroc: 0.9538 - val_f1: 0.8665\n",
      "Epoch 14/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1568 - acc: 0.9945 - auroc: 0.9999 - f1: 0.9941 - val_loss: 0.5065 - val_acc: 0.8625 - val_auroc: 0.9440 - val_f1: 0.8693\n",
      "Epoch 15/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.1523 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9977 - val_loss: 0.4551 - val_acc: 0.8875 - val_auroc: 0.9458 - val_f1: 0.8815\n",
      "Epoch 16/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.1602 - acc: 0.9945 - auroc: 0.9999 - f1: 0.9940 - val_loss: 0.5992 - val_acc: 0.8469 - val_auroc: 0.9310 - val_f1: 0.8236\n",
      "Epoch 17/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1942 - acc: 0.9844 - auroc: 0.9995 - f1: 0.9840 - val_loss: 0.4669 - val_acc: 0.8844 - val_auroc: 0.9472 - val_f1: 0.8817\n",
      "Epoch 18/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.2005 - acc: 0.9859 - auroc: 0.9997 - f1: 0.9860 - val_loss: 0.6248 - val_acc: 0.8688 - val_auroc: 0.9342 - val_f1: 0.8740\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 561us/step - loss: 0.8860 - acc: 0.5516 - auroc: 0.6373 - f1: 0.6743 - val_loss: 0.7520 - val_acc: 0.7812 - val_auroc: 0.8960 - val_f1: 0.8088\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 131us/step - loss: 0.6084 - acc: 0.7977 - auroc: 0.9439 - f1: 0.8226 - val_loss: 0.5490 - val_acc: 0.8781 - val_auroc: 0.9498 - val_f1: 0.8852\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 132us/step - loss: 0.4242 - acc: 0.9320 - auroc: 0.9859 - f1: 0.9331 - val_loss: 0.4685 - val_acc: 0.9031 - val_auroc: 0.9577 - val_f1: 0.9044\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 132us/step - loss: 0.3250 - acc: 0.9727 - auroc: 0.9938 - f1: 0.9718 - val_loss: 0.4265 - val_acc: 0.9031 - val_auroc: 0.9605 - val_f1: 0.9039\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 136us/step - loss: 0.2606 - acc: 0.9852 - auroc: 0.9981 - f1: 0.9836 - val_loss: 0.3993 - val_acc: 0.9094 - val_auroc: 0.9645 - val_f1: 0.9111\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 136us/step - loss: 0.2304 - acc: 0.9922 - auroc: 0.9981 - f1: 0.9915 - val_loss: 0.3988 - val_acc: 0.9000 - val_auroc: 0.9617 - val_f1: 0.8999\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.2063 - acc: 0.9953 - auroc: 0.9993 - f1: 0.9948 - val_loss: 0.3937 - val_acc: 0.9000 - val_auroc: 0.9660 - val_f1: 0.9035\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1936 - acc: 0.9930 - auroc: 0.9999 - f1: 0.9926 - val_loss: 0.3947 - val_acc: 0.8844 - val_auroc: 0.9652 - val_f1: 0.8896\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 133us/step - loss: 0.1762 - acc: 0.9969 - auroc: 0.9998 - f1: 0.9969 - val_loss: 0.3929 - val_acc: 0.8812 - val_auroc: 0.9632 - val_f1: 0.8858\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 135us/step - loss: 0.1762 - acc: 0.9953 - auroc: 1.0000 - f1: 0.9954 - val_loss: 0.3864 - val_acc: 0.8969 - val_auroc: 0.9612 - val_f1: 0.8975\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 133us/step - loss: 0.1669 - acc: 0.9969 - auroc: 0.9997 - f1: 0.9967 - val_loss: 0.3822 - val_acc: 0.8969 - val_auroc: 0.9600 - val_f1: 0.8985\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 132us/step - loss: 0.1568 - acc: 0.9969 - auroc: 0.9997 - f1: 0.9972 - val_loss: 0.3889 - val_acc: 0.8781 - val_auroc: 0.9640 - val_f1: 0.8838\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 137us/step - loss: 0.1543 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9980 - val_loss: 0.3711 - val_acc: 0.9000 - val_auroc: 0.9664 - val_f1: 0.9014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25\n",
      "1280/1280 [==============================] - 0s 135us/step - loss: 0.1502 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9976 - val_loss: 0.3915 - val_acc: 0.8938 - val_auroc: 0.9596 - val_f1: 0.8959\n",
      "Epoch 15/25\n",
      "1280/1280 [==============================] - 0s 132us/step - loss: 0.1429 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9977 - val_loss: 0.3768 - val_acc: 0.8875 - val_auroc: 0.9604 - val_f1: 0.8895\n",
      "Epoch 16/25\n",
      "1280/1280 [==============================] - 0s 129us/step - loss: 0.1464 - acc: 0.9937 - auroc: 0.9998 - f1: 0.9940 - val_loss: 0.3787 - val_acc: 0.8844 - val_auroc: 0.9597 - val_f1: 0.8864\n",
      "Epoch 17/25\n",
      "1280/1280 [==============================] - 0s 133us/step - loss: 0.1435 - acc: 0.9937 - auroc: 1.0000 - f1: 0.9937 - val_loss: 0.3802 - val_acc: 0.8844 - val_auroc: 0.9621 - val_f1: 0.8892\n",
      "Epoch 18/25\n",
      "1280/1280 [==============================] - 0s 134us/step - loss: 0.1403 - acc: 0.9992 - auroc: 1.0000 - f1: 0.9992 - val_loss: 0.3692 - val_acc: 0.8875 - val_auroc: 0.9620 - val_f1: 0.8860\n",
      "Epoch 19/25\n",
      "1280/1280 [==============================] - 0s 133us/step - loss: 0.1405 - acc: 0.9953 - auroc: 1.0000 - f1: 0.9955 - val_loss: 0.3802 - val_acc: 0.8906 - val_auroc: 0.9648 - val_f1: 0.8833\n",
      "Epoch 20/25\n",
      "1280/1280 [==============================] - 0s 136us/step - loss: 0.1381 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9986 - val_loss: 0.3523 - val_acc: 0.9000 - val_auroc: 0.9660 - val_f1: 0.8989\n",
      "Epoch 21/25\n",
      "1280/1280 [==============================] - 0s 134us/step - loss: 0.1344 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9978 - val_loss: 0.3422 - val_acc: 0.9125 - val_auroc: 0.9664 - val_f1: 0.9130\n",
      "Epoch 22/25\n",
      "1280/1280 [==============================] - 0s 135us/step - loss: 0.1350 - acc: 0.9969 - auroc: 0.9997 - f1: 0.9956 - val_loss: 0.3515 - val_acc: 0.9094 - val_auroc: 0.9649 - val_f1: 0.9094\n",
      "Epoch 23/25\n",
      "1280/1280 [==============================] - 0s 129us/step - loss: 0.1280 - acc: 0.9977 - auroc: 0.9997 - f1: 0.9969 - val_loss: 0.3509 - val_acc: 0.8906 - val_auroc: 0.9637 - val_f1: 0.8933\n",
      "Epoch 24/25\n",
      "1280/1280 [==============================] - 0s 134us/step - loss: 0.1319 - acc: 0.9953 - auroc: 0.9999 - f1: 0.9948 - val_loss: 0.3641 - val_acc: 0.9031 - val_auroc: 0.9676 - val_f1: 0.9003\n",
      "Epoch 25/25\n",
      "1280/1280 [==============================] - 0s 135us/step - loss: 0.1374 - acc: 0.9969 - auroc: 0.9999 - f1: 0.9969 - val_loss: 0.3833 - val_acc: 0.8906 - val_auroc: 0.9684 - val_f1: 0.8889\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 561us/step - loss: 0.8356 - acc: 0.6703 - auroc: 0.7278 - f1: 0.5978 - val_loss: 0.6367 - val_acc: 0.8875 - val_auroc: 0.9451 - val_f1: 0.8855\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.4758 - acc: 0.9164 - auroc: 0.9736 - f1: 0.9164 - val_loss: 0.4906 - val_acc: 0.8812 - val_auroc: 0.9598 - val_f1: 0.8650\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.3217 - acc: 0.9688 - auroc: 0.9935 - f1: 0.9695 - val_loss: 0.4394 - val_acc: 0.8781 - val_auroc: 0.9625 - val_f1: 0.8627\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.2553 - acc: 0.9852 - auroc: 0.9994 - f1: 0.9852 - val_loss: 0.4348 - val_acc: 0.8875 - val_auroc: 0.9617 - val_f1: 0.8710\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.2244 - acc: 0.9898 - auroc: 0.9996 - f1: 0.9889 - val_loss: 0.4188 - val_acc: 0.8844 - val_auroc: 0.9594 - val_f1: 0.8670\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 138us/step - loss: 0.2011 - acc: 0.9922 - auroc: 0.9998 - f1: 0.9923 - val_loss: 0.3954 - val_acc: 0.8906 - val_auroc: 0.9606 - val_f1: 0.8786\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.1834 - acc: 0.9961 - auroc: 1.0000 - f1: 0.9955 - val_loss: 0.3934 - val_acc: 0.8875 - val_auroc: 0.9611 - val_f1: 0.8737\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1781 - acc: 0.9906 - auroc: 0.9999 - f1: 0.9907 - val_loss: 0.3764 - val_acc: 0.8750 - val_auroc: 0.9571 - val_f1: 0.8654\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 138us/step - loss: 0.1694 - acc: 0.9945 - auroc: 1.0000 - f1: 0.9944 - val_loss: 0.3805 - val_acc: 0.8906 - val_auroc: 0.9523 - val_f1: 0.8801\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1570 - acc: 0.9945 - auroc: 0.9997 - f1: 0.9943 - val_loss: 0.3749 - val_acc: 0.9000 - val_auroc: 0.9536 - val_f1: 0.8966\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1544 - acc: 0.9945 - auroc: 0.9998 - f1: 0.9950 - val_loss: 0.3810 - val_acc: 0.8812 - val_auroc: 0.9552 - val_f1: 0.8733\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1515 - acc: 0.9914 - auroc: 0.9995 - f1: 0.9900 - val_loss: 0.3714 - val_acc: 0.8906 - val_auroc: 0.9547 - val_f1: 0.8852\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 137us/step - loss: 0.1474 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9977 - val_loss: 0.3691 - val_acc: 0.8750 - val_auroc: 0.9586 - val_f1: 0.8669\n",
      "Epoch 14/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1388 - acc: 0.9953 - auroc: 0.9999 - f1: 0.9960 - val_loss: 0.3831 - val_acc: 0.8719 - val_auroc: 0.9521 - val_f1: 0.8675\n",
      "Epoch 15/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1358 - acc: 0.9961 - auroc: 1.0000 - f1: 0.9961 - val_loss: 0.3737 - val_acc: 0.8844 - val_auroc: 0.9556 - val_f1: 0.8779\n",
      "Epoch 16/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1325 - acc: 0.9969 - auroc: 0.9999 - f1: 0.9963 - val_loss: 0.3989 - val_acc: 0.8750 - val_auroc: 0.9507 - val_f1: 0.8650\n",
      "Epoch 17/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.1330 - acc: 0.9961 - auroc: 0.9999 - f1: 0.9961 - val_loss: 0.4003 - val_acc: 0.8781 - val_auroc: 0.9517 - val_f1: 0.8751\n",
      "Epoch 18/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1275 - acc: 0.9992 - auroc: 0.9999 - f1: 0.9992 - val_loss: 0.3761 - val_acc: 0.8812 - val_auroc: 0.9531 - val_f1: 0.8768\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 676us/step - loss: 0.8584 - acc: 0.5625 - auroc: 0.7288 - f1: 0.2345 - val_loss: 0.7283 - val_acc: 0.7438 - val_auroc: 0.9019 - val_f1: 0.6678\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.6377 - acc: 0.7594 - auroc: 0.9616 - f1: 0.6667 - val_loss: 0.6325 - val_acc: 0.8375 - val_auroc: 0.9510 - val_f1: 0.7981\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.5285 - acc: 0.8992 - auroc: 0.9877 - f1: 0.8836 - val_loss: 0.5646 - val_acc: 0.8781 - val_auroc: 0.9565 - val_f1: 0.8642\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.4290 - acc: 0.9477 - auroc: 0.9916 - f1: 0.9443 - val_loss: 0.4954 - val_acc: 0.8875 - val_auroc: 0.9589 - val_f1: 0.8875\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 147us/step - loss: 0.3328 - acc: 0.9719 - auroc: 0.9956 - f1: 0.9714 - val_loss: 0.4423 - val_acc: 0.8969 - val_auroc: 0.9565 - val_f1: 0.8970\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.2825 - acc: 0.9781 - auroc: 0.9959 - f1: 0.9765 - val_loss: 0.4202 - val_acc: 0.8875 - val_auroc: 0.9566 - val_f1: 0.8884\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.2484 - acc: 0.9844 - auroc: 0.9959 - f1: 0.9847 - val_loss: 0.4003 - val_acc: 0.9062 - val_auroc: 0.9590 - val_f1: 0.9061\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.2140 - acc: 0.9906 - auroc: 0.9993 - f1: 0.9904 - val_loss: 0.3885 - val_acc: 0.9000 - val_auroc: 0.9567 - val_f1: 0.8977\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 146us/step - loss: 0.1989 - acc: 0.9922 - auroc: 0.9985 - f1: 0.9925 - val_loss: 0.3852 - val_acc: 0.9031 - val_auroc: 0.9584 - val_f1: 0.9022\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1953 - acc: 0.9883 - auroc: 0.9987 - f1: 0.9882 - val_loss: 0.3937 - val_acc: 0.8938 - val_auroc: 0.9553 - val_f1: 0.8905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1751 - acc: 0.9953 - auroc: 1.0000 - f1: 0.9954 - val_loss: 0.3916 - val_acc: 0.8781 - val_auroc: 0.9536 - val_f1: 0.8790\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1651 - acc: 0.9961 - auroc: 0.9999 - f1: 0.9961 - val_loss: 0.3778 - val_acc: 0.8875 - val_auroc: 0.9584 - val_f1: 0.8859\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 134us/step - loss: 0.1617 - acc: 0.9961 - auroc: 0.9997 - f1: 0.9966 - val_loss: 0.3745 - val_acc: 0.8906 - val_auroc: 0.9569 - val_f1: 0.8838\n",
      "Epoch 14/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1507 - acc: 0.9969 - auroc: 1.0000 - f1: 0.9967 - val_loss: 0.3781 - val_acc: 0.8719 - val_auroc: 0.9576 - val_f1: 0.8714\n",
      "Epoch 15/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1422 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9979 - val_loss: 0.3758 - val_acc: 0.8719 - val_auroc: 0.9575 - val_f1: 0.8703\n",
      "Epoch 16/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1409 - acc: 0.9961 - auroc: 0.9999 - f1: 0.9963 - val_loss: 0.3990 - val_acc: 0.8812 - val_auroc: 0.9544 - val_f1: 0.8695\n",
      "Epoch 17/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1444 - acc: 0.9937 - auroc: 0.9998 - f1: 0.9943 - val_loss: 0.4027 - val_acc: 0.8938 - val_auroc: 0.9536 - val_f1: 0.8853\n",
      "Epoch 18/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1628 - acc: 0.9922 - auroc: 0.9996 - f1: 0.9916 - val_loss: 0.4445 - val_acc: 0.8656 - val_auroc: 0.9523 - val_f1: 0.8754\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 659us/step - loss: 0.8397 - acc: 0.6992 - auroc: 0.7500 - f1: 0.6579 - val_loss: 0.6517 - val_acc: 0.8844 - val_auroc: 0.9465 - val_f1: 0.8799\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 149us/step - loss: 0.4827 - acc: 0.9195 - auroc: 0.9762 - f1: 0.9149 - val_loss: 0.4762 - val_acc: 0.9125 - val_auroc: 0.9613 - val_f1: 0.9136\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.3273 - acc: 0.9703 - auroc: 0.9940 - f1: 0.9684 - val_loss: 0.4298 - val_acc: 0.9031 - val_auroc: 0.9668 - val_f1: 0.9047\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.2568 - acc: 0.9883 - auroc: 0.9992 - f1: 0.9873 - val_loss: 0.4171 - val_acc: 0.9031 - val_auroc: 0.9688 - val_f1: 0.9070\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.2207 - acc: 0.9922 - auroc: 0.9998 - f1: 0.9915 - val_loss: 0.3914 - val_acc: 0.9031 - val_auroc: 0.9700 - val_f1: 0.9042\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1922 - acc: 0.9953 - auroc: 0.9997 - f1: 0.9945 - val_loss: 0.4138 - val_acc: 0.8906 - val_auroc: 0.9696 - val_f1: 0.8958\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1699 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9976 - val_loss: 0.3997 - val_acc: 0.8906 - val_auroc: 0.9699 - val_f1: 0.8920\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1676 - acc: 0.9937 - auroc: 1.0000 - f1: 0.9935 - val_loss: 0.3893 - val_acc: 0.9000 - val_auroc: 0.9617 - val_f1: 0.8985\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1590 - acc: 0.9953 - auroc: 1.0000 - f1: 0.9954 - val_loss: 0.3844 - val_acc: 0.9094 - val_auroc: 0.9665 - val_f1: 0.9117\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 147us/step - loss: 0.1431 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9985 - val_loss: 0.4114 - val_acc: 0.9062 - val_auroc: 0.9629 - val_f1: 0.9102\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 146us/step - loss: 0.1375 - acc: 0.9969 - auroc: 1.0000 - f1: 0.9970 - val_loss: 0.4012 - val_acc: 0.8906 - val_auroc: 0.9668 - val_f1: 0.8968\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1293 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9976 - val_loss: 0.3869 - val_acc: 0.8969 - val_auroc: 0.9711 - val_f1: 0.8996\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.1257 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9981 - val_loss: 0.3834 - val_acc: 0.8969 - val_auroc: 0.9692 - val_f1: 0.8985\n",
      "Epoch 14/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1343 - acc: 0.9977 - auroc: 0.9985 - f1: 0.9979 - val_loss: 0.3697 - val_acc: 0.8938 - val_auroc: 0.9652 - val_f1: 0.8935\n",
      "Epoch 15/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1251 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9985 - val_loss: 0.3772 - val_acc: 0.8969 - val_auroc: 0.9640 - val_f1: 0.8960\n",
      "Epoch 16/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1234 - acc: 0.9977 - auroc: 0.9999 - f1: 0.9974 - val_loss: 0.3452 - val_acc: 0.8969 - val_auroc: 0.9695 - val_f1: 0.8970\n",
      "Epoch 17/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1193 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9980 - val_loss: 0.3922 - val_acc: 0.8875 - val_auroc: 0.9601 - val_f1: 0.8895\n",
      "Epoch 18/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1159 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4003 - val_acc: 0.8844 - val_auroc: 0.9561 - val_f1: 0.8824\n",
      "Epoch 19/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1148 - acc: 0.9992 - auroc: 0.9999 - f1: 0.9993 - val_loss: 0.4328 - val_acc: 0.8656 - val_auroc: 0.9507 - val_f1: 0.8618\n",
      "Epoch 20/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1237 - acc: 0.9953 - auroc: 0.9999 - f1: 0.9947 - val_loss: 0.4271 - val_acc: 0.8750 - val_auroc: 0.9601 - val_f1: 0.8804\n",
      "Epoch 21/25\n",
      "1280/1280 [==============================] - 0s 147us/step - loss: 0.1168 - acc: 0.9969 - auroc: 0.9999 - f1: 0.9972 - val_loss: 0.4003 - val_acc: 0.8781 - val_auroc: 0.9605 - val_f1: 0.8732\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 774us/step - loss: 0.8592 - acc: 0.6148 - auroc: 0.6927 - f1: 0.5076 - val_loss: 0.7280 - val_acc: 0.7656 - val_auroc: 0.8791 - val_f1: 0.7346\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.5505 - acc: 0.8820 - auroc: 0.9517 - f1: 0.8801 - val_loss: 0.5365 - val_acc: 0.8562 - val_auroc: 0.9417 - val_f1: 0.8556\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.3573 - acc: 0.9516 - auroc: 0.9890 - f1: 0.9505 - val_loss: 0.4532 - val_acc: 0.8719 - val_auroc: 0.9565 - val_f1: 0.8750\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.2752 - acc: 0.9727 - auroc: 0.9974 - f1: 0.9724 - val_loss: 0.4361 - val_acc: 0.8812 - val_auroc: 0.9537 - val_f1: 0.8801\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.2329 - acc: 0.9813 - auroc: 0.9989 - f1: 0.9810 - val_loss: 0.4219 - val_acc: 0.8781 - val_auroc: 0.9562 - val_f1: 0.8835\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.2022 - acc: 0.9906 - auroc: 0.9997 - f1: 0.9904 - val_loss: 0.4233 - val_acc: 0.8719 - val_auroc: 0.9494 - val_f1: 0.8744\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.1877 - acc: 0.9898 - auroc: 0.9997 - f1: 0.9892 - val_loss: 0.4065 - val_acc: 0.8812 - val_auroc: 0.9502 - val_f1: 0.8829\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1694 - acc: 0.9961 - auroc: 0.9999 - f1: 0.9958 - val_loss: 0.4091 - val_acc: 0.8719 - val_auroc: 0.9514 - val_f1: 0.8773\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1651 - acc: 0.9922 - auroc: 1.0000 - f1: 0.9917 - val_loss: 0.4091 - val_acc: 0.8812 - val_auroc: 0.9531 - val_f1: 0.8854\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1566 - acc: 0.9945 - auroc: 0.9999 - f1: 0.9941 - val_loss: 0.4092 - val_acc: 0.8750 - val_auroc: 0.9557 - val_f1: 0.8817\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1522 - acc: 0.9937 - auroc: 0.9998 - f1: 0.9939 - val_loss: 0.4061 - val_acc: 0.8688 - val_auroc: 0.9497 - val_f1: 0.8718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1488 - acc: 0.9922 - auroc: 0.9999 - f1: 0.9921 - val_loss: 0.4094 - val_acc: 0.8750 - val_auroc: 0.9481 - val_f1: 0.8721\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.1427 - acc: 0.9969 - auroc: 0.9999 - f1: 0.9968 - val_loss: 0.4287 - val_acc: 0.8594 - val_auroc: 0.9465 - val_f1: 0.8545\n",
      "Epoch 14/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.1400 - acc: 0.9945 - auroc: 1.0000 - f1: 0.9943 - val_loss: 0.4371 - val_acc: 0.8625 - val_auroc: 0.9432 - val_f1: 0.8605\n",
      "Epoch 15/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.1314 - acc: 0.9992 - auroc: 0.9999 - f1: 0.9992 - val_loss: 0.4391 - val_acc: 0.8750 - val_auroc: 0.9479 - val_f1: 0.8692\n",
      "Epoch 16/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.1308 - acc: 0.9937 - auroc: 0.9997 - f1: 0.9936 - val_loss: 0.4256 - val_acc: 0.8781 - val_auroc: 0.9479 - val_f1: 0.8736\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 826us/step - loss: 0.8244 - acc: 0.6609 - auroc: 0.7274 - f1: 0.6249 - val_loss: 0.6434 - val_acc: 0.8125 - val_auroc: 0.9169 - val_f1: 0.8289\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 146us/step - loss: 0.4548 - acc: 0.9094 - auroc: 0.9680 - f1: 0.9048 - val_loss: 0.4941 - val_acc: 0.8625 - val_auroc: 0.9401 - val_f1: 0.8657\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.3046 - acc: 0.9633 - auroc: 0.9953 - f1: 0.9629 - val_loss: 0.4610 - val_acc: 0.8656 - val_auroc: 0.9472 - val_f1: 0.8646\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.2542 - acc: 0.9797 - auroc: 0.9986 - f1: 0.9773 - val_loss: 0.4602 - val_acc: 0.8750 - val_auroc: 0.9426 - val_f1: 0.8678\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 146us/step - loss: 0.2225 - acc: 0.9820 - auroc: 0.9993 - f1: 0.9824 - val_loss: 0.4641 - val_acc: 0.8656 - val_auroc: 0.9397 - val_f1: 0.8676\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1926 - acc: 0.9953 - auroc: 0.9995 - f1: 0.9949 - val_loss: 0.4405 - val_acc: 0.8750 - val_auroc: 0.9452 - val_f1: 0.8781\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 139us/step - loss: 0.1773 - acc: 0.9922 - auroc: 0.9997 - f1: 0.9915 - val_loss: 0.4509 - val_acc: 0.8656 - val_auroc: 0.9426 - val_f1: 0.8556\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1714 - acc: 0.9930 - auroc: 0.9999 - f1: 0.9925 - val_loss: 0.4493 - val_acc: 0.8812 - val_auroc: 0.9452 - val_f1: 0.8717\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.1575 - acc: 0.9953 - auroc: 0.9999 - f1: 0.9953 - val_loss: 0.4345 - val_acc: 0.8594 - val_auroc: 0.9481 - val_f1: 0.8486\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 146us/step - loss: 0.1525 - acc: 0.9953 - auroc: 1.0000 - f1: 0.9953 - val_loss: 0.4250 - val_acc: 0.8625 - val_auroc: 0.9489 - val_f1: 0.8603\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 149us/step - loss: 0.1452 - acc: 0.9945 - auroc: 1.0000 - f1: 0.9943 - val_loss: 0.4313 - val_acc: 0.8688 - val_auroc: 0.9485 - val_f1: 0.8596\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 141us/step - loss: 0.1409 - acc: 0.9953 - auroc: 0.9999 - f1: 0.9954 - val_loss: 0.4239 - val_acc: 0.8719 - val_auroc: 0.9484 - val_f1: 0.8608\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.1333 - acc: 0.9969 - auroc: 0.9999 - f1: 0.9967 - val_loss: 0.4302 - val_acc: 0.8656 - val_auroc: 0.9475 - val_f1: 0.8614\n",
      "Epoch 14/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1293 - acc: 0.9992 - auroc: 1.0000 - f1: 0.9991 - val_loss: 0.4577 - val_acc: 0.8844 - val_auroc: 0.9434 - val_f1: 0.8826\n",
      "Epoch 15/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.1323 - acc: 0.9961 - auroc: 0.9999 - f1: 0.9961 - val_loss: 0.4722 - val_acc: 0.8719 - val_auroc: 0.9399 - val_f1: 0.8675\n",
      "Epoch 16/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.1268 - acc: 0.9984 - auroc: 0.9998 - f1: 0.9983 - val_loss: 0.5137 - val_acc: 0.8406 - val_auroc: 0.9394 - val_f1: 0.8543\n",
      "Epoch 17/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1251 - acc: 0.9969 - auroc: 1.0000 - f1: 0.9966 - val_loss: 0.5358 - val_acc: 0.8313 - val_auroc: 0.9385 - val_f1: 0.8473\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 858us/step - loss: 0.8477 - acc: 0.6320 - auroc: 0.6876 - f1: 0.5824 - val_loss: 0.6441 - val_acc: 0.8562 - val_auroc: 0.9286 - val_f1: 0.8601\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 153us/step - loss: 0.4846 - acc: 0.8836 - auroc: 0.9533 - f1: 0.8804 - val_loss: 0.4865 - val_acc: 0.8719 - val_auroc: 0.9512 - val_f1: 0.8760\n",
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.3048 - acc: 0.9680 - auroc: 0.9952 - f1: 0.9684 - val_loss: 0.4584 - val_acc: 0.8875 - val_auroc: 0.9461 - val_f1: 0.8905\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 140us/step - loss: 0.2436 - acc: 0.9891 - auroc: 0.9994 - f1: 0.9881 - val_loss: 0.4568 - val_acc: 0.8812 - val_auroc: 0.9438 - val_f1: 0.8758\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.2077 - acc: 0.9961 - auroc: 1.0000 - f1: 0.9960 - val_loss: 0.4521 - val_acc: 0.8844 - val_auroc: 0.9436 - val_f1: 0.8840\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1955 - acc: 0.9906 - auroc: 0.9995 - f1: 0.9909 - val_loss: 0.5005 - val_acc: 0.8531 - val_auroc: 0.9303 - val_f1: 0.8403\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 149us/step - loss: 0.1841 - acc: 0.9937 - auroc: 0.9997 - f1: 0.9935 - val_loss: 0.4559 - val_acc: 0.8750 - val_auroc: 0.9421 - val_f1: 0.8704\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 147us/step - loss: 0.1672 - acc: 0.9984 - auroc: 0.9999 - f1: 0.9983 - val_loss: 0.4448 - val_acc: 0.8906 - val_auroc: 0.9434 - val_f1: 0.8886\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 147us/step - loss: 0.1590 - acc: 0.9969 - auroc: 0.9999 - f1: 0.9967 - val_loss: 0.4767 - val_acc: 0.8781 - val_auroc: 0.9342 - val_f1: 0.8726\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1587 - acc: 0.9953 - auroc: 0.9999 - f1: 0.9946 - val_loss: 0.4631 - val_acc: 0.8750 - val_auroc: 0.9342 - val_f1: 0.8751\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1512 - acc: 0.9969 - auroc: 0.9989 - f1: 0.9970 - val_loss: 0.4441 - val_acc: 0.8812 - val_auroc: 0.9378 - val_f1: 0.8776\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 146us/step - loss: 0.1517 - acc: 0.9937 - auroc: 1.0000 - f1: 0.9934 - val_loss: 0.4683 - val_acc: 0.8750 - val_auroc: 0.9317 - val_f1: 0.8725\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1474 - acc: 0.9953 - auroc: 0.9999 - f1: 0.9952 - val_loss: 0.4966 - val_acc: 0.8562 - val_auroc: 0.9304 - val_f1: 0.8552\n",
      "Epoch 14/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.1366 - acc: 0.9992 - auroc: 1.0000 - f1: 0.9991 - val_loss: 0.5271 - val_acc: 0.8531 - val_auroc: 0.9191 - val_f1: 0.8405\n",
      "Epoch 15/25\n",
      "1280/1280 [==============================] - 0s 147us/step - loss: 0.1301 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.5108 - val_acc: 0.8531 - val_auroc: 0.9253 - val_f1: 0.8573\n",
      "Epoch 16/25\n",
      "1280/1280 [==============================] - 0s 153us/step - loss: 0.1290 - acc: 0.9984 - auroc: 1.0000 - f1: 0.9985 - val_loss: 0.4832 - val_acc: 0.8469 - val_auroc: 0.9348 - val_f1: 0.8477\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/25\n",
      "1280/1280 [==============================] - 1s 913us/step - loss: 0.8687 - acc: 0.5711 - auroc: 0.6385 - f1: 0.6478 - val_loss: 0.7554 - val_acc: 0.6438 - val_auroc: 0.8548 - val_f1: 0.7266\n",
      "Epoch 2/25\n",
      "1280/1280 [==============================] - 0s 147us/step - loss: 0.6286 - acc: 0.8180 - auroc: 0.9285 - f1: 0.8368 - val_loss: 0.5858 - val_acc: 0.8375 - val_auroc: 0.9346 - val_f1: 0.8499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n",
      "1280/1280 [==============================] - 0s 151us/step - loss: 0.4209 - acc: 0.9344 - auroc: 0.9835 - f1: 0.9358 - val_loss: 0.4854 - val_acc: 0.8656 - val_auroc: 0.9434 - val_f1: 0.8663\n",
      "Epoch 4/25\n",
      "1280/1280 [==============================] - 0s 142us/step - loss: 0.3183 - acc: 0.9531 - auroc: 0.9942 - f1: 0.9527 - val_loss: 0.4528 - val_acc: 0.8688 - val_auroc: 0.9453 - val_f1: 0.8646\n",
      "Epoch 5/25\n",
      "1280/1280 [==============================] - 0s 147us/step - loss: 0.2642 - acc: 0.9773 - auroc: 0.9985 - f1: 0.9783 - val_loss: 0.4503 - val_acc: 0.8688 - val_auroc: 0.9399 - val_f1: 0.8627\n",
      "Epoch 6/25\n",
      "1280/1280 [==============================] - 0s 145us/step - loss: 0.2249 - acc: 0.9859 - auroc: 0.9989 - f1: 0.9845 - val_loss: 0.4476 - val_acc: 0.8656 - val_auroc: 0.9399 - val_f1: 0.8618\n",
      "Epoch 7/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.2031 - acc: 0.9906 - auroc: 0.9997 - f1: 0.9893 - val_loss: 0.4431 - val_acc: 0.8719 - val_auroc: 0.9447 - val_f1: 0.8685\n",
      "Epoch 8/25\n",
      "1280/1280 [==============================] - 0s 146us/step - loss: 0.1832 - acc: 0.9930 - auroc: 0.9997 - f1: 0.9931 - val_loss: 0.4388 - val_acc: 0.8688 - val_auroc: 0.9498 - val_f1: 0.8654\n",
      "Epoch 9/25\n",
      "1280/1280 [==============================] - 0s 144us/step - loss: 0.1744 - acc: 0.9922 - auroc: 1.0000 - f1: 0.9923 - val_loss: 0.4528 - val_acc: 0.8688 - val_auroc: 0.9393 - val_f1: 0.8638\n",
      "Epoch 10/25\n",
      "1280/1280 [==============================] - 0s 143us/step - loss: 0.1663 - acc: 0.9953 - auroc: 0.9996 - f1: 0.9953 - val_loss: 0.4588 - val_acc: 0.8594 - val_auroc: 0.9391 - val_f1: 0.8591\n",
      "Epoch 11/25\n",
      "1280/1280 [==============================] - 0s 149us/step - loss: 0.1583 - acc: 0.9969 - auroc: 1.0000 - f1: 0.9964 - val_loss: 0.5097 - val_acc: 0.8375 - val_auroc: 0.9387 - val_f1: 0.8475\n",
      "Epoch 12/25\n",
      "1280/1280 [==============================] - 0s 148us/step - loss: 0.1561 - acc: 0.9930 - auroc: 0.9999 - f1: 0.9931 - val_loss: 0.4963 - val_acc: 0.8625 - val_auroc: 0.9446 - val_f1: 0.8657\n",
      "Epoch 13/25\n",
      "1280/1280 [==============================] - 0s 149us/step - loss: 0.1458 - acc: 0.9977 - auroc: 1.0000 - f1: 0.9976 - val_loss: 0.4751 - val_acc: 0.8594 - val_auroc: 0.9407 - val_f1: 0.8592\n"
     ]
    }
   ],
   "source": [
    "def evaluate_ffnn_model(train_X, train_y, test_X, test_y):\n",
    "    ffnn_model = get_ff_bow_model()\n",
    "    return ffnn_model.fit(train_X, train_y, epochs=25, batch_size=32, verbose=1, shuffle=False,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "                   validation_data=(test_X, test_y))\n",
    "\n",
    "ff_bow_scores = run_cross_validate(evaluate_ffnn_model, bow_features, labels, splitter, cv=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we will get results for embeddings. This time I will use pretrained Word2Vec. Although this was not trained directly on words from our dataset, the Word2Vec has a higher dimensionality (making it harder to run on our machines) and so may show better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(scores):\n",
    "    bests = []\n",
    "    for his in scores:\n",
    "        best = None\n",
    "        min_val_loss = 99999\n",
    "        h = his.history\n",
    "        for i, val_loss in enumerate(h['val_loss']):\n",
    "            if val_loss < min_val_loss:\n",
    "                min_val_loss = val_loss\n",
    "                best = { 'val_loss': val_loss, 'val_accuracy': h['val_acc'][i], 'val_auroc': h['auroc'][i], 'val_f1': h['val_f1'][i]}\n",
    "        bests.append(best)\n",
    "    return bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests = results(ff_bow_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'val_accuracy': 0.8875,\n",
       "   'val_auroc': 0.9991180117880486,\n",
       "   'val_f1': 0.884575891494751,\n",
       "   'val_loss': 0.4488638907670975},\n",
       "  {'val_accuracy': 0.875,\n",
       "   'val_auroc': 1.0,\n",
       "   'val_f1': 0.8665441572666168,\n",
       "   'val_loss': 0.4275026202201843},\n",
       "  {'val_accuracy': 0.9125,\n",
       "   'val_auroc': 1.0,\n",
       "   'val_f1': 0.9129968762397767,\n",
       "   'val_loss': 0.3421775847673416},\n",
       "  {'val_accuracy': 0.875,\n",
       "   'val_auroc': 1.0,\n",
       "   'val_f1': 0.8668681204319,\n",
       "   'val_loss': 0.3691168874502182},\n",
       "  {'val_accuracy': 0.890625,\n",
       "   'val_auroc': 0.9996875,\n",
       "   'val_f1': 0.8838273704051971,\n",
       "   'val_loss': 0.37449787706136706},\n",
       "  {'val_accuracy': 0.896875,\n",
       "   'val_auroc': 0.9999019607843138,\n",
       "   'val_f1': 0.8969626903533936,\n",
       "   'val_loss': 0.34524360597133635},\n",
       "  {'val_accuracy': 0.86875,\n",
       "   'val_auroc': 0.9998039215686274,\n",
       "   'val_f1': 0.8717897593975067,\n",
       "   'val_loss': 0.4060693964362144},\n",
       "  {'val_accuracy': 0.871875,\n",
       "   'val_auroc': 0.9998987854251012,\n",
       "   'val_f1': 0.8607736051082611,\n",
       "   'val_loss': 0.4239336043596268},\n",
       "  {'val_accuracy': 0.88125,\n",
       "   'val_auroc': 0.9989215686274509,\n",
       "   'val_f1': 0.8775607109069824,\n",
       "   'val_loss': 0.4441039994359016},\n",
       "  {'val_accuracy': 0.86875,\n",
       "   'val_auroc': 0.9997054811507937,\n",
       "   'val_f1': 0.8653841972351074,\n",
       "   'val_loss': 0.438772514462471}],\n",
       " 0.8828125)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests, statistics.mean([x['val_accuracy'] for x in bests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = None\n",
    "embedding_length = 0\n",
    "\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format(\"../../data/GoogleNews-vectors-negative300.bin\",\n",
    "                                                                 binary=True)\n",
    "embedding_length = word_vectors.vector_size\n",
    "    \n",
    "embedding_matrix = np.zeros((corpus_vocab_size, embedding_length))\n",
    "for word, index in corpus_words.items():\n",
    "  if word in word_vectors.vocab:\n",
    "    embedding_matrix[index] = np.array(word_vectors[word], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ff_wv_model():\n",
    "  model_ff_wv = Sequential([\n",
    "      Embedding(corpus_vocab_size, embedding_length, weights=[embedding_matrix], trainable=False,\n",
    "                input_length=corpus_vocab_size),\n",
    "      Flatten(),\n",
    "      Dense(16, activation=relu, kernel_regularizer=l2(0.01)),\n",
    "      Dropout(0.25),\n",
    "      Dense(8, activation=relu, kernel_regularizer=l2(0.01)),\n",
    "      Dense(1, activation=sigmoid)\n",
    "  ])\n",
    "  model_ff_wv.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', auroc, f1])\n",
    "  return model_ff_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 30s 21ms/step - loss: 0.9887 - acc: 0.5604 - auroc: 0.6524 - f1: 0.2396 - val_loss: 1.0446 - val_acc: 0.6000 - val_auroc: 0.8253 - val_f1: 0.3246\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0809 - acc: 0.6417 - auroc: 0.7355 - f1: 0.5392 - val_loss: 1.0094 - val_acc: 0.6000 - val_auroc: 0.7975 - val_f1: 0.3796\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.9907 - acc: 0.6785 - auroc: 0.7631 - f1: 0.5929 - val_loss: 0.9520 - val_acc: 0.6375 - val_auroc: 0.8102 - val_f1: 0.4555\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.9458 - acc: 0.6847 - auroc: 0.7736 - f1: 0.6303 - val_loss: 0.8963 - val_acc: 0.6375 - val_auroc: 0.8281 - val_f1: 0.4484\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.9121 - acc: 0.7132 - auroc: 0.7937 - f1: 0.6719 - val_loss: 0.8887 - val_acc: 0.7188 - val_auroc: 0.8438 - val_f1: 0.6383\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.9316 - acc: 0.7097 - auroc: 0.7935 - f1: 0.6838 - val_loss: 0.9623 - val_acc: 0.7312 - val_auroc: 0.8001 - val_f1: 0.7089\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.9270 - acc: 0.7174 - auroc: 0.7901 - f1: 0.7113 - val_loss: 0.9365 - val_acc: 0.7063 - val_auroc: 0.8577 - val_f1: 0.5825\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.9170 - acc: 0.7521 - auroc: 0.8182 - f1: 0.7414 - val_loss: 0.9476 - val_acc: 0.6875 - val_auroc: 0.8141 - val_f1: 0.6309\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.8990 - acc: 0.7667 - auroc: 0.8247 - f1: 0.7528 - val_loss: 0.9001 - val_acc: 0.7188 - val_auroc: 0.8261 - val_f1: 0.6553\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.9187 - acc: 0.7500 - auroc: 0.8146 - f1: 0.7532 - val_loss: 0.9614 - val_acc: 0.7188 - val_auroc: 0.8112 - val_f1: 0.6592\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 29s 20ms/step - loss: 0.9421 - acc: 0.5618 - auroc: 0.6276 - f1: 0.5004 - val_loss: 0.9560 - val_acc: 0.6500 - val_auroc: 0.8257 - val_f1: 0.4988\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0923 - acc: 0.6431 - auroc: 0.7346 - f1: 0.6142 - val_loss: 1.1152 - val_acc: 0.7188 - val_auroc: 0.7822 - val_f1: 0.7023\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1398 - acc: 0.6778 - auroc: 0.7575 - f1: 0.6844 - val_loss: 1.0973 - val_acc: 0.6937 - val_auroc: 0.8240 - val_f1: 0.6400\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1326 - acc: 0.6750 - auroc: 0.7694 - f1: 0.6774 - val_loss: 1.0678 - val_acc: 0.7625 - val_auroc: 0.8086 - val_f1: 0.7634\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0789 - acc: 0.6965 - auroc: 0.7832 - f1: 0.7063 - val_loss: 1.0557 - val_acc: 0.6937 - val_auroc: 0.8032 - val_f1: 0.6978\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0787 - acc: 0.7160 - auroc: 0.7911 - f1: 0.7236 - val_loss: 1.0866 - val_acc: 0.7188 - val_auroc: 0.8328 - val_f1: 0.6728\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 29s 20ms/step - loss: 1.0234 - acc: 0.6438 - auroc: 0.7147 - f1: 0.5797 - val_loss: 1.2533 - val_acc: 0.6875 - val_auroc: 0.7708 - val_f1: 0.6418\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.2357 - acc: 0.6993 - auroc: 0.7937 - f1: 0.6901 - val_loss: 1.2260 - val_acc: 0.6937 - val_auroc: 0.7776 - val_f1: 0.6413\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1730 - acc: 0.7382 - auroc: 0.8193 - f1: 0.7429 - val_loss: 1.2634 - val_acc: 0.6562 - val_auroc: 0.7732 - val_f1: 0.5546\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1739 - acc: 0.7528 - auroc: 0.8468 - f1: 0.7459 - val_loss: 1.2532 - val_acc: 0.6937 - val_auroc: 0.7570 - val_f1: 0.6794\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1834 - acc: 0.7569 - auroc: 0.8498 - f1: 0.7615 - val_loss: 1.2684 - val_acc: 0.7188 - val_auroc: 0.7857 - val_f1: 0.7094\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1757 - acc: 0.7681 - auroc: 0.8567 - f1: 0.7710 - val_loss: 1.2114 - val_acc: 0.7000 - val_auroc: 0.7631 - val_f1: 0.6804\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0997 - acc: 0.7875 - auroc: 0.8714 - f1: 0.7932 - val_loss: 1.2574 - val_acc: 0.7000 - val_auroc: 0.7560 - val_f1: 0.6911\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1083 - acc: 0.8021 - auroc: 0.8797 - f1: 0.8026 - val_loss: 1.3156 - val_acc: 0.6813 - val_auroc: 0.7627 - val_f1: 0.6338\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1190 - acc: 0.7875 - auroc: 0.8713 - f1: 0.7904 - val_loss: 1.2556 - val_acc: 0.6875 - val_auroc: 0.7576 - val_f1: 0.6563\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0690 - acc: 0.7979 - auroc: 0.8885 - f1: 0.8014 - val_loss: 1.2508 - val_acc: 0.7312 - val_auroc: 0.7952 - val_f1: 0.6922\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1249 - acc: 0.7951 - auroc: 0.8808 - f1: 0.8010 - val_loss: 1.2260 - val_acc: 0.6937 - val_auroc: 0.7718 - val_f1: 0.7271\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 30s 21ms/step - loss: 0.9369 - acc: 0.5215 - auroc: 0.6669 - f1: 0.6544 - val_loss: 0.9502 - val_acc: 0.6062 - val_auroc: 0.7922 - val_f1: 0.7081\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0715 - acc: 0.6535 - auroc: 0.7329 - f1: 0.6500 - val_loss: 1.1230 - val_acc: 0.7125 - val_auroc: 0.7742 - val_f1: 0.7432\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1912 - acc: 0.6778 - auroc: 0.7390 - f1: 0.6759 - val_loss: 1.1830 - val_acc: 0.7375 - val_auroc: 0.7860 - val_f1: 0.7672\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.2088 - acc: 0.6736 - auroc: 0.7611 - f1: 0.6649 - val_loss: 1.2166 - val_acc: 0.7250 - val_auroc: 0.7969 - val_f1: 0.7511\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1744 - acc: 0.7028 - auroc: 0.7726 - f1: 0.6926 - val_loss: 1.2366 - val_acc: 0.7375 - val_auroc: 0.7994 - val_f1: 0.7612\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1873 - acc: 0.6875 - auroc: 0.7717 - f1: 0.6747 - val_loss: 1.1181 - val_acc: 0.7188 - val_auroc: 0.8105 - val_f1: 0.7385\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 30s 21ms/step - loss: 1.0079 - acc: 0.6118 - auroc: 0.6740 - f1: 0.5951 - val_loss: 1.0437 - val_acc: 0.7375 - val_auroc: 0.8346 - val_f1: 0.7046\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1337 - acc: 0.6958 - auroc: 0.7597 - f1: 0.6773 - val_loss: 1.2119 - val_acc: 0.7562 - val_auroc: 0.8198 - val_f1: 0.7342\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.2026 - acc: 0.6944 - auroc: 0.7780 - f1: 0.6722 - val_loss: 1.2062 - val_acc: 0.7438 - val_auroc: 0.8229 - val_f1: 0.7198\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1945 - acc: 0.6944 - auroc: 0.7904 - f1: 0.6717 - val_loss: 1.1999 - val_acc: 0.7312 - val_auroc: 0.8342 - val_f1: 0.6596\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1812 - acc: 0.7083 - auroc: 0.7918 - f1: 0.6738 - val_loss: 1.1845 - val_acc: 0.6937 - val_auroc: 0.8112 - val_f1: 0.6437\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0924 - acc: 0.7097 - auroc: 0.7977 - f1: 0.6934 - val_loss: 1.1268 - val_acc: 0.7625 - val_auroc: 0.8380 - val_f1: 0.7664\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 30s 21ms/step - loss: 1.0677 - acc: 0.6382 - auroc: 0.6934 - f1: 0.6395 - val_loss: 1.1466 - val_acc: 0.6625 - val_auroc: 0.7811 - val_f1: 0.6303\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0919 - acc: 0.7174 - auroc: 0.8115 - f1: 0.7136 - val_loss: 1.1176 - val_acc: 0.7063 - val_auroc: 0.7801 - val_f1: 0.6530\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0498 - acc: 0.7444 - auroc: 0.8300 - f1: 0.7291 - val_loss: 1.1040 - val_acc: 0.7000 - val_auroc: 0.7768 - val_f1: 0.6712\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0588 - acc: 0.7458 - auroc: 0.8428 - f1: 0.7295 - val_loss: 1.1670 - val_acc: 0.6625 - val_auroc: 0.7922 - val_f1: 0.6014\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0901 - acc: 0.7389 - auroc: 0.8504 - f1: 0.7288 - val_loss: 1.1702 - val_acc: 0.7000 - val_auroc: 0.7812 - val_f1: 0.6283\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0414 - acc: 0.7576 - auroc: 0.8526 - f1: 0.7396 - val_loss: 1.1160 - val_acc: 0.7063 - val_auroc: 0.7647 - val_f1: 0.7058\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0490 - acc: 0.7604 - auroc: 0.8557 - f1: 0.7442 - val_loss: 1.1505 - val_acc: 0.6687 - val_auroc: 0.7897 - val_f1: 0.5742\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0629 - acc: 0.7757 - auroc: 0.8683 - f1: 0.7613 - val_loss: 1.1540 - val_acc: 0.6937 - val_auroc: 0.7790 - val_f1: 0.6353\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 30s 21ms/step - loss: 1.0409 - acc: 0.6271 - auroc: 0.7140 - f1: 0.6565 - val_loss: 1.1023 - val_acc: 0.7312 - val_auroc: 0.8460 - val_f1: 0.6781\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.2001 - acc: 0.6729 - auroc: 0.7440 - f1: 0.6679 - val_loss: 1.2043 - val_acc: 0.7188 - val_auroc: 0.8469 - val_f1: 0.6662\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.2487 - acc: 0.6771 - auroc: 0.7575 - f1: 0.6582 - val_loss: 1.2945 - val_acc: 0.7250 - val_auroc: 0.8436 - val_f1: 0.6752\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.2318 - acc: 0.6757 - auroc: 0.7622 - f1: 0.6730 - val_loss: 1.1882 - val_acc: 0.7438 - val_auroc: 0.8494 - val_f1: 0.7036\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.2252 - acc: 0.6785 - auroc: 0.7580 - f1: 0.6693 - val_loss: 1.2243 - val_acc: 0.7438 - val_auroc: 0.8274 - val_f1: 0.7250\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.2196 - acc: 0.6965 - auroc: 0.7799 - f1: 0.6917 - val_loss: 1.2761 - val_acc: 0.7625 - val_auroc: 0.8532 - val_f1: 0.7445\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 30s 21ms/step - loss: 1.0600 - acc: 0.6264 - auroc: 0.7025 - f1: 0.6105 - val_loss: 1.0939 - val_acc: 0.7000 - val_auroc: 0.8160 - val_f1: 0.7367\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1266 - acc: 0.7278 - auroc: 0.8268 - f1: 0.7229 - val_loss: 1.1922 - val_acc: 0.7500 - val_auroc: 0.8135 - val_f1: 0.7668\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0959 - acc: 0.7507 - auroc: 0.8373 - f1: 0.7431 - val_loss: 1.1345 - val_acc: 0.7688 - val_auroc: 0.8226 - val_f1: 0.7881\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1212 - acc: 0.7569 - auroc: 0.8623 - f1: 0.7521 - val_loss: 1.2801 - val_acc: 0.7063 - val_auroc: 0.8368 - val_f1: 0.7554\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1507 - acc: 0.7715 - auroc: 0.8583 - f1: 0.7612 - val_loss: 1.1166 - val_acc: 0.7625 - val_auroc: 0.8340 - val_f1: 0.7753\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0951 - acc: 0.7687 - auroc: 0.8737 - f1: 0.7568 - val_loss: 1.2410 - val_acc: 0.7500 - val_auroc: 0.8177 - val_f1: 0.7668\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 31s 21ms/step - loss: 1.0078 - acc: 0.5521 - auroc: 0.6301 - f1: 0.6727 - val_loss: 0.9826 - val_acc: 0.5938 - val_auroc: 0.7747 - val_f1: 0.6967\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.9577 - acc: 0.6333 - auroc: 0.7548 - f1: 0.6799 - val_loss: 0.9239 - val_acc: 0.7312 - val_auroc: 0.8147 - val_f1: 0.7124\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.8814 - acc: 0.6868 - auroc: 0.7744 - f1: 0.6933 - val_loss: 0.8782 - val_acc: 0.7438 - val_auroc: 0.8154 - val_f1: 0.7155\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.8625 - acc: 0.6972 - auroc: 0.7932 - f1: 0.7089 - val_loss: 0.8975 - val_acc: 0.7562 - val_auroc: 0.7821 - val_f1: 0.7360\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.8711 - acc: 0.7347 - auroc: 0.7944 - f1: 0.7239 - val_loss: 0.9399 - val_acc: 0.7375 - val_auroc: 0.7902 - val_f1: 0.7390\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.9652 - acc: 0.7146 - auroc: 0.7818 - f1: 0.6914 - val_loss: 0.9301 - val_acc: 0.7188 - val_auroc: 0.7748 - val_f1: 0.7132\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.8759 - acc: 0.7208 - auroc: 0.7822 - f1: 0.6870 - val_loss: 0.8960 - val_acc: 0.7188 - val_auroc: 0.7880 - val_f1: 0.6984\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 0.9024 - acc: 0.7396 - auroc: 0.7962 - f1: 0.7054 - val_loss: 0.9671 - val_acc: 0.7000 - val_auroc: 0.7753 - val_f1: 0.6838\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 30s 21ms/step - loss: 1.0371 - acc: 0.5764 - auroc: 0.6697 - f1: 0.6662 - val_loss: 1.0824 - val_acc: 0.6937 - val_auroc: 0.7739 - val_f1: 0.6933\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1279 - acc: 0.6813 - auroc: 0.7525 - f1: 0.6759 - val_loss: 1.0925 - val_acc: 0.7312 - val_auroc: 0.8193 - val_f1: 0.7512\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.1049 - acc: 0.7160 - auroc: 0.7983 - f1: 0.7135 - val_loss: 1.0923 - val_acc: 0.7312 - val_auroc: 0.8020 - val_f1: 0.7057\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0564 - acc: 0.7167 - auroc: 0.8022 - f1: 0.7066 - val_loss: 1.0861 - val_acc: 0.7000 - val_auroc: 0.8153 - val_f1: 0.6608\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0555 - acc: 0.7194 - auroc: 0.8044 - f1: 0.6922 - val_loss: 1.1122 - val_acc: 0.6875 - val_auroc: 0.7942 - val_f1: 0.7173\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 24s 17ms/step - loss: 1.0908 - acc: 0.7368 - auroc: 0.8260 - f1: 0.7209 - val_loss: 1.0960 - val_acc: 0.7125 - val_auroc: 0.8162 - val_f1: 0.7279\n"
     ]
    }
   ],
   "source": [
    "def evaluate_ffnn_model(train_X, train_y, test_X, test_y):\n",
    "    ffnn_model = get_ff_wv_model()\n",
    "    return ffnn_model.fit(train_X, train_y, epochs=25, batch_size=32, verbose=1, shuffle=False,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "                   validation_data=(test_X, test_y))\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=10, test_size=0.1)\n",
    "ff_wv_scores = run_cross_validate(evaluate_ffnn_model, bow_features, labels, splitter, cv=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'val_accuracy': 0.71875,\n",
       "   'val_auroc': 0.7936700483169452,\n",
       "   'val_f1': 0.6382959127426148,\n",
       "   'val_loss': 0.8887249827384949},\n",
       "  {'val_accuracy': 0.65,\n",
       "   'val_auroc': 0.6275774079244152,\n",
       "   'val_f1': 0.49876795411109925,\n",
       "   'val_loss': 0.9560416460037231},\n",
       "  {'val_accuracy': 0.7,\n",
       "   'val_auroc': 0.8567476988895654,\n",
       "   'val_f1': 0.6803570866584778,\n",
       "   'val_loss': 1.211377453804016},\n",
       "  {'val_accuracy': 0.60625,\n",
       "   'val_auroc': 0.6669282862851145,\n",
       "   'val_f1': 0.7080702066421509,\n",
       "   'val_loss': 0.9501791834831238},\n",
       "  {'val_accuracy': 0.7375,\n",
       "   'val_auroc': 0.6739759650358529,\n",
       "   'val_f1': 0.7046153306961059,\n",
       "   'val_loss': 1.0436803579330445},\n",
       "  {'val_accuracy': 0.7,\n",
       "   'val_auroc': 0.83001717099607,\n",
       "   'val_f1': 0.6711758196353912,\n",
       "   'val_loss': 1.1039915561676026},\n",
       "  {'val_accuracy': 0.73125,\n",
       "   'val_auroc': 0.7139770079523986,\n",
       "   'val_f1': 0.6781166434288025,\n",
       "   'val_loss': 1.1022765398025514},\n",
       "  {'val_accuracy': 0.7,\n",
       "   'val_auroc': 0.7024625967749485,\n",
       "   'val_f1': 0.7366747260093689,\n",
       "   'val_loss': 1.0939374685287475},\n",
       "  {'val_accuracy': 0.74375,\n",
       "   'val_auroc': 0.774422942148119,\n",
       "   'val_f1': 0.7155123591423035,\n",
       "   'val_loss': 0.8781776547431945},\n",
       "  {'val_accuracy': 0.69375,\n",
       "   'val_auroc': 0.6697021653097506,\n",
       "   'val_f1': 0.6932591676712037,\n",
       "   'val_loss': 1.082363247871399}],\n",
       " 0.698125)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_wv_bests = results(ff_wv_scores)\n",
    "ff_wv_bests, statistics.mean([x['val_accuracy'] for x in ff_wv_bests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_scores_entries =[('Bag of Words', x['val_accuracy']) for x in bests] + [('Word Vectors', x['val_accuracy']) for x in ff_wv_bests]\n",
    "ff_scores_data_frame = DataFrame(ff_scores_entries, columns=['input type', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(x='input type', y='accuracy', data=ff_scores_data_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like word vectors are doing better now! Although they should be more accurate than Bag of Words, unless this is an exceptional case. The next step here is to investigate how BoW and word vectors perform on more data, since a small amount of data is a case known to cause results like this. It is also very unlikely Bag of Words will perform as well on a large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research has shown that word embeddings perform better than Bag of Words (Convolutional Neural Networks for Sentence Classification, Yoon Kim 2014). We will use our convolutional network on pretrained Word2Vec embeddings to see if we obtain an improved accuracy. First we will obtain results for bag of words again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 1, 9839, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = 1600\n",
    "convolutional_data = np.array(np.split(np.array([[[y] for y in z] for z in bow_features]), batches))\n",
    "convolutional_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_bow_model():\n",
    "  model = Sequential([\n",
    "      Conv2D(\n",
    "          filters=50,\n",
    "          kernel_size=(1, 10),\n",
    "          data_format=\"channels_last\",\n",
    "          input_shape=(1, corpus_vocab_size, 1),\n",
    "          activation=relu),\n",
    "      MaxPooling2D(pool_size=(1, 10)),\n",
    "      Dropout(0.2),\n",
    "      Flatten(),\n",
    "      Dense(2, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_conv_model(train_X, train_y, test_X, test_y):\n",
    "    conv_model = get_conv_bow_model()\n",
    "    return conv_model.fit(train_X, train_y, epochs=25, batch_size=34, verbose=1, shuffle=False,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=6)],\n",
    "                   validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.7179 - acc: 0.5611 - auroc: 0.6229 - f1: 0.5611 - val_loss: 0.6476 - val_acc: 0.6313 - val_auroc: 0.7103 - val_f1: 0.6312\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4409 - acc: 0.8104 - auroc: 0.9065 - f1: 0.8104 - val_loss: 0.6162 - val_acc: 0.6813 - val_auroc: 0.7666 - val_f1: 0.6812\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3189 - acc: 0.8681 - auroc: 0.9514 - f1: 0.8681 - val_loss: 0.6425 - val_acc: 0.6563 - val_auroc: 0.7669 - val_f1: 0.6562\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2325 - acc: 0.9174 - auroc: 0.9775 - f1: 0.9174 - val_loss: 0.7159 - val_acc: 0.6562 - val_auroc: 0.7609 - val_f1: 0.6562\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1771 - acc: 0.9403 - auroc: 0.9899 - f1: 0.9403 - val_loss: 1.0124 - val_acc: 0.6750 - val_auroc: 0.7500 - val_f1: 0.6750\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2209 - acc: 0.9000 - auroc: 0.9894 - f1: 0.9000 - val_loss: 1.0901 - val_acc: 0.6937 - val_auroc: 0.7572 - val_f1: 0.6937\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3071 - acc: 0.8694 - auroc: 0.9848 - f1: 0.8694 - val_loss: 1.1144 - val_acc: 0.6750 - val_auroc: 0.7555 - val_f1: 0.6750\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1694 - acc: 0.9257 - auroc: 0.9923 - f1: 0.9257 - val_loss: 0.9672 - val_acc: 0.6562 - val_auroc: 0.7542 - val_f1: 0.6562\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.7098 - acc: 0.5813 - auroc: 0.6191 - f1: 0.5812 - val_loss: 0.6031 - val_acc: 0.6563 - val_auroc: 0.7279 - val_f1: 0.6562\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4259 - acc: 0.8278 - auroc: 0.9081 - f1: 0.8278 - val_loss: 0.6572 - val_acc: 0.6500 - val_auroc: 0.7178 - val_f1: 0.6500\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3170 - acc: 0.8750 - auroc: 0.9512 - f1: 0.8750 - val_loss: 0.7548 - val_acc: 0.6438 - val_auroc: 0.7226 - val_f1: 0.6437\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2352 - acc: 0.9208 - auroc: 0.9770 - f1: 0.9208 - val_loss: 0.9032 - val_acc: 0.6563 - val_auroc: 0.7321 - val_f1: 0.6562\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1864 - acc: 0.9354 - auroc: 0.9892 - f1: 0.9354 - val_loss: 1.0765 - val_acc: 0.6250 - val_auroc: 0.7214 - val_f1: 0.6250\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1992 - acc: 0.9187 - auroc: 0.9928 - f1: 0.9187 - val_loss: 0.9934 - val_acc: 0.6188 - val_auroc: 0.7188 - val_f1: 0.6187\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3093 - acc: 0.8701 - auroc: 0.9887 - f1: 0.8701 - val_loss: 1.1104 - val_acc: 0.5937 - val_auroc: 0.6998 - val_f1: 0.5937\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.6891 - acc: 0.6007 - auroc: 0.6385 - f1: 0.6007 - val_loss: 0.7345 - val_acc: 0.6125 - val_auroc: 0.6336 - val_f1: 0.6125\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4170 - acc: 0.8201 - auroc: 0.9054 - f1: 0.8201 - val_loss: 0.7657 - val_acc: 0.6250 - val_auroc: 0.6609 - val_f1: 0.6250\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3104 - acc: 0.8812 - auroc: 0.9543 - f1: 0.8812 - val_loss: 0.8400 - val_acc: 0.6313 - val_auroc: 0.6764 - val_f1: 0.6312\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2273 - acc: 0.9201 - auroc: 0.9815 - f1: 0.9201 - val_loss: 0.9440 - val_acc: 0.6063 - val_auroc: 0.6805 - val_f1: 0.6062\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1818 - acc: 0.9410 - auroc: 0.9915 - f1: 0.9410 - val_loss: 1.1083 - val_acc: 0.5875 - val_auroc: 0.6757 - val_f1: 0.5875\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2053 - acc: 0.9118 - auroc: 0.9927 - f1: 0.9118 - val_loss: 1.1675 - val_acc: 0.6000 - val_auroc: 0.6848 - val_f1: 0.6000\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3093 - acc: 0.8743 - auroc: 0.9856 - f1: 0.8743 - val_loss: 1.3397 - val_acc: 0.6375 - val_auroc: 0.6900 - val_f1: 0.6375\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.6981 - acc: 0.5903 - auroc: 0.6393 - f1: 0.5903 - val_loss: 0.6496 - val_acc: 0.6438 - val_auroc: 0.6944 - val_f1: 0.6437\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4582 - acc: 0.7736 - auroc: 0.9006 - f1: 0.7736 - val_loss: 0.7173 - val_acc: 0.6562 - val_auroc: 0.7012 - val_f1: 0.6562\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3243 - acc: 0.8750 - auroc: 0.9533 - f1: 0.8750 - val_loss: 0.7695 - val_acc: 0.6625 - val_auroc: 0.7031 - val_f1: 0.6625\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2336 - acc: 0.9181 - auroc: 0.9764 - f1: 0.9181 - val_loss: 0.8726 - val_acc: 0.6500 - val_auroc: 0.6844 - val_f1: 0.6500\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1754 - acc: 0.9479 - auroc: 0.9900 - f1: 0.9479 - val_loss: 1.0246 - val_acc: 0.6438 - val_auroc: 0.6881 - val_f1: 0.6437\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1542 - acc: 0.9493 - auroc: 0.9946 - f1: 0.9493 - val_loss: 1.2207 - val_acc: 0.6438 - val_auroc: 0.6886 - val_f1: 0.6437\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1887 - acc: 0.9285 - auroc: 0.9939 - f1: 0.9285 - val_loss: 1.8838 - val_acc: 0.6375 - val_auroc: 0.6646 - val_f1: 0.6375\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.6777 - acc: 0.6146 - auroc: 0.6496 - f1: 0.6146 - val_loss: 0.6581 - val_acc: 0.6438 - val_auroc: 0.7232 - val_f1: 0.6437\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4059 - acc: 0.8312 - auroc: 0.9227 - f1: 0.8312 - val_loss: 0.6499 - val_acc: 0.6563 - val_auroc: 0.7288 - val_f1: 0.6562\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3087 - acc: 0.8854 - auroc: 0.9594 - f1: 0.8854 - val_loss: 0.7044 - val_acc: 0.6813 - val_auroc: 0.7279 - val_f1: 0.6812\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2294 - acc: 0.9208 - auroc: 0.9825 - f1: 0.9208 - val_loss: 1.0141 - val_acc: 0.6125 - val_auroc: 0.7094 - val_f1: 0.6125\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1849 - acc: 0.9299 - auroc: 0.9919 - f1: 0.9299 - val_loss: 0.9862 - val_acc: 0.6250 - val_auroc: 0.7232 - val_f1: 0.6250\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2380 - acc: 0.8944 - auroc: 0.9897 - f1: 0.8944 - val_loss: 0.8388 - val_acc: 0.6875 - val_auroc: 0.7698 - val_f1: 0.6875\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1842 - acc: 0.9285 - auroc: 0.9924 - f1: 0.9285 - val_loss: 1.1520 - val_acc: 0.6500 - val_auroc: 0.7537 - val_f1: 0.6500\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1144 - acc: 0.9632 - auroc: 0.9969 - f1: 0.9632 - val_loss: 1.6490 - val_acc: 0.6125 - val_auroc: 0.7193 - val_f1: 0.6125\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.6976 - acc: 0.5819 - auroc: 0.6363 - f1: 0.5819 - val_loss: 0.7547 - val_acc: 0.5563 - val_auroc: 0.6471 - val_f1: 0.5562\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4265 - acc: 0.8174 - auroc: 0.9184 - f1: 0.8174 - val_loss: 0.8023 - val_acc: 0.5625 - val_auroc: 0.6770 - val_f1: 0.5625\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3221 - acc: 0.8708 - auroc: 0.9589 - f1: 0.8708 - val_loss: 0.7520 - val_acc: 0.6312 - val_auroc: 0.6970 - val_f1: 0.6312\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2400 - acc: 0.9118 - auroc: 0.9757 - f1: 0.9118 - val_loss: 0.8247 - val_acc: 0.6313 - val_auroc: 0.7068 - val_f1: 0.6312\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 2ms/step - loss: 0.2322 - acc: 0.8910 - auroc: 0.9856 - f1: 0.8910 - val_loss: 1.0652 - val_acc: 0.6188 - val_auroc: 0.7043 - val_f1: 0.6187\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2081 - acc: 0.9118 - auroc: 0.9912 - f1: 0.9118 - val_loss: 1.2072 - val_acc: 0.6125 - val_auroc: 0.6862 - val_f1: 0.6125\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1506 - acc: 0.9465 - auroc: 0.9928 - f1: 0.9465 - val_loss: 1.0376 - val_acc: 0.6250 - val_auroc: 0.7179 - val_f1: 0.6250\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1403 - acc: 0.9465 - auroc: 0.9969 - f1: 0.9465 - val_loss: 1.1844 - val_acc: 0.6250 - val_auroc: 0.7055 - val_f1: 0.6250\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1353 - acc: 0.9444 - auroc: 0.9981 - f1: 0.9444 - val_loss: 1.5639 - val_acc: 0.6063 - val_auroc: 0.7026 - val_f1: 0.6062\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.7071 - acc: 0.5611 - auroc: 0.6151 - f1: 0.5611 - val_loss: 0.5816 - val_acc: 0.6812 - val_auroc: 0.7400 - val_f1: 0.6812\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4414 - acc: 0.7958 - auroc: 0.8995 - f1: 0.7958 - val_loss: 0.5911 - val_acc: 0.7125 - val_auroc: 0.7366 - val_f1: 0.7125\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3440 - acc: 0.8569 - auroc: 0.9449 - f1: 0.8569 - val_loss: 0.6856 - val_acc: 0.6625 - val_auroc: 0.7499 - val_f1: 0.6625\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2696 - acc: 0.8951 - auroc: 0.9690 - f1: 0.8951 - val_loss: 0.8735 - val_acc: 0.6250 - val_auroc: 0.7641 - val_f1: 0.6250\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2529 - acc: 0.8882 - auroc: 0.9809 - f1: 0.8882 - val_loss: 0.8406 - val_acc: 0.6563 - val_auroc: 0.7614 - val_f1: 0.6562\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2809 - acc: 0.8729 - auroc: 0.9827 - f1: 0.8729 - val_loss: 0.9286 - val_acc: 0.6937 - val_auroc: 0.7341 - val_f1: 0.6937\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2118 - acc: 0.9111 - auroc: 0.9892 - f1: 0.9111 - val_loss: 0.6851 - val_acc: 0.7063 - val_auroc: 0.7828 - val_f1: 0.7062\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.7509 - acc: 0.5563 - auroc: 0.6212 - f1: 0.5562 - val_loss: 0.6924 - val_acc: 0.5875 - val_auroc: 0.6185 - val_f1: 0.5875\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4545 - acc: 0.7910 - auroc: 0.9029 - f1: 0.7910 - val_loss: 0.7496 - val_acc: 0.5938 - val_auroc: 0.6628 - val_f1: 0.5937\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3518 - acc: 0.8549 - auroc: 0.9427 - f1: 0.8549 - val_loss: 0.8078 - val_acc: 0.5750 - val_auroc: 0.6952 - val_f1: 0.5750\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2747 - acc: 0.8868 - auroc: 0.9695 - f1: 0.8868 - val_loss: 0.8305 - val_acc: 0.6125 - val_auroc: 0.7030 - val_f1: 0.6125\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2154 - acc: 0.9229 - auroc: 0.9834 - f1: 0.9229 - val_loss: 0.9609 - val_acc: 0.6250 - val_auroc: 0.7011 - val_f1: 0.6250\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 2ms/step - loss: 0.1831 - acc: 0.9306 - auroc: 0.9908 - f1: 0.9306 - val_loss: 1.3718 - val_acc: 0.5813 - val_auroc: 0.7028 - val_f1: 0.5812\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1767 - acc: 0.9292 - auroc: 0.9927 - f1: 0.9292 - val_loss: 0.9878 - val_acc: 0.6063 - val_auroc: 0.7110 - val_f1: 0.6062\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.7031 - acc: 0.5958 - auroc: 0.6548 - f1: 0.5958 - val_loss: 0.6944 - val_acc: 0.6250 - val_auroc: 0.6423 - val_f1: 0.6250\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4081 - acc: 0.8375 - auroc: 0.9198 - f1: 0.8375 - val_loss: 0.7235 - val_acc: 0.6125 - val_auroc: 0.6713 - val_f1: 0.6125\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3090 - acc: 0.8875 - auroc: 0.9618 - f1: 0.8875 - val_loss: 0.8188 - val_acc: 0.6375 - val_auroc: 0.6765 - val_f1: 0.6375\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2172 - acc: 0.9285 - auroc: 0.9848 - f1: 0.9285 - val_loss: 0.9430 - val_acc: 0.6375 - val_auroc: 0.6792 - val_f1: 0.6375\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1699 - acc: 0.9437 - auroc: 0.9918 - f1: 0.9437 - val_loss: 1.0776 - val_acc: 0.6438 - val_auroc: 0.6664 - val_f1: 0.6437\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1409 - acc: 0.9611 - auroc: 0.9951 - f1: 0.9611 - val_loss: 1.2565 - val_acc: 0.6250 - val_auroc: 0.6603 - val_f1: 0.6250\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1384 - acc: 0.9472 - auroc: 0.9953 - f1: 0.9472 - val_loss: 1.6977 - val_acc: 0.5563 - val_auroc: 0.6754 - val_f1: 0.5562\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.6894 - acc: 0.5861 - auroc: 0.6310 - f1: 0.5861 - val_loss: 0.6669 - val_acc: 0.6063 - val_auroc: 0.6680 - val_f1: 0.6062\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.4302 - acc: 0.8076 - auroc: 0.9111 - f1: 0.8076 - val_loss: 0.6452 - val_acc: 0.6188 - val_auroc: 0.7253 - val_f1: 0.6187\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.3228 - acc: 0.8667 - auroc: 0.9557 - f1: 0.8667 - val_loss: 0.7754 - val_acc: 0.6625 - val_auroc: 0.7449 - val_f1: 0.6625\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2593 - acc: 0.8937 - auroc: 0.9774 - f1: 0.8937 - val_loss: 0.8173 - val_acc: 0.6250 - val_auroc: 0.7194 - val_f1: 0.6250\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.2039 - acc: 0.9160 - auroc: 0.9876 - f1: 0.9160 - val_loss: 1.1387 - val_acc: 0.5750 - val_auroc: 0.6708 - val_f1: 0.5750\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1783 - acc: 0.9271 - auroc: 0.9942 - f1: 0.9271 - val_loss: 1.0221 - val_acc: 0.6062 - val_auroc: 0.7045 - val_f1: 0.6062\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1413 - acc: 0.9451 - auroc: 0.9956 - f1: 0.9451 - val_loss: 1.0683 - val_acc: 0.6375 - val_auroc: 0.7117 - val_f1: 0.6375\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 4s 3ms/step - loss: 0.1065 - acc: 0.9632 - auroc: 0.9989 - f1: 0.9632 - val_loss: 1.2900 - val_acc: 0.6063 - val_auroc: 0.6954 - val_f1: 0.6062\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=10, test_size=0.1)\n",
    "conv_bow_scores = run_cross_validate(evaluate_conv_model, convolutional_data, labels, splitter, cv=10, categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'val_accuracy': 0.6812500104308128,\n",
       "   'val_auroc': 0.9065476436334551,\n",
       "   'val_f1': 0.681249950826168,\n",
       "   'val_loss': 0.616241792589426},\n",
       "  {'val_accuracy': 0.6562500067055226,\n",
       "   'val_auroc': 0.619058912856078,\n",
       "   'val_f1': 0.6562499471008778,\n",
       "   'val_loss': 0.6031138226389885},\n",
       "  {'val_accuracy': 0.6125000156462193,\n",
       "   'val_auroc': 0.6385484442248793,\n",
       "   'val_f1': 0.6124999560415745,\n",
       "   'val_loss': 0.7345238126814365},\n",
       "  {'val_accuracy': 0.6437500201165676,\n",
       "   'val_auroc': 0.6392952605865928,\n",
       "   'val_f1': 0.6437499605119228,\n",
       "   'val_loss': 0.6495866138488054},\n",
       "  {'val_accuracy': 0.6562500067055226,\n",
       "   'val_auroc': 0.9226500976210343,\n",
       "   'val_f1': 0.6562499471008778,\n",
       "   'val_loss': 0.6499350242316723},\n",
       "  {'val_accuracy': 0.6312499962747097,\n",
       "   'val_auroc': 0.9589272395805188,\n",
       "   'val_f1': 0.6312499366700649,\n",
       "   'val_loss': 0.7519850976765156},\n",
       "  {'val_accuracy': 0.6812499903142453,\n",
       "   'val_auroc': 0.6151408407339134,\n",
       "   'val_f1': 0.6812499351799488,\n",
       "   'val_loss': 0.5816270515322686},\n",
       "  {'val_accuracy': 0.5875000171363354,\n",
       "   'val_auroc': 0.6212389944471018,\n",
       "   'val_f1': 0.5874999575316906,\n",
       "   'val_loss': 0.6923500038683414},\n",
       "  {'val_accuracy': 0.625000012665987,\n",
       "   'val_auroc': 0.6548067166255923,\n",
       "   'val_f1': 0.6249999530613423,\n",
       "   'val_loss': 0.6944297038018703},\n",
       "  {'val_accuracy': 0.6187500096857548,\n",
       "   'val_auroc': 0.9111347852279853,\n",
       "   'val_f1': 0.61874995008111,\n",
       "   'val_loss': 0.6451635524630547}],\n",
       " 0.6393750085681676)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_bow_bests = results(conv_bow_scores)\n",
    "conv_bow_bests, statistics.mean([x['val_accuracy'] for x in conv_bow_bests])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter out reviews with more than 300 words because a small number have an exceptionally large number of words and dramatically increase the memory requirements. These reviews are rare and are not expected to provide much value, while also preventing this experiment from being run on a normal machine, so I will filter them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_words = []\n",
    "conv_wv_labels = []\n",
    "for i, raw_feature in enumerate(raw_features):\n",
    "    word_sequence = text_to_word_sequence(raw_feature)\n",
    "    if len(word_sequence) > 320:\n",
    "        continue\n",
    "    conv_wv_labels.append(labels[i])\n",
    "    reviews_words.append(word_sequence)\n",
    "max_review_len = max([len(x) for x in reviews_words])\n",
    "\n",
    "vectorized_reviews = np.zeros((len(reviews_words), max_review_len, 300, 1))\n",
    "for i, review in enumerate(reviews_words):\n",
    "    for j, word in enumerate(review):\n",
    "        vectorized_reviews[i][j] = [[x] for x in embedding_matrix[corpus_words[word]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_conv_wv_model():\n",
    "  model = Sequential([\n",
    "      Conv2D(\n",
    "          filters=50,\n",
    "          kernel_size=(10, 300),\n",
    "          data_format=\"channels_last\",\n",
    "          input_shape=(320, 300, 1),\n",
    "          activation=relu),\n",
    "      MaxPooling2D(strides=(1, 1), pool_size=(2, 1), data_format=\"channels_last\"),\n",
    "      Dropout(0.2),\n",
    "      Flatten(),\n",
    "      Dense(2, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_conv_wv_model(train_X, train_y, test_X, test_y):\n",
    "    conv_model = get_conv_wv_model()\n",
    "    return conv_model.fit(train_X, train_y, epochs=25, batch_size=34, verbose=1, shuffle=False,\n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=6)],\n",
    "                   validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 9s 6ms/step - loss: 0.6636 - acc: 0.5988 - auroc: 0.6715 - f1: 0.5988 - val_loss: 0.6126 - val_acc: 0.6928 - val_auroc: 0.7107 - val_f1: 0.6928\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.4742 - acc: 0.7812 - auroc: 0.8929 - f1: 0.7812 - val_loss: 0.5657 - val_acc: 0.7320 - val_auroc: 0.7703 - val_f1: 0.7320\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.3143 - acc: 0.8738 - auroc: 0.9602 - f1: 0.8738 - val_loss: 0.5415 - val_acc: 0.7059 - val_auroc: 0.7801 - val_f1: 0.7059\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2090 - acc: 0.9220 - auroc: 0.9916 - f1: 0.9220 - val_loss: 0.6968 - val_acc: 0.6863 - val_auroc: 0.7865 - val_f1: 0.6863\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1539 - acc: 0.9489 - auroc: 0.9984 - f1: 0.9489 - val_loss: 0.5729 - val_acc: 0.7320 - val_auroc: 0.7818 - val_f1: 0.7320\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1326 - acc: 0.9533 - auroc: 0.9997 - f1: 0.9533 - val_loss: 1.1961 - val_acc: 0.6340 - val_auroc: 0.7815 - val_f1: 0.6340\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1103 - acc: 0.9708 - auroc: 0.9995 - f1: 0.9708 - val_loss: 0.7779 - val_acc: 0.7124 - val_auroc: 0.7740 - val_f1: 0.7124\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0472 - acc: 0.9934 - auroc: 1.0000 - f1: 0.9934 - val_loss: 0.7352 - val_acc: 0.6797 - val_auroc: 0.7475 - val_f1: 0.6797\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0155 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.7747 - val_acc: 0.6601 - val_auroc: 0.7419 - val_f1: 0.6601\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 9s 6ms/step - loss: 0.6517 - acc: 0.6120 - auroc: 0.7117 - f1: 0.6120 - val_loss: 0.5434 - val_acc: 0.7451 - val_auroc: 0.8284 - val_f1: 0.7451\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.4426 - acc: 0.8001 - auroc: 0.9042 - f1: 0.8001 - val_loss: 0.4082 - val_acc: 0.8039 - val_auroc: 0.9078 - val_f1: 0.8039\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2908 - acc: 0.8789 - auroc: 0.9681 - f1: 0.8789 - val_loss: 0.3935 - val_acc: 0.8170 - val_auroc: 0.9062 - val_f1: 0.8170\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2074 - acc: 0.9241 - auroc: 0.9949 - f1: 0.9241 - val_loss: 0.7010 - val_acc: 0.7059 - val_auroc: 0.8906 - val_f1: 0.7059\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1757 - acc: 0.9336 - auroc: 0.9996 - f1: 0.9336 - val_loss: 0.4456 - val_acc: 0.8235 - val_auroc: 0.8975 - val_f1: 0.8235\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0992 - acc: 0.9752 - auroc: 0.9998 - f1: 0.9752 - val_loss: 0.4307 - val_acc: 0.8105 - val_auroc: 0.8976 - val_f1: 0.8105\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.0296 - acc: 0.9985 - auroc: 1.0000 - f1: 0.9985 - val_loss: 0.4542 - val_acc: 0.8039 - val_auroc: 0.9022 - val_f1: 0.8039\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0161 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.5216 - val_acc: 0.8170 - val_auroc: 0.9069 - val_f1: 0.8170\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0123 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4799 - val_acc: 0.8170 - val_auroc: 0.9123 - val_f1: 0.8170\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 9s 6ms/step - loss: 0.6408 - acc: 0.6309 - auroc: 0.7130 - f1: 0.6309 - val_loss: 0.5205 - val_acc: 0.7320 - val_auroc: 0.8318 - val_f1: 0.7320\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.4010 - acc: 0.8249 - auroc: 0.9278 - f1: 0.8249 - val_loss: 0.4121 - val_acc: 0.7778 - val_auroc: 0.9036 - val_f1: 0.7778\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2541 - acc: 0.8993 - auroc: 0.9853 - f1: 0.8993 - val_loss: 0.3812 - val_acc: 0.8039 - val_auroc: 0.9081 - val_f1: 0.8039\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2047 - acc: 0.9307 - auroc: 0.9950 - f1: 0.9307 - val_loss: 1.2716 - val_acc: 0.5948 - val_auroc: 0.8944 - val_f1: 0.5948\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.2973 - acc: 0.8724 - auroc: 0.9952 - f1: 0.8724 - val_loss: 0.4545 - val_acc: 0.7712 - val_auroc: 0.8645 - val_f1: 0.7712\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.1062 - acc: 0.9701 - auroc: 0.9996 - f1: 0.9701 - val_loss: 0.4582 - val_acc: 0.7582 - val_auroc: 0.8679 - val_f1: 0.7582\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0304 - acc: 0.9978 - auroc: 1.0000 - f1: 0.9978 - val_loss: 0.4693 - val_acc: 0.7516 - val_auroc: 0.8680 - val_f1: 0.7516\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0159 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4744 - val_acc: 0.7843 - val_auroc: 0.8829 - val_f1: 0.7843\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 4s 3ms/step - loss: 0.0113 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4706 - val_acc: 0.7778 - val_auroc: 0.8854 - val_f1: 0.7778\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 9s 7ms/step - loss: 0.6724 - acc: 0.5638 - auroc: 0.6894 - f1: 0.5638 - val_loss: 0.6002 - val_acc: 0.6863 - val_auroc: 0.7781 - val_f1: 0.6863\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.4910 - acc: 0.7659 - auroc: 0.8799 - f1: 0.7659 - val_loss: 0.4810 - val_acc: 0.7647 - val_auroc: 0.8856 - val_f1: 0.7647\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.3179 - acc: 0.8745 - auroc: 0.9579 - f1: 0.8745 - val_loss: 0.4571 - val_acc: 0.7908 - val_auroc: 0.9119 - val_f1: 0.7908\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.1917 - acc: 0.9446 - auroc: 0.9935 - f1: 0.9446 - val_loss: 0.3880 - val_acc: 0.8235 - val_auroc: 0.9044 - val_f1: 0.8235\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.1676 - acc: 0.9460 - auroc: 0.9982 - f1: 0.9460 - val_loss: 1.1282 - val_acc: 0.5882 - val_auroc: 0.8805 - val_f1: 0.5882\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.2252 - acc: 0.9256 - auroc: 0.9976 - f1: 0.9256 - val_loss: 0.5109 - val_acc: 0.7778 - val_auroc: 0.8950 - val_f1: 0.7778\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0582 - acc: 0.9912 - auroc: 0.9999 - f1: 0.9912 - val_loss: 0.4002 - val_acc: 0.8431 - val_auroc: 0.9088 - val_f1: 0.8431\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0202 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4226 - val_acc: 0.8497 - val_auroc: 0.9073 - val_f1: 0.8497\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0141 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.4137 - val_acc: 0.8562 - val_auroc: 0.9073 - val_f1: 0.8562\n",
      "Epoch 10/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0084 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4259 - val_acc: 0.8366 - val_auroc: 0.9104 - val_f1: 0.8366\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 9s 7ms/step - loss: 0.6608 - acc: 0.6112 - auroc: 0.7057 - f1: 0.6112 - val_loss: 0.5541 - val_acc: 0.7451 - val_auroc: 0.8382 - val_f1: 0.7451\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.4695 - acc: 0.7885 - auroc: 0.8781 - f1: 0.7885 - val_loss: 0.4724 - val_acc: 0.7712 - val_auroc: 0.8844 - val_f1: 0.7712\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.3158 - acc: 0.8716 - auroc: 0.9542 - f1: 0.8716 - val_loss: 0.4986 - val_acc: 0.8039 - val_auroc: 0.9161 - val_f1: 0.8039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.1989 - acc: 0.9351 - auroc: 0.9916 - f1: 0.9351 - val_loss: 0.4229 - val_acc: 0.8039 - val_auroc: 0.9024 - val_f1: 0.8039\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.1357 - acc: 0.9562 - auroc: 0.9991 - f1: 0.9562 - val_loss: 0.5837 - val_acc: 0.7974 - val_auroc: 0.8951 - val_f1: 0.7974\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.1780 - acc: 0.9234 - auroc: 0.9992 - f1: 0.9234 - val_loss: 0.5963 - val_acc: 0.7843 - val_auroc: 0.8524 - val_f1: 0.7843\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.1166 - acc: 0.9716 - auroc: 0.9989 - f1: 0.9716 - val_loss: 0.5021 - val_acc: 0.7712 - val_auroc: 0.8763 - val_f1: 0.7712\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0325 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.6919 - val_acc: 0.7255 - val_auroc: 0.8726 - val_f1: 0.7255\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0329 - acc: 0.9971 - auroc: 1.0000 - f1: 0.9971 - val_loss: 0.5539 - val_acc: 0.7712 - val_auroc: 0.8774 - val_f1: 0.7712\n",
      "Epoch 10/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0164 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.5189 - val_acc: 0.7908 - val_auroc: 0.8773 - val_f1: 0.7908\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 9s 7ms/step - loss: 0.6544 - acc: 0.6112 - auroc: 0.7179 - f1: 0.6112 - val_loss: 0.5347 - val_acc: 0.7320 - val_auroc: 0.8308 - val_f1: 0.7320\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.4399 - acc: 0.8089 - auroc: 0.9160 - f1: 0.8089 - val_loss: 0.4906 - val_acc: 0.7386 - val_auroc: 0.8586 - val_f1: 0.7386\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.2849 - acc: 0.8942 - auroc: 0.9762 - f1: 0.8942 - val_loss: 0.5155 - val_acc: 0.7386 - val_auroc: 0.8602 - val_f1: 0.7386\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.1734 - acc: 0.9570 - auroc: 0.9961 - f1: 0.9570 - val_loss: 0.5220 - val_acc: 0.7778 - val_auroc: 0.8843 - val_f1: 0.7778\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.1337 - acc: 0.9628 - auroc: 0.9996 - f1: 0.9628 - val_loss: 0.5430 - val_acc: 0.7974 - val_auroc: 0.8727 - val_f1: 0.7974\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.1155 - acc: 0.9664 - auroc: 1.0000 - f1: 0.9664 - val_loss: 0.5209 - val_acc: 0.7974 - val_auroc: 0.8511 - val_f1: 0.7974\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0445 - acc: 0.9927 - auroc: 0.9997 - f1: 0.9927 - val_loss: 0.5548 - val_acc: 0.7974 - val_auroc: 0.8558 - val_f1: 0.7974\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0133 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.6078 - val_acc: 0.7516 - val_auroc: 0.8504 - val_f1: 0.7516\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 9s 7ms/step - loss: 0.6805 - acc: 0.5390 - auroc: 0.6342 - f1: 0.5390 - val_loss: 0.5867 - val_acc: 0.6928 - val_auroc: 0.8065 - val_f1: 0.6928\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.5031 - acc: 0.7688 - auroc: 0.8790 - f1: 0.7688 - val_loss: 0.4359 - val_acc: 0.8039 - val_auroc: 0.8735 - val_f1: 0.8039\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.3109 - acc: 0.8724 - auroc: 0.9646 - f1: 0.8724 - val_loss: 0.4035 - val_acc: 0.8105 - val_auroc: 0.8954 - val_f1: 0.8105\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.2038 - acc: 0.9190 - auroc: 0.9926 - f1: 0.9190 - val_loss: 0.4699 - val_acc: 0.7647 - val_auroc: 0.8965 - val_f1: 0.7647\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.2210 - acc: 0.9168 - auroc: 0.9990 - f1: 0.9168 - val_loss: 0.4375 - val_acc: 0.7712 - val_auroc: 0.8770 - val_f1: 0.7712\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.1347 - acc: 0.9592 - auroc: 0.9990 - f1: 0.9592 - val_loss: 0.7092 - val_acc: 0.7124 - val_auroc: 0.8697 - val_f1: 0.7124\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0565 - acc: 0.9912 - auroc: 0.9998 - f1: 0.9912 - val_loss: 0.4098 - val_acc: 0.7974 - val_auroc: 0.8936 - val_f1: 0.7974\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0300 - acc: 0.9985 - auroc: 1.0000 - f1: 0.9985 - val_loss: 0.4874 - val_acc: 0.7908 - val_auroc: 0.8927 - val_f1: 0.7908\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0252 - acc: 0.9985 - auroc: 1.0000 - f1: 0.9985 - val_loss: 0.4485 - val_acc: 0.7843 - val_auroc: 0.8810 - val_f1: 0.7843\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 10s 7ms/step - loss: 0.6532 - acc: 0.5799 - auroc: 0.6988 - f1: 0.5799 - val_loss: 0.5762 - val_acc: 0.6732 - val_auroc: 0.8311 - val_f1: 0.6732\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.4314 - acc: 0.8053 - auroc: 0.9103 - f1: 0.8053 - val_loss: 0.4292 - val_acc: 0.8235 - val_auroc: 0.9035 - val_f1: 0.8235\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.3091 - acc: 0.8680 - auroc: 0.9763 - f1: 0.8680 - val_loss: 0.3879 - val_acc: 0.8627 - val_auroc: 0.9212 - val_f1: 0.8627\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.2064 - acc: 0.9263 - auroc: 0.9942 - f1: 0.9263 - val_loss: 0.4469 - val_acc: 0.8105 - val_auroc: 0.9058 - val_f1: 0.8105\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0901 - acc: 0.9898 - auroc: 0.9983 - f1: 0.9898 - val_loss: 0.3774 - val_acc: 0.8627 - val_auroc: 0.9110 - val_f1: 0.8627\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.0391 - acc: 0.9978 - auroc: 0.9999 - f1: 0.9978 - val_loss: 0.4996 - val_acc: 0.8235 - val_auroc: 0.9084 - val_f1: 0.8235\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0213 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.4763 - val_acc: 0.8366 - val_auroc: 0.8988 - val_f1: 0.8366\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.0134 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4519 - val_acc: 0.8497 - val_auroc: 0.8996 - val_f1: 0.8497\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0082 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4701 - val_acc: 0.8301 - val_auroc: 0.8956 - val_f1: 0.8301\n",
      "Epoch 10/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0058 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4782 - val_acc: 0.8105 - val_auroc: 0.8973 - val_f1: 0.8105\n",
      "Epoch 11/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.0046 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4877 - val_acc: 0.8105 - val_auroc: 0.8981 - val_f1: 0.8105\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 10s 7ms/step - loss: 0.6663 - acc: 0.5784 - auroc: 0.6854 - f1: 0.5784 - val_loss: 0.6042 - val_acc: 0.6536 - val_auroc: 0.8219 - val_f1: 0.6536\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.4646 - acc: 0.7856 - auroc: 0.8949 - f1: 0.7856 - val_loss: 0.6225 - val_acc: 0.6928 - val_auroc: 0.8997 - val_f1: 0.6928\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.2863 - acc: 0.8942 - auroc: 0.9707 - f1: 0.8942 - val_loss: 0.6692 - val_acc: 0.6928 - val_auroc: 0.9084 - val_f1: 0.6928\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.1858 - acc: 0.9373 - auroc: 0.9929 - f1: 0.9373 - val_loss: 0.4366 - val_acc: 0.8039 - val_auroc: 0.8933 - val_f1: 0.8039\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.1675 - acc: 0.9336 - auroc: 0.9985 - f1: 0.9336 - val_loss: 0.5002 - val_acc: 0.8039 - val_auroc: 0.8782 - val_f1: 0.8039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0936 - acc: 0.9818 - auroc: 0.9997 - f1: 0.9818 - val_loss: 0.4960 - val_acc: 0.7843 - val_auroc: 0.8692 - val_f1: 0.7843\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0325 - acc: 0.9985 - auroc: 1.0000 - f1: 0.9985 - val_loss: 0.4929 - val_acc: 0.7974 - val_auroc: 0.8904 - val_f1: 0.7974\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.0199 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.5187 - val_acc: 0.7712 - val_auroc: 0.8866 - val_f1: 0.7712\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0130 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.5252 - val_acc: 0.7974 - val_auroc: 0.9017 - val_f1: 0.7974\n",
      "Epoch 10/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0078 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.5980 - val_acc: 0.7843 - val_auroc: 0.8992 - val_f1: 0.7843\n",
      "Train on 1371 samples, validate on 153 samples\n",
      "Epoch 1/25\n",
      "1371/1371 [==============================] - 9s 7ms/step - loss: 0.6731 - acc: 0.5740 - auroc: 0.6663 - f1: 0.5740 - val_loss: 0.5918 - val_acc: 0.7320 - val_auroc: 0.8022 - val_f1: 0.7320\n",
      "Epoch 2/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.4723 - acc: 0.7805 - auroc: 0.8812 - f1: 0.7805 - val_loss: 0.4428 - val_acc: 0.7908 - val_auroc: 0.8784 - val_f1: 0.7908\n",
      "Epoch 3/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.2708 - acc: 0.9074 - auroc: 0.9687 - f1: 0.9074 - val_loss: 0.3864 - val_acc: 0.7908 - val_auroc: 0.9133 - val_f1: 0.7908\n",
      "Epoch 4/25\n",
      "1371/1371 [==============================] - 3s 3ms/step - loss: 0.1425 - acc: 0.9643 - auroc: 0.9969 - f1: 0.9643 - val_loss: 0.4222 - val_acc: 0.7778 - val_auroc: 0.9133 - val_f1: 0.7778\n",
      "Epoch 5/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.1620 - acc: 0.9402 - auroc: 0.9996 - f1: 0.9402 - val_loss: 0.4670 - val_acc: 0.7582 - val_auroc: 0.8789 - val_f1: 0.7582\n",
      "Epoch 6/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0944 - acc: 0.9759 - auroc: 1.0000 - f1: 0.9759 - val_loss: 0.4451 - val_acc: 0.8235 - val_auroc: 0.9013 - val_f1: 0.8235\n",
      "Epoch 7/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0338 - acc: 0.9971 - auroc: 1.0000 - f1: 0.9971 - val_loss: 0.4718 - val_acc: 0.7712 - val_auroc: 0.8926 - val_f1: 0.7712\n",
      "Epoch 8/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0150 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4780 - val_acc: 0.8039 - val_auroc: 0.8926 - val_f1: 0.8039\n",
      "Epoch 9/25\n",
      "1371/1371 [==============================] - 3s 2ms/step - loss: 0.0094 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.5059 - val_acc: 0.7843 - val_auroc: 0.8926 - val_f1: 0.7843\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=10, test_size=0.1)\n",
    "conv_wv_scores = run_cross_validate(evaluate_conv_wv_model, vectorized_reviews, conv_wv_labels, splitter, cv=10, categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'val_accuracy': 0.7058823506037394,\n",
       "   'val_auroc': 0.9601902103061325,\n",
       "   'val_f1': 0.7058822909990946,\n",
       "   'val_loss': 0.541508310370975},\n",
       "  {'val_accuracy': 0.8169934617148505,\n",
       "   'val_auroc': 0.968131444477296,\n",
       "   'val_f1': 0.8169934021102058,\n",
       "   'val_loss': 0.3934679494963752},\n",
       "  {'val_accuracy': 0.8039215736918979,\n",
       "   'val_auroc': 0.9852851516752751,\n",
       "   'val_f1': 0.8039215140872531,\n",
       "   'val_loss': 0.3812228772375319},\n",
       "  {'val_accuracy': 0.8235294156604342,\n",
       "   'val_auroc': 0.9935402395406223,\n",
       "   'val_f1': 0.8235293560557895,\n",
       "   'val_loss': 0.3879835108915965},\n",
       "  {'val_accuracy': 0.8039215803146362,\n",
       "   'val_auroc': 0.9916042444946963,\n",
       "   'val_f1': 0.8039215207099915,\n",
       "   'val_loss': 0.42290018333329094},\n",
       "  {'val_accuracy': 0.7385621070861816,\n",
       "   'val_auroc': 0.9159913336931205,\n",
       "   'val_f1': 0.7385620474815369,\n",
       "   'val_loss': 0.4906387991375393},\n",
       "  {'val_accuracy': 0.8104575210147433,\n",
       "   'val_auroc': 0.9645749473307322,\n",
       "   'val_f1': 0.8104574680328369,\n",
       "   'val_loss': 0.40353768070538837},\n",
       "  {'val_accuracy': 0.8627450863520304,\n",
       "   'val_auroc': 0.9982728977805564,\n",
       "   'val_f1': 0.8627450399928622,\n",
       "   'val_loss': 0.3773556384775374},\n",
       "  {'val_accuracy': 0.8039215604464213,\n",
       "   'val_auroc': 0.992869032134771,\n",
       "   'val_f1': 0.8039215008417765,\n",
       "   'val_loss': 0.4366307705640793},\n",
       "  {'val_accuracy': 0.7908496724234687,\n",
       "   'val_auroc': 0.9687108128152235,\n",
       "   'val_f1': 0.7908496128188239,\n",
       "   'val_loss': 0.38644993636343217}],\n",
       " 0.7960784329308404)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_wv_bests = results(conv_wv_scores)\n",
    "conv_wv_bests, statistics.mean([x['val_accuracy'] for x in conv_wv_bests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_scores_entries =[('Bag of Words', x['val_accuracy']) for x in conv_bow_bests] + [('Word Vectors', x['val_accuracy']) for x in conv_wv_bests]\n",
    "conv_scores_data_frame = DataFrame(conv_scores_entries, columns=['input type', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(x='input type', y='accuracy', data=conv_scores_data_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again our results look better. If this continues to be consistent we know that Word2Vec has some property that is beneficial, which may be training on more data, or it may be the higher vector dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final experiment we will run to test the results of using pretrained Word2Vec embeddings will be our LSTM network. \n",
    "In the previous test we did with word embeddings, our accuracy was 50%, so simply a random guess. Following the trend above of pretrained embeddings giving us better accuracies, we will run a test and see if this can give any improvements for the LSTM network.\n",
    "\n",
    "First, let's get our BOW accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 1600\n",
    "padded = pad_sequences(bow_features)\n",
    "rnn_bow = np.array(np.split(padded, batches))\n",
    "max_len_bow = max([len(x) for x in padded])\n",
    "rnn_bow_targets = np.array([[x] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_bow_model():\n",
    "  model = Sequential([\n",
    "      LSTM(20, input_shape=(1, max_len_bow)),\n",
    "      Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_model(train_X, train_y, test_X, test_y):\n",
    "    lstm_model = get_rnn_bow_model()\n",
    "    return lstm_model.fit(train_X, train_y, epochs=25, batch_size=32, verbose=1, shuffle=False,\n",
    "                          callbacks=[EarlyStopping(monitor='val_loss', patience=6)], validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.5324 - acc: 0.7757 - auroc: 0.8500 - f1: 0.7735 - val_loss: 0.3632 - val_acc: 0.8688 - val_auroc: 0.9383 - val_f1: 0.8669\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.1040 - acc: 0.9826 - auroc: 0.9985 - f1: 0.9820 - val_loss: 0.3090 - val_acc: 0.8812 - val_auroc: 0.9407 - val_f1: 0.8765\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 268us/step - loss: 0.0364 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9994 - val_loss: 0.2971 - val_acc: 0.8562 - val_auroc: 0.9431 - val_f1: 0.8621\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 268us/step - loss: 0.0191 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3008 - val_acc: 0.8562 - val_auroc: 0.9455 - val_f1: 0.8621\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 266us/step - loss: 0.0118 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3035 - val_acc: 0.8875 - val_auroc: 0.9447 - val_f1: 0.8850\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 270us/step - loss: 0.0080 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3084 - val_acc: 0.8812 - val_auroc: 0.9439 - val_f1: 0.8794\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 270us/step - loss: 0.0059 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3133 - val_acc: 0.8812 - val_auroc: 0.9423 - val_f1: 0.8794\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 265us/step - loss: 0.0046 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3181 - val_acc: 0.8812 - val_auroc: 0.9431 - val_f1: 0.8794\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 0s 265us/step - loss: 0.0037 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3228 - val_acc: 0.8812 - val_auroc: 0.9447 - val_f1: 0.8794\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.5442 - acc: 0.7604 - auroc: 0.8453 - f1: 0.7503 - val_loss: 0.4096 - val_acc: 0.8500 - val_auroc: 0.9176 - val_f1: 0.8509\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 276us/step - loss: 0.1253 - acc: 0.9771 - auroc: 0.9976 - f1: 0.9737 - val_loss: 0.3381 - val_acc: 0.8875 - val_auroc: 0.9310 - val_f1: 0.8840\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.0458 - acc: 0.9979 - auroc: 1.0000 - f1: 0.9973 - val_loss: 0.3411 - val_acc: 0.8812 - val_auroc: 0.9308 - val_f1: 0.8813\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 265us/step - loss: 0.0242 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9990 - val_loss: 0.3521 - val_acc: 0.8875 - val_auroc: 0.9252 - val_f1: 0.8863\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 265us/step - loss: 0.0151 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3627 - val_acc: 0.8750 - val_auroc: 0.9252 - val_f1: 0.8735\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.0105 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3724 - val_acc: 0.8812 - val_auroc: 0.9236 - val_f1: 0.8789\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.0078 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3815 - val_acc: 0.8750 - val_auroc: 0.9228 - val_f1: 0.8731\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 265us/step - loss: 0.0061 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3897 - val_acc: 0.8750 - val_auroc: 0.9220 - val_f1: 0.8731\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.5309 - acc: 0.7785 - auroc: 0.8508 - f1: 0.7753 - val_loss: 0.3579 - val_acc: 0.8625 - val_auroc: 0.9326 - val_f1: 0.8684\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 286us/step - loss: 0.1141 - acc: 0.9778 - auroc: 0.9975 - f1: 0.9782 - val_loss: 0.2759 - val_acc: 0.8625 - val_auroc: 0.9523 - val_f1: 0.8653\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 276us/step - loss: 0.0409 - acc: 0.9958 - auroc: 1.0000 - f1: 0.9962 - val_loss: 0.2629 - val_acc: 0.8625 - val_auroc: 0.9554 - val_f1: 0.8601\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 0.0215 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9995 - val_loss: 0.2661 - val_acc: 0.8562 - val_auroc: 0.9522 - val_f1: 0.8577\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.0132 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2731 - val_acc: 0.8500 - val_auroc: 0.9483 - val_f1: 0.8530\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 274us/step - loss: 0.0091 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2775 - val_acc: 0.8500 - val_auroc: 0.9499 - val_f1: 0.8530\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.0067 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2822 - val_acc: 0.8500 - val_auroc: 0.9491 - val_f1: 0.8530\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.0052 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2867 - val_acc: 0.8500 - val_auroc: 0.9491 - val_f1: 0.8530\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 0.0042 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2909 - val_acc: 0.8500 - val_auroc: 0.9499 - val_f1: 0.8530\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.5218 - acc: 0.7701 - auroc: 0.8641 - f1: 0.6897 - val_loss: 0.3417 - val_acc: 0.8875 - val_auroc: 0.9480 - val_f1: 0.8886\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 280us/step - loss: 0.1088 - acc: 0.9806 - auroc: 0.9981 - f1: 0.9796 - val_loss: 0.3029 - val_acc: 0.8750 - val_auroc: 0.9371 - val_f1: 0.8826\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.0398 - acc: 0.9986 - auroc: 1.0000 - f1: 0.9985 - val_loss: 0.3174 - val_acc: 0.8750 - val_auroc: 0.9355 - val_f1: 0.8861\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 274us/step - loss: 0.0217 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9992 - val_loss: 0.3217 - val_acc: 0.8750 - val_auroc: 0.9308 - val_f1: 0.8759\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 275us/step - loss: 0.0131 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3337 - val_acc: 0.8812 - val_auroc: 0.9269 - val_f1: 0.8823\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 276us/step - loss: 0.0090 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3443 - val_acc: 0.8812 - val_auroc: 0.9245 - val_f1: 0.8823\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.0067 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3539 - val_acc: 0.8812 - val_auroc: 0.9253 - val_f1: 0.8823\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 275us/step - loss: 0.0052 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3627 - val_acc: 0.8875 - val_auroc: 0.9237 - val_f1: 0.8883\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.5480 - acc: 0.7618 - auroc: 0.8503 - f1: 0.7021 - val_loss: 0.3562 - val_acc: 0.8625 - val_auroc: 0.9517 - val_f1: 0.8558\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 281us/step - loss: 0.1311 - acc: 0.9736 - auroc: 0.9972 - f1: 0.9726 - val_loss: 0.2861 - val_acc: 0.9000 - val_auroc: 0.9553 - val_f1: 0.8834\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 269us/step - loss: 0.0481 - acc: 0.9958 - auroc: 1.0000 - f1: 0.9960 - val_loss: 0.2791 - val_acc: 0.8812 - val_auroc: 0.9538 - val_f1: 0.8648\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.0257 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9995 - val_loss: 0.2830 - val_acc: 0.8625 - val_auroc: 0.9538 - val_f1: 0.8491\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.0162 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2899 - val_acc: 0.8625 - val_auroc: 0.9513 - val_f1: 0.8491\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 275us/step - loss: 0.0113 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2960 - val_acc: 0.8625 - val_auroc: 0.9488 - val_f1: 0.8491\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 280us/step - loss: 0.0085 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3025 - val_acc: 0.8625 - val_auroc: 0.9479 - val_f1: 0.8491\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 282us/step - loss: 0.0066 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3084 - val_acc: 0.8562 - val_auroc: 0.9479 - val_f1: 0.8445\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 0s 279us/step - loss: 0.0054 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3141 - val_acc: 0.8562 - val_auroc: 0.9488 - val_f1: 0.8445\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.5257 - acc: 0.7854 - auroc: 0.8627 - f1: 0.7755 - val_loss: 0.3715 - val_acc: 0.8375 - val_auroc: 0.9373 - val_f1: 0.8428\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 282us/step - loss: 0.1038 - acc: 0.9833 - auroc: 0.9992 - f1: 0.9833 - val_loss: 0.3360 - val_acc: 0.8500 - val_auroc: 0.9351 - val_f1: 0.8552\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.0379 - acc: 0.9965 - auroc: 1.0000 - f1: 0.9966 - val_loss: 0.3517 - val_acc: 0.8375 - val_auroc: 0.9359 - val_f1: 0.8470\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 275us/step - loss: 0.0196 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9994 - val_loss: 0.3620 - val_acc: 0.8500 - val_auroc: 0.9328 - val_f1: 0.8565\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 276us/step - loss: 0.0119 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3772 - val_acc: 0.8500 - val_auroc: 0.9312 - val_f1: 0.8565\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.0082 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3906 - val_acc: 0.8500 - val_auroc: 0.9296 - val_f1: 0.8565\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 275us/step - loss: 0.0061 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4024 - val_acc: 0.8500 - val_auroc: 0.9288 - val_f1: 0.8565\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 277us/step - loss: 0.0047 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.4129 - val_acc: 0.8500 - val_auroc: 0.9288 - val_f1: 0.8565\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.5503 - acc: 0.7653 - auroc: 0.8367 - f1: 0.7871 - val_loss: 0.3910 - val_acc: 0.8063 - val_auroc: 0.9448 - val_f1: 0.7742\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 276us/step - loss: 0.1269 - acc: 0.9771 - auroc: 0.9976 - f1: 0.9771 - val_loss: 0.3099 - val_acc: 0.8625 - val_auroc: 0.9458 - val_f1: 0.8583\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 275us/step - loss: 0.0452 - acc: 0.9979 - auroc: 0.9999 - f1: 0.9980 - val_loss: 0.3119 - val_acc: 0.8438 - val_auroc: 0.9393 - val_f1: 0.8415\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.0237 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3211 - val_acc: 0.8500 - val_auroc: 0.9336 - val_f1: 0.8464\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 274us/step - loss: 0.0151 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3321 - val_acc: 0.8438 - val_auroc: 0.9304 - val_f1: 0.8391\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 268us/step - loss: 0.0106 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3425 - val_acc: 0.8375 - val_auroc: 0.9271 - val_f1: 0.8349\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.0080 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3524 - val_acc: 0.8375 - val_auroc: 0.9263 - val_f1: 0.8349\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.0063 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3617 - val_acc: 0.8375 - val_auroc: 0.9270 - val_f1: 0.8349\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 0.5331 - acc: 0.7674 - auroc: 0.8431 - f1: 0.7857 - val_loss: 0.3436 - val_acc: 0.8750 - val_auroc: 0.9577 - val_f1: 0.8615\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 277us/step - loss: 0.1084 - acc: 0.9833 - auroc: 0.9981 - f1: 0.9828 - val_loss: 0.2791 - val_acc: 0.8812 - val_auroc: 0.9686 - val_f1: 0.8736\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.0396 - acc: 0.9972 - auroc: 0.9999 - f1: 0.9972 - val_loss: 0.2650 - val_acc: 0.8812 - val_auroc: 0.9661 - val_f1: 0.8825\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.0214 - acc: 0.9993 - auroc: 1.0000 - f1: 0.9993 - val_loss: 0.2604 - val_acc: 0.8812 - val_auroc: 0.9678 - val_f1: 0.8825\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 0.0129 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2561 - val_acc: 0.9062 - val_auroc: 0.9646 - val_f1: 0.9035\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.0086 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2570 - val_acc: 0.8875 - val_auroc: 0.9654 - val_f1: 0.8863\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.0064 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2587 - val_acc: 0.8938 - val_auroc: 0.9646 - val_f1: 0.8917\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 276us/step - loss: 0.0050 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2606 - val_acc: 0.8938 - val_auroc: 0.9646 - val_f1: 0.8917\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 0s 274us/step - loss: 0.0040 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2626 - val_acc: 0.9000 - val_auroc: 0.9654 - val_f1: 0.8977\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 0s 275us/step - loss: 0.0033 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2647 - val_acc: 0.9000 - val_auroc: 0.9654 - val_f1: 0.8977\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 0s 274us/step - loss: 0.0028 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.2668 - val_acc: 0.9000 - val_auroc: 0.9654 - val_f1: 0.8977\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 0.5209 - acc: 0.8097 - auroc: 0.8748 - f1: 0.8097 - val_loss: 0.3559 - val_acc: 0.8187 - val_auroc: 0.9262 - val_f1: 0.8074\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 290us/step - loss: 0.1096 - acc: 0.9792 - auroc: 0.9984 - f1: 0.9780 - val_loss: 0.3237 - val_acc: 0.8375 - val_auroc: 0.9381 - val_f1: 0.8329\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 280us/step - loss: 0.0405 - acc: 0.9979 - auroc: 1.0000 - f1: 0.9978 - val_loss: 0.3324 - val_acc: 0.8438 - val_auroc: 0.9373 - val_f1: 0.8458\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 281us/step - loss: 0.0214 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3499 - val_acc: 0.8313 - val_auroc: 0.9357 - val_f1: 0.8354\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 282us/step - loss: 0.0135 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3640 - val_acc: 0.8250 - val_auroc: 0.9349 - val_f1: 0.8287\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 280us/step - loss: 0.0095 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3765 - val_acc: 0.8250 - val_auroc: 0.9349 - val_f1: 0.8287\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 283us/step - loss: 0.0071 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3880 - val_acc: 0.8187 - val_auroc: 0.9357 - val_f1: 0.8237\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 284us/step - loss: 0.0055 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3984 - val_acc: 0.8187 - val_auroc: 0.9350 - val_f1: 0.8237\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 9s 7ms/step - loss: 0.5390 - acc: 0.7847 - auroc: 0.8475 - f1: 0.7709 - val_loss: 0.3829 - val_acc: 0.8812 - val_auroc: 0.9212 - val_f1: 0.8816\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 0s 295us/step - loss: 0.1202 - acc: 0.9778 - auroc: 0.9983 - f1: 0.9770 - val_loss: 0.3163 - val_acc: 0.8625 - val_auroc: 0.9361 - val_f1: 0.8642\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 0s 283us/step - loss: 0.0432 - acc: 0.9986 - auroc: 1.0000 - f1: 0.9984 - val_loss: 0.3430 - val_acc: 0.8500 - val_auroc: 0.9255 - val_f1: 0.8587\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 0s 286us/step - loss: 0.0232 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3390 - val_acc: 0.8438 - val_auroc: 0.9304 - val_f1: 0.8536\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 0s 288us/step - loss: 0.0145 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3396 - val_acc: 0.8438 - val_auroc: 0.9321 - val_f1: 0.8534\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 0s 285us/step - loss: 0.0101 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3486 - val_acc: 0.8500 - val_auroc: 0.9313 - val_f1: 0.8582\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 0s 282us/step - loss: 0.0075 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3563 - val_acc: 0.8500 - val_auroc: 0.9313 - val_f1: 0.8582\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 0s 287us/step - loss: 0.0059 - acc: 1.0000 - auroc: 1.0000 - f1: 1.0000 - val_loss: 0.3638 - val_acc: 0.8500 - val_auroc: 0.9305 - val_f1: 0.8582\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=10, test_size=0.1)\n",
    "rnn_bow_scores = run_cross_validate(evaluate_lstm_model, rnn_bow, rnn_bow_targets, splitter, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'val_accuracy': 0.85625,\n",
       "   'val_auroc': 1.0,\n",
       "   'val_f1': 0.8621114492416382,\n",
       "   'val_loss': 0.29705649614334106},\n",
       "  {'val_accuracy': 0.8875,\n",
       "   'val_auroc': 0.9975583280999416,\n",
       "   'val_f1': 0.8839776992797852,\n",
       "   'val_loss': 0.33806551694869996},\n",
       "  {'val_accuracy': 0.8625,\n",
       "   'val_auroc': 1.0,\n",
       "   'val_f1': 0.8601470232009888,\n",
       "   'val_loss': 0.2629497766494751},\n",
       "  {'val_accuracy': 0.875,\n",
       "   'val_auroc': 0.9981377578771798,\n",
       "   'val_f1': 0.8826005816459656,\n",
       "   'val_loss': 0.3029003322124481},\n",
       "  {'val_accuracy': 0.88125,\n",
       "   'val_auroc': 1.0,\n",
       "   'val_f1': 0.8647875547409057,\n",
       "   'val_loss': 0.2791174933314323},\n",
       "  {'val_accuracy': 0.85,\n",
       "   'val_auroc': 0.9991914819881798,\n",
       "   'val_f1': 0.855248773097992,\n",
       "   'val_loss': 0.33604530096054075},\n",
       "  {'val_accuracy': 0.8625,\n",
       "   'val_auroc': 0.9976448998039991,\n",
       "   'val_f1': 0.8582827329635621,\n",
       "   'val_loss': 0.3098704099655151},\n",
       "  {'val_accuracy': 0.90625,\n",
       "   'val_auroc': 1.0,\n",
       "   'val_f1': 0.9034559965133667,\n",
       "   'val_loss': 0.2561005771160126},\n",
       "  {'val_accuracy': 0.8375,\n",
       "   'val_auroc': 0.9983950351907007,\n",
       "   'val_f1': 0.8329297184944153,\n",
       "   'val_loss': 0.3236561417579651},\n",
       "  {'val_accuracy': 0.8625,\n",
       "   'val_auroc': 0.9982974557429535,\n",
       "   'val_f1': 0.8641605854034424,\n",
       "   'val_loss': 0.3163498044013977}],\n",
       " 0.868125)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_bow_bests = results(rnn_bow_scores)\n",
    "rnn_bow_bests, statistics.mean([x['val_accuracy'] for x in rnn_bow_bests])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW again gives us astoundingly good accuracies, but of course, because it's over a tiny amount of data.\n",
    "\n",
    "Now let's try our pretrained Word2Vec embeddings, and compare it to our previous OpSpam embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_sequences = pad_sequences(tokenizer.texts_to_sequences(raw_features))\n",
    "max_len = max([len(x) for x in predictors_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_wv_model():\n",
    "  model = Sequential([\n",
    "        Embedding(corpus_vocab_size, embedding_length, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
    "        LSTM(10),\n",
    "        Dense(1, activation=sigmoid)\n",
    "  ])\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', auroc, f1])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_model(train_X, train_y, test_X, test_y):\n",
    "    lstm_model = get_lstm_wv_model()\n",
    "    return lstm_model.fit(train_X, train_y, epochs=25, batch_size=32, verbose=1, shuffle=False,\n",
    "                          callbacks=[EarlyStopping(monitor='val_loss', patience=6)],\n",
    "                          validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 38s 27ms/step - loss: 0.6883 - acc: 0.5368 - auroc: 0.5654 - f1: 0.5247 - val_loss: 0.6874 - val_acc: 0.5813 - val_auroc: 0.6041 - val_f1: 0.6137\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.6620 - acc: 0.6312 - auroc: 0.6959 - f1: 0.6417 - val_loss: 0.6640 - val_acc: 0.6062 - val_auroc: 0.6536 - val_f1: 0.5576\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.6138 - acc: 0.6681 - auroc: 0.7548 - f1: 0.6641 - val_loss: 0.6025 - val_acc: 0.7188 - val_auroc: 0.7446 - val_f1: 0.6765\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.5891 - acc: 0.6979 - auroc: 0.7884 - f1: 0.6801 - val_loss: 0.6733 - val_acc: 0.6500 - val_auroc: 0.6854 - val_f1: 0.7158\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.6718 - acc: 0.5958 - auroc: 0.7324 - f1: 0.6453 - val_loss: 0.6781 - val_acc: 0.5563 - val_auroc: 0.6062 - val_f1: 0.5072\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.6316 - acc: 0.6722 - auroc: 0.7420 - f1: 0.6687 - val_loss: 0.6676 - val_acc: 0.5687 - val_auroc: 0.6383 - val_f1: 0.5744\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.5933 - acc: 0.7000 - auroc: 0.7756 - f1: 0.6939 - val_loss: 0.6330 - val_acc: 0.6750 - val_auroc: 0.6924 - val_f1: 0.6289\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.6269 - acc: 0.6486 - auroc: 0.7455 - f1: 0.6947 - val_loss: 0.6755 - val_acc: 0.5687 - val_auroc: 0.5954 - val_f1: 0.4833\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 28s 19ms/step - loss: 0.6465 - acc: 0.6556 - auroc: 0.7075 - f1: 0.6203 - val_loss: 0.6606 - val_acc: 0.5938 - val_auroc: 0.6326 - val_f1: 0.6116\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 37s 26ms/step - loss: 0.6882 - acc: 0.5437 - auroc: 0.5828 - f1: 0.4971 - val_loss: 0.6744 - val_acc: 0.6125 - val_auroc: 0.6911 - val_f1: 0.6946\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6694 - acc: 0.6118 - auroc: 0.6667 - f1: 0.6146 - val_loss: 0.6497 - val_acc: 0.6625 - val_auroc: 0.7292 - val_f1: 0.6961\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6373 - acc: 0.6424 - auroc: 0.7204 - f1: 0.6215 - val_loss: 0.6136 - val_acc: 0.6625 - val_auroc: 0.7554 - val_f1: 0.6715\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6100 - acc: 0.6708 - auroc: 0.7738 - f1: 0.6561 - val_loss: 0.6254 - val_acc: 0.6500 - val_auroc: 0.7610 - val_f1: 0.5157\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5757 - acc: 0.7035 - auroc: 0.8150 - f1: 0.6802 - val_loss: 0.6392 - val_acc: 0.6500 - val_auroc: 0.7702 - val_f1: 0.4949\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5779 - acc: 0.6986 - auroc: 0.8217 - f1: 0.6431 - val_loss: 0.5999 - val_acc: 0.6750 - val_auroc: 0.7721 - val_f1: 0.6931\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5243 - acc: 0.7528 - auroc: 0.8295 - f1: 0.7291 - val_loss: 0.6110 - val_acc: 0.6875 - val_auroc: 0.7674 - val_f1: 0.7140\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5838 - acc: 0.6924 - auroc: 0.7996 - f1: 0.5875 - val_loss: 0.5871 - val_acc: 0.6937 - val_auroc: 0.7778 - val_f1: 0.7109\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5326 - acc: 0.7472 - auroc: 0.8340 - f1: 0.7448 - val_loss: 0.5680 - val_acc: 0.7000 - val_auroc: 0.7977 - val_f1: 0.5972\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5486 - acc: 0.7444 - auroc: 0.8457 - f1: 0.7515 - val_loss: 0.7156 - val_acc: 0.6188 - val_auroc: 0.7627 - val_f1: 0.7112\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6172 - acc: 0.6715 - auroc: 0.7833 - f1: 0.5379 - val_loss: 0.6781 - val_acc: 0.5687 - val_auroc: 0.7059 - val_f1: 0.3117\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5740 - acc: 0.6819 - auroc: 0.8021 - f1: 0.5551 - val_loss: 0.6594 - val_acc: 0.5375 - val_auroc: 0.7390 - val_f1: 0.1778\n",
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6533 - acc: 0.6215 - auroc: 0.7282 - f1: 0.4689 - val_loss: 0.6458 - val_acc: 0.6250 - val_auroc: 0.7183 - val_f1: 0.6488\n",
      "Epoch 14/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6259 - acc: 0.6729 - auroc: 0.7416 - f1: 0.6562 - val_loss: 0.6247 - val_acc: 0.6438 - val_auroc: 0.7265 - val_f1: 0.6531\n",
      "Epoch 15/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5986 - acc: 0.6736 - auroc: 0.7753 - f1: 0.6793 - val_loss: 0.5883 - val_acc: 0.6500 - val_auroc: 0.7843 - val_f1: 0.6741\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 37s 26ms/step - loss: 0.6891 - acc: 0.5410 - auroc: 0.5677 - f1: 0.6005 - val_loss: 0.6900 - val_acc: 0.5813 - val_auroc: 0.5722 - val_f1: 0.5857\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6690 - acc: 0.6042 - auroc: 0.6622 - f1: 0.6041 - val_loss: 0.6770 - val_acc: 0.5875 - val_auroc: 0.6131 - val_f1: 0.5939\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6287 - acc: 0.6618 - auroc: 0.7351 - f1: 0.6563 - val_loss: 0.6085 - val_acc: 0.6937 - val_auroc: 0.7633 - val_f1: 0.7340\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5725 - acc: 0.7042 - auroc: 0.8038 - f1: 0.7261 - val_loss: 0.5811 - val_acc: 0.7063 - val_auroc: 0.7799 - val_f1: 0.7433\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5172 - acc: 0.7681 - auroc: 0.8456 - f1: 0.7648 - val_loss: 0.5914 - val_acc: 0.7125 - val_auroc: 0.7800 - val_f1: 0.7567\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5699 - acc: 0.7215 - auroc: 0.8367 - f1: 0.7507 - val_loss: 0.6386 - val_acc: 0.6250 - val_auroc: 0.7499 - val_f1: 0.7103\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.5283 - acc: 0.7667 - auroc: 0.8556 - f1: 0.7232 - val_loss: 0.5441 - val_acc: 0.7625 - val_auroc: 0.7830 - val_f1: 0.7573\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5178 - acc: 0.7562 - auroc: 0.8487 - f1: 0.7613 - val_loss: 0.6940 - val_acc: 0.6937 - val_auroc: 0.7461 - val_f1: 0.5646\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5229 - acc: 0.7708 - auroc: 0.8521 - f1: 0.7366 - val_loss: 0.5568 - val_acc: 0.7438 - val_auroc: 0.7814 - val_f1: 0.7226\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5853 - acc: 0.6694 - auroc: 0.8195 - f1: 0.4860 - val_loss: 0.6792 - val_acc: 0.5875 - val_auroc: 0.6649 - val_f1: 0.4158\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5907 - acc: 0.6958 - auroc: 0.7737 - f1: 0.6760 - val_loss: 0.6303 - val_acc: 0.6562 - val_auroc: 0.7059 - val_f1: 0.6610\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5416 - acc: 0.7417 - auroc: 0.8146 - f1: 0.7317 - val_loss: 0.5688 - val_acc: 0.7312 - val_auroc: 0.7735 - val_f1: 0.7204\n",
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4501 - acc: 0.7979 - auroc: 0.8853 - f1: 0.7912 - val_loss: 0.5707 - val_acc: 0.7375 - val_auroc: 0.8012 - val_f1: 0.7525\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 38s 26ms/step - loss: 0.6910 - acc: 0.5347 - auroc: 0.5486 - f1: 0.5926 - val_loss: 0.6812 - val_acc: 0.6500 - val_auroc: 0.6776 - val_f1: 0.6663\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6751 - acc: 0.6167 - auroc: 0.6507 - f1: 0.6272 - val_loss: 0.6671 - val_acc: 0.6312 - val_auroc: 0.6930 - val_f1: 0.6050\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6348 - acc: 0.6583 - auroc: 0.7215 - f1: 0.6295 - val_loss: 0.6245 - val_acc: 0.6312 - val_auroc: 0.7193 - val_f1: 0.6164\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5870 - acc: 0.7021 - auroc: 0.7807 - f1: 0.6791 - val_loss: 0.5994 - val_acc: 0.6750 - val_auroc: 0.7593 - val_f1: 0.6436\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.6083 - acc: 0.6813 - auroc: 0.8086 - f1: 0.6021 - val_loss: 0.5170 - val_acc: 0.7875 - val_auroc: 0.8709 - val_f1: 0.7772\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6505 - acc: 0.6257 - auroc: 0.7910 - f1: 0.4563 - val_loss: 0.6076 - val_acc: 0.6875 - val_auroc: 0.7612 - val_f1: 0.6868\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5772 - acc: 0.7229 - auroc: 0.7943 - f1: 0.7233 - val_loss: 0.5741 - val_acc: 0.7250 - val_auroc: 0.8087 - val_f1: 0.7361\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5310 - acc: 0.7472 - auroc: 0.8326 - f1: 0.7411 - val_loss: 0.5201 - val_acc: 0.7688 - val_auroc: 0.8445 - val_f1: 0.7781\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5214 - acc: 0.7444 - auroc: 0.8510 - f1: 0.7152 - val_loss: 0.5532 - val_acc: 0.7063 - val_auroc: 0.8044 - val_f1: 0.6502\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5083 - acc: 0.7514 - auroc: 0.8554 - f1: 0.7390 - val_loss: 0.5345 - val_acc: 0.7562 - val_auroc: 0.8327 - val_f1: 0.7794\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5679 - acc: 0.6972 - auroc: 0.8464 - f1: 0.5732 - val_loss: 0.6820 - val_acc: 0.6250 - val_auroc: 0.7949 - val_f1: 0.7079\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 39s 27ms/step - loss: 0.6892 - acc: 0.5437 - auroc: 0.5709 - f1: 0.5621 - val_loss: 0.6773 - val_acc: 0.6125 - val_auroc: 0.6667 - val_f1: 0.6821\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6418 - acc: 0.6528 - auroc: 0.7117 - f1: 0.6678 - val_loss: 0.6021 - val_acc: 0.6937 - val_auroc: 0.7735 - val_f1: 0.7212\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6717 - acc: 0.6160 - auroc: 0.7261 - f1: 0.5562 - val_loss: 0.6393 - val_acc: 0.6562 - val_auroc: 0.7354 - val_f1: 0.7240\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6144 - acc: 0.6799 - auroc: 0.7597 - f1: 0.6468 - val_loss: 0.6272 - val_acc: 0.6687 - val_auroc: 0.7250 - val_f1: 0.5629\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5936 - acc: 0.6917 - auroc: 0.7690 - f1: 0.6289 - val_loss: 0.6222 - val_acc: 0.6375 - val_auroc: 0.7100 - val_f1: 0.6228\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5820 - acc: 0.7229 - auroc: 0.8019 - f1: 0.7229 - val_loss: 0.5058 - val_acc: 0.7875 - val_auroc: 0.8255 - val_f1: 0.7684\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5700 - acc: 0.7181 - auroc: 0.8066 - f1: 0.6665 - val_loss: 0.6523 - val_acc: 0.6062 - val_auroc: 0.7186 - val_f1: 0.3617\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5882 - acc: 0.6979 - auroc: 0.7904 - f1: 0.6134 - val_loss: 0.5867 - val_acc: 0.7125 - val_auroc: 0.7642 - val_f1: 0.6944\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6455 - acc: 0.6111 - auroc: 0.7728 - f1: 0.4315 - val_loss: 0.6783 - val_acc: 0.5625 - val_auroc: 0.6648 - val_f1: 0.3030\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6246 - acc: 0.6556 - auroc: 0.7421 - f1: 0.5593 - val_loss: 0.6348 - val_acc: 0.6250 - val_auroc: 0.6809 - val_f1: 0.6330\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6000 - acc: 0.6785 - auroc: 0.7559 - f1: 0.6671 - val_loss: 0.6268 - val_acc: 0.6500 - val_auroc: 0.6997 - val_f1: 0.6532\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5728 - acc: 0.6882 - auroc: 0.7796 - f1: 0.6697 - val_loss: 0.6371 - val_acc: 0.6625 - val_auroc: 0.7178 - val_f1: 0.6893\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 39s 27ms/step - loss: 0.6902 - acc: 0.5278 - auroc: 0.5499 - f1: 0.4365 - val_loss: 0.6770 - val_acc: 0.5750 - val_auroc: 0.6597 - val_f1: 0.6512\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6716 - acc: 0.6167 - auroc: 0.6779 - f1: 0.6086 - val_loss: 0.6493 - val_acc: 0.6875 - val_auroc: 0.7203 - val_f1: 0.6501\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6333 - acc: 0.6486 - auroc: 0.7414 - f1: 0.5850 - val_loss: 0.6035 - val_acc: 0.7250 - val_auroc: 0.7632 - val_f1: 0.6872\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5939 - acc: 0.6937 - auroc: 0.7872 - f1: 0.6615 - val_loss: 0.5924 - val_acc: 0.6875 - val_auroc: 0.7709 - val_f1: 0.6236\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5558 - acc: 0.7229 - auroc: 0.8234 - f1: 0.7023 - val_loss: 0.7894 - val_acc: 0.5312 - val_auroc: 0.6493 - val_f1: 0.1200\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5915 - acc: 0.6944 - auroc: 0.8220 - f1: 0.6515 - val_loss: 0.5557 - val_acc: 0.7562 - val_auroc: 0.8033 - val_f1: 0.7729\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5125 - acc: 0.7667 - auroc: 0.8472 - f1: 0.7586 - val_loss: 0.5633 - val_acc: 0.7125 - val_auroc: 0.7982 - val_f1: 0.7093\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.4970 - acc: 0.7743 - auroc: 0.8664 - f1: 0.7611 - val_loss: 0.5682 - val_acc: 0.7312 - val_auroc: 0.8117 - val_f1: 0.7384\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5459 - acc: 0.7215 - auroc: 0.8424 - f1: 0.7457 - val_loss: 0.5366 - val_acc: 0.7500 - val_auroc: 0.8289 - val_f1: 0.7761\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4829 - acc: 0.7882 - auroc: 0.8767 - f1: 0.7732 - val_loss: 0.6097 - val_acc: 0.7125 - val_auroc: 0.7876 - val_f1: 0.6590\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5668 - acc: 0.7097 - auroc: 0.8538 - f1: 0.6473 - val_loss: 0.5521 - val_acc: 0.7500 - val_auroc: 0.8084 - val_f1: 0.7496\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4515 - acc: 0.8132 - auroc: 0.8954 - f1: 0.8114 - val_loss: 0.5208 - val_acc: 0.7562 - val_auroc: 0.8213 - val_f1: 0.7458\n",
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.4792 - acc: 0.7826 - auroc: 0.8805 - f1: 0.7829 - val_loss: 0.5648 - val_acc: 0.7312 - val_auroc: 0.8004 - val_f1: 0.7023\n",
      "Epoch 14/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.5026 - acc: 0.7597 - auroc: 0.8725 - f1: 0.7146 - val_loss: 0.6232 - val_acc: 0.6687 - val_auroc: 0.7217 - val_f1: 0.6587\n",
      "Epoch 15/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5148 - acc: 0.7444 - auroc: 0.8387 - f1: 0.7379 - val_loss: 0.6089 - val_acc: 0.6875 - val_auroc: 0.7546 - val_f1: 0.6226\n",
      "Epoch 16/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4424 - acc: 0.7986 - auroc: 0.8795 - f1: 0.7841 - val_loss: 0.5820 - val_acc: 0.7312 - val_auroc: 0.8109 - val_f1: 0.6964\n",
      "Epoch 17/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4241 - acc: 0.8271 - auroc: 0.8976 - f1: 0.8199 - val_loss: 0.6138 - val_acc: 0.7250 - val_auroc: 0.8515 - val_f1: 0.7784\n",
      "Epoch 18/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4227 - acc: 0.8153 - auroc: 0.9078 - f1: 0.8134 - val_loss: 0.5299 - val_acc: 0.7500 - val_auroc: 0.8251 - val_f1: 0.7399\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 40s 27ms/step - loss: 0.6883 - acc: 0.5382 - auroc: 0.5526 - f1: 0.4248 - val_loss: 0.6801 - val_acc: 0.5375 - val_auroc: 0.6384 - val_f1: 0.6394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6635 - acc: 0.5993 - auroc: 0.6726 - f1: 0.5753 - val_loss: 0.6456 - val_acc: 0.6062 - val_auroc: 0.7094 - val_f1: 0.6695\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6076 - acc: 0.6701 - auroc: 0.7544 - f1: 0.6496 - val_loss: 0.5649 - val_acc: 0.7438 - val_auroc: 0.8142 - val_f1: 0.7573\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5459 - acc: 0.7208 - auroc: 0.8095 - f1: 0.6992 - val_loss: 0.5182 - val_acc: 0.7438 - val_auroc: 0.8453 - val_f1: 0.7522\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5058 - acc: 0.7590 - auroc: 0.8436 - f1: 0.7409 - val_loss: 0.5190 - val_acc: 0.7500 - val_auroc: 0.8666 - val_f1: 0.7814\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4944 - acc: 0.7660 - auroc: 0.8674 - f1: 0.7628 - val_loss: 0.5177 - val_acc: 0.8000 - val_auroc: 0.8505 - val_f1: 0.8164\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5347 - acc: 0.7347 - auroc: 0.8644 - f1: 0.7106 - val_loss: 0.5858 - val_acc: 0.6813 - val_auroc: 0.8367 - val_f1: 0.7446\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4790 - acc: 0.7674 - auroc: 0.8792 - f1: 0.7531 - val_loss: 0.4893 - val_acc: 0.7625 - val_auroc: 0.8756 - val_f1: 0.7785\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5060 - acc: 0.7674 - auroc: 0.8662 - f1: 0.7185 - val_loss: 0.4966 - val_acc: 0.8063 - val_auroc: 0.8607 - val_f1: 0.8055\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4284 - acc: 0.8111 - auroc: 0.8951 - f1: 0.7993 - val_loss: 0.5038 - val_acc: 0.7812 - val_auroc: 0.8846 - val_f1: 0.7986\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4692 - acc: 0.7917 - auroc: 0.8871 - f1: 0.7963 - val_loss: 0.8993 - val_acc: 0.5188 - val_auroc: 0.7212 - val_f1: 0.6717\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6166 - acc: 0.6687 - auroc: 0.8126 - f1: 0.7236 - val_loss: 0.5197 - val_acc: 0.7438 - val_auroc: 0.8494 - val_f1: 0.7846\n",
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4647 - acc: 0.7993 - auroc: 0.8852 - f1: 0.8045 - val_loss: 0.5054 - val_acc: 0.7438 - val_auroc: 0.8595 - val_f1: 0.7806\n",
      "Epoch 14/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4141 - acc: 0.8312 - auroc: 0.9044 - f1: 0.8256 - val_loss: 0.4964 - val_acc: 0.7812 - val_auroc: 0.8723 - val_f1: 0.7990\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 40s 28ms/step - loss: 0.6905 - acc: 0.5444 - auroc: 0.5546 - f1: 0.5906 - val_loss: 0.6771 - val_acc: 0.6000 - val_auroc: 0.6464 - val_f1: 0.6070\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6503 - acc: 0.6299 - auroc: 0.7070 - f1: 0.6098 - val_loss: 0.6014 - val_acc: 0.7063 - val_auroc: 0.7552 - val_f1: 0.6896\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6294 - acc: 0.6667 - auroc: 0.7778 - f1: 0.6207 - val_loss: 0.5931 - val_acc: 0.7125 - val_auroc: 0.7676 - val_f1: 0.6532\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.5638 - acc: 0.7285 - auroc: 0.8112 - f1: 0.7039 - val_loss: 0.5662 - val_acc: 0.7312 - val_auroc: 0.7934 - val_f1: 0.7161\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5844 - acc: 0.7181 - auroc: 0.8032 - f1: 0.7154 - val_loss: 0.5932 - val_acc: 0.7125 - val_auroc: 0.7902 - val_f1: 0.7409\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5403 - acc: 0.7514 - auroc: 0.8415 - f1: 0.7609 - val_loss: 0.5230 - val_acc: 0.7688 - val_auroc: 0.8266 - val_f1: 0.7664\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4979 - acc: 0.7833 - auroc: 0.8603 - f1: 0.7687 - val_loss: 0.5241 - val_acc: 0.7688 - val_auroc: 0.8336 - val_f1: 0.7893\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5221 - acc: 0.7576 - auroc: 0.8579 - f1: 0.7650 - val_loss: 0.7632 - val_acc: 0.5813 - val_auroc: 0.7530 - val_f1: 0.6975\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.8264 - acc: 0.5021 - auroc: 0.6895 - f1: 0.6636 - val_loss: 0.7196 - val_acc: 0.5125 - val_auroc: 0.6684 - val_f1: 0.6653\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6778 - acc: 0.5465 - auroc: 0.7217 - f1: 0.6771 - val_loss: 0.6542 - val_acc: 0.6125 - val_auroc: 0.7139 - val_f1: 0.6928\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6036 - acc: 0.7215 - auroc: 0.8038 - f1: 0.7183 - val_loss: 0.5414 - val_acc: 0.7688 - val_auroc: 0.8428 - val_f1: 0.7742\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6102 - acc: 0.6507 - auroc: 0.7849 - f1: 0.7293 - val_loss: 0.6265 - val_acc: 0.6188 - val_auroc: 0.7305 - val_f1: 0.7131\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 41s 28ms/step - loss: 0.6877 - acc: 0.5354 - auroc: 0.5857 - f1: 0.4825 - val_loss: 0.6740 - val_acc: 0.6062 - val_auroc: 0.7036 - val_f1: 0.6431\n",
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6655 - acc: 0.6174 - auroc: 0.6753 - f1: 0.6096 - val_loss: 0.6253 - val_acc: 0.7188 - val_auroc: 0.7593 - val_f1: 0.7391\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6067 - acc: 0.6826 - auroc: 0.7510 - f1: 0.6636 - val_loss: 0.5261 - val_acc: 0.7688 - val_auroc: 0.8185 - val_f1: 0.7588\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5587 - acc: 0.7132 - auroc: 0.7993 - f1: 0.6877 - val_loss: 0.4892 - val_acc: 0.7625 - val_auroc: 0.8475 - val_f1: 0.7386\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5341 - acc: 0.7438 - auroc: 0.8411 - f1: 0.7145 - val_loss: 0.5010 - val_acc: 0.7750 - val_auroc: 0.8451 - val_f1: 0.7626\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6346 - acc: 0.6958 - auroc: 0.8094 - f1: 0.7405 - val_loss: 0.5891 - val_acc: 0.6875 - val_auroc: 0.7949 - val_f1: 0.7494\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5668 - acc: 0.7257 - auroc: 0.8290 - f1: 0.6673 - val_loss: 0.5809 - val_acc: 0.7063 - val_auroc: 0.8042 - val_f1: 0.6190\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5435 - acc: 0.7417 - auroc: 0.8276 - f1: 0.7233 - val_loss: 0.4788 - val_acc: 0.8000 - val_auroc: 0.8727 - val_f1: 0.8032\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4950 - acc: 0.7715 - auroc: 0.8654 - f1: 0.7780 - val_loss: 0.5203 - val_acc: 0.7750 - val_auroc: 0.8483 - val_f1: 0.7960\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4933 - acc: 0.7799 - auroc: 0.8636 - f1: 0.7882 - val_loss: 0.4859 - val_acc: 0.7750 - val_auroc: 0.8656 - val_f1: 0.7714\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6166 - acc: 0.7125 - auroc: 0.8280 - f1: 0.6399 - val_loss: 1.0057 - val_acc: 0.5000 - val_auroc: 0.6031 - val_f1: 0.0000e+00\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.7395 - acc: 0.5521 - auroc: 0.7395 - f1: 0.1980 - val_loss: 0.6354 - val_acc: 0.6750 - val_auroc: 0.7226 - val_f1: 0.6239\n",
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6256 - acc: 0.6819 - auroc: 0.7519 - f1: 0.6593 - val_loss: 0.6191 - val_acc: 0.6937 - val_auroc: 0.7580 - val_f1: 0.6847\n",
      "Epoch 14/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6066 - acc: 0.7042 - auroc: 0.7727 - f1: 0.6871 - val_loss: 0.5954 - val_acc: 0.7375 - val_auroc: 0.7800 - val_f1: 0.7326\n",
      "Train on 1440 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "1440/1440 [==============================] - 41s 28ms/step - loss: 0.6879 - acc: 0.5431 - auroc: 0.5914 - f1: 0.6150 - val_loss: 0.6844 - val_acc: 0.5437 - val_auroc: 0.5714 - val_f1: 0.5411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6568 - acc: 0.6347 - auroc: 0.6931 - f1: 0.6308 - val_loss: 0.6682 - val_acc: 0.6000 - val_auroc: 0.6376 - val_f1: 0.5077\n",
      "Epoch 3/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6079 - acc: 0.6764 - auroc: 0.7519 - f1: 0.6541 - val_loss: 0.6519 - val_acc: 0.6375 - val_auroc: 0.6713 - val_f1: 0.6133\n",
      "Epoch 4/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6214 - acc: 0.6528 - auroc: 0.7716 - f1: 0.4912 - val_loss: 0.6976 - val_acc: 0.5375 - val_auroc: 0.6484 - val_f1: 0.1714\n",
      "Epoch 5/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6396 - acc: 0.6528 - auroc: 0.7488 - f1: 0.5830 - val_loss: 0.6569 - val_acc: 0.6188 - val_auroc: 0.6547 - val_f1: 0.6103\n",
      "Epoch 6/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.6103 - acc: 0.6778 - auroc: 0.7543 - f1: 0.6603 - val_loss: 0.6553 - val_acc: 0.6062 - val_auroc: 0.6634 - val_f1: 0.5779\n",
      "Epoch 7/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5838 - acc: 0.6944 - auroc: 0.7708 - f1: 0.6776 - val_loss: 0.6602 - val_acc: 0.6250 - val_auroc: 0.6760 - val_f1: 0.5825\n",
      "Epoch 8/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5583 - acc: 0.7167 - auroc: 0.7942 - f1: 0.7074 - val_loss: 0.6511 - val_acc: 0.6438 - val_auroc: 0.6902 - val_f1: 0.6497\n",
      "Epoch 9/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5300 - acc: 0.7438 - auroc: 0.8171 - f1: 0.7392 - val_loss: 0.6296 - val_acc: 0.6375 - val_auroc: 0.7298 - val_f1: 0.6333\n",
      "Epoch 10/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.5101 - acc: 0.7514 - auroc: 0.8430 - f1: 0.7456 - val_loss: 0.6193 - val_acc: 0.6937 - val_auroc: 0.7457 - val_f1: 0.7311\n",
      "Epoch 11/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.5117 - acc: 0.7583 - auroc: 0.8569 - f1: 0.7500 - val_loss: 0.6598 - val_acc: 0.6438 - val_auroc: 0.7273 - val_f1: 0.5644\n",
      "Epoch 12/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4857 - acc: 0.7826 - auroc: 0.8636 - f1: 0.7696 - val_loss: 0.5782 - val_acc: 0.7188 - val_auroc: 0.7867 - val_f1: 0.7302\n",
      "Epoch 13/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4613 - acc: 0.7993 - auroc: 0.8811 - f1: 0.7974 - val_loss: 0.6042 - val_acc: 0.7188 - val_auroc: 0.7880 - val_f1: 0.7676\n",
      "Epoch 14/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4837 - acc: 0.7764 - auroc: 0.8848 - f1: 0.7593 - val_loss: 0.5244 - val_acc: 0.7875 - val_auroc: 0.8090 - val_f1: 0.7819\n",
      "Epoch 15/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4249 - acc: 0.8111 - auroc: 0.9010 - f1: 0.8109 - val_loss: 0.6323 - val_acc: 0.6750 - val_auroc: 0.7845 - val_f1: 0.5825\n",
      "Epoch 16/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4319 - acc: 0.8083 - auroc: 0.9000 - f1: 0.8088 - val_loss: 0.5218 - val_acc: 0.8063 - val_auroc: 0.8255 - val_f1: 0.7896\n",
      "Epoch 17/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4404 - acc: 0.8097 - auroc: 0.9060 - f1: 0.8054 - val_loss: 0.5427 - val_acc: 0.7812 - val_auroc: 0.8394 - val_f1: 0.8038\n",
      "Epoch 18/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.4277 - acc: 0.8083 - auroc: 0.9091 - f1: 0.7829 - val_loss: 0.5843 - val_acc: 0.7625 - val_auroc: 0.8252 - val_f1: 0.7905\n",
      "Epoch 19/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.3839 - acc: 0.8424 - auroc: 0.9241 - f1: 0.8303 - val_loss: 0.5082 - val_acc: 0.8187 - val_auroc: 0.8341 - val_f1: 0.8177\n",
      "Epoch 20/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.3711 - acc: 0.8438 - auroc: 0.9271 - f1: 0.8302 - val_loss: 0.5052 - val_acc: 0.8187 - val_auroc: 0.8300 - val_f1: 0.8204\n",
      "Epoch 21/25\n",
      "1440/1440 [==============================] - 27s 18ms/step - loss: 0.3755 - acc: 0.8403 - auroc: 0.9296 - f1: 0.8287 - val_loss: 0.5180 - val_acc: 0.8063 - val_auroc: 0.8322 - val_f1: 0.8041\n",
      "Epoch 22/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.3688 - acc: 0.8431 - auroc: 0.9302 - f1: 0.8353 - val_loss: 0.5782 - val_acc: 0.7125 - val_auroc: 0.8150 - val_f1: 0.6610\n",
      "Epoch 23/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.3802 - acc: 0.8410 - auroc: 0.9209 - f1: 0.8318 - val_loss: 0.6722 - val_acc: 0.7125 - val_auroc: 0.8174 - val_f1: 0.7711\n",
      "Epoch 24/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.3742 - acc: 0.8438 - auroc: 0.9287 - f1: 0.8422 - val_loss: 0.4753 - val_acc: 0.8313 - val_auroc: 0.8497 - val_f1: 0.8379\n",
      "Epoch 25/25\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 0.3197 - acc: 0.8806 - auroc: 0.9397 - f1: 0.8747 - val_loss: 0.4671 - val_acc: 0.8438 - val_auroc: 0.8491 - val_f1: 0.8473\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=10, test_size=0.1)\n",
    "rnn_wv_scores = run_cross_validate(evaluate_lstm_model, predictors_sequences, labels, splitter, cv=10, verbose=1, epochs=12, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'val_accuracy': 0.71875,\n",
       "   'val_auroc': 0.7548312122281745,\n",
       "   'val_f1': 0.6764826536178589,\n",
       "   'val_loss': 0.6025090217590332},\n",
       "  {'val_accuracy': 0.7,\n",
       "   'val_auroc': 0.8339738215502533,\n",
       "   'val_f1': 0.5972380459308624,\n",
       "   'val_loss': 0.5680399894714355},\n",
       "  {'val_accuracy': 0.7625,\n",
       "   'val_auroc': 0.855618929031113,\n",
       "   'val_f1': 0.757334041595459,\n",
       "   'val_loss': 0.5441445708274841},\n",
       "  {'val_accuracy': 0.7875,\n",
       "   'val_auroc': 0.8086068390971964,\n",
       "   'val_f1': 0.7771724700927735,\n",
       "   'val_loss': 0.5170442998409271},\n",
       "  {'val_accuracy': 0.7875,\n",
       "   'val_auroc': 0.8019395169232308,\n",
       "   'val_f1': 0.7683555722236634,\n",
       "   'val_loss': 0.5057554423809052},\n",
       "  {'val_accuracy': 0.75625,\n",
       "   'val_auroc': 0.895406646700345,\n",
       "   'val_f1': 0.7458417177200317,\n",
       "   'val_loss': 0.520826256275177},\n",
       "  {'val_accuracy': 0.7625,\n",
       "   'val_auroc': 0.879181166539429,\n",
       "   'val_f1': 0.7785416841506958,\n",
       "   'val_loss': 0.48928182721138},\n",
       "  {'val_accuracy': 0.76875,\n",
       "   'val_auroc': 0.8415054827914413,\n",
       "   'val_f1': 0.7664394974708557,\n",
       "   'val_loss': 0.5229696273803711},\n",
       "  {'val_accuracy': 0.8,\n",
       "   'val_auroc': 0.8276340565167644,\n",
       "   'val_f1': 0.8031648516654968,\n",
       "   'val_loss': 0.4788025677204132},\n",
       "  {'val_accuracy': 0.84375,\n",
       "   'val_auroc': 0.9397378836500997,\n",
       "   'val_f1': 0.8472953319549561,\n",
       "   'val_loss': 0.4670828402042389}],\n",
       " 0.76875)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_wv_bests = results(rnn_wv_scores)\n",
    "rnn_wv_bests, statistics.mean([x['val_accuracy'] for x in rnn_wv_bests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_scores_entries =[('Bag of Words', x['val_accuracy']) for x in rnn_bow_bests] + [('Word Vectors', x['val_accuracy']) for x in rnn_wv_bests]\n",
    "rnn_scores_data_frame = DataFrame(rnn_scores_entries, columns=['input type', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(x='input type', y='accuracy', data=rnn_scores_data_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are still seeing much higher results for BOW, however our pretrained vectors are doing better than the custom ones trained on the OpSpam dataset. This shows us conclusively that word embeddings do have some value, though perhaps not on a dataset as small as this. When we test over our full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
