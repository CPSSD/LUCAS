{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need data that labels online user-submitted content as genuine or purposely falsified. We have found three sources of data.\n",
    "\n",
    "## Yelp Reviews\n",
    "\n",
    "* 426,447 reviews (?)\n",
    "* Split into three sets, New York, Chicago and a third 'zip' set.\n",
    "* Ground truth set, derived from Yelp's spam detection detection.\n",
    "* Yelp's spam detection [is accurate](https://bloom.bg/1KAxzhK)\n",
    "### NYC\n",
    "* 359,052 reviews\n",
    "* All reviews are for restaurants.\n",
    "* 923 resteraunts\n",
    "* 160,225 reviewers\n",
    "* 322167 Genuine, 36885 Fake\n",
    "### Chicago\n",
    "* 67,395 reviews\n",
    "* Reviews are split between restaurants and hotels.\n",
    "* 201 hotels/resteraunts\n",
    "* 38,063 reviewers\n",
    "* 5854 hotel reviews / 61541 restaurant reviews\n",
    "* ~36874 Fake reviews\n",
    "### Zip\n",
    "* 608,598 reviews\n",
    "* All reviews are for restaurants.\n",
    "* 5045 restaurants\n",
    "* 260,277 reviewers\n",
    "* 80466 fake / 528132 genuine\n",
    "* Organised by zip codes (NY, NJ, VT, CT, PA)\n",
    "\n",
    "## Amazon Reviews\n",
    "\n",
    "* Compiled as a result of an investigation into fake review production\n",
    "* 628 fake reviews, 942 real reviews\n",
    "* Gold standard set. From book authors that confessed to buying fake reviews.\n",
    "* \"All reviews were between 50 and 150 words as a minimum length\"\n",
    "\n",
    "## TripAdvisor Reviews\n",
    "\n",
    "* 800 Hotel reviews\n",
    "* 400 genuine reviews, 400 fake reviews\n",
    "* Gold standard set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What dataset should we use?\n",
    "\n",
    "We should think about what dataset we should use to avoid poor performance later. For example, the [Review Skeptic](http://reviewskeptic.com) site uses a technique that can achieve 90% accuracy on a specific hotel review corpus, however it does not have the same results cross-domain.\n",
    "\n",
    "We have multiple categories of reviews (resteraunts, hotels, books). There are signifigant differences between these categories. To use all of them together we must use Multi-domain learning, and understand it's implications.\n",
    "\n",
    "[Mahesh Joshi et al. Multi-Domain Learning: When Do Domains Matter?](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwiAx9bht5PeAhXnJMAKHR-gDSwQFjAAegQICRAC&url=https%3A%2F%2Fwww.cs.cmu.edu%2F~wcohen%2Fpostscript%2Femnlp-2012-mahesh.pdf&usg=AOvVaw2MXWvDn1n2Cs2KXKxqdBP6)\n",
    "\n",
    "\n",
    "# Well known points:\n",
    "\n",
    "* There are signifigant differences between product review categories. ([John Blitzer et al. Domain Adaptation for Sentiment Classification](https://www.cs.jhu.edu/~mdredze/datasets/sentiment/))\n",
    "* Trained classifiers lose accuracy when the test data distribution is significantly different from the training data distribution.\n",
    "* Features may be distributed differently in different domains. This is the case of p(x) changing between domains. The result is some features may only appear in a single domain.\n",
    "* Features may behave differently in different domains. This is the case of p(y|x) changing between domains. The result is that the learning algorithm cannot generalise feature behaviour across domains.\n",
    "\n",
    "## Is there a problem with interlacing all our data?\n",
    "\n",
    "Possibly. A natural first step is to attempt to create our benchmark from a single domain. Afterwards, we can try interlacing the data to see what results we get. When we do this, we should add a feature 'domain' meaning which domain it comes from (resteraunts, hotels or books)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which training set do we use?\n",
    "\n",
    "The most trustworthy sets are those that are gold standard. The problem with these is that there is not enough data available in these sets.\n",
    "\n",
    "We don't know how much the different domains will affect our results. It might be possible to train on our ground truth set of hotel reviews and test on the gold standard set, however we only have 5854 ground truth hotel reviews. We do not know how this will perform until we experiment with it.\n",
    "\n",
    "Initial experiments could be:\n",
    "* Train & test on single domain 'ground truth' restaurant set from NYC.\n",
    "* Trian & test on multi domain 'ground truth' resteraunt set from NYC and Chicago. (domains are NYC and Chicago)\n",
    "* Trian & test on multi domain 'ground truth' resteraunt set and hotel set from NYC and Chicago (domains are NYC-Res, Chi-Res and Chi-Hotels)\n",
    "\n",
    "And the following, testing on the 'gold standard' TripAdvisor hotel set:\n",
    "* Train on single domain 'ground truth' hotel set from Chicago.\n",
    "* Train on multi domain 'ground truth' hotel and restaurant set from Chicago.\n",
    "* Train on multi domain 'ground truth' hotel and restaurant set from Chicago and NYC.\n",
    "\n",
    "All of which are in a different domain to the TripAdvisor hotel set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
