{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Neural Models 2\n",
    "\n",
    "## Feedforward Neural Network\n",
    "\n",
    "Following an experiment to compare neural models, we discovered odd results showing that bag of words could outperform embeddings. This experiment attempts to tweak the embeddings to show the expected results under the assumption that the problem is not the amount of data. If the problem is the amount of data we will investigate this in another experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will show Bag of Words results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import training_helpers\n",
    "from scripts.cross_validate import run_cross_validate\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Embedding, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from pandas import DataFrame\n",
    "from seaborn import boxplot\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "read_existing_embeddings = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = training_helpers.get_data_frame()\n",
    "raw_features = data_frame['review']\n",
    "labels = [x for x in data_frame['deceptive']]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(raw_features)\n",
    "bow_features = tokenizer.texts_to_matrix(raw_features, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words = tokenizer.word_index\n",
    "corpus_vocab_size = len(corpus_words)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with:  (1440, 9839) labels (1440,)\n",
      "160/160 [==============================] - 0s 144us/step\n",
      "Fitting with:  (1440, 9839) labels (1440,)\n",
      "160/160 [==============================] - 0s 155us/step\n",
      "Fitting with:  (1440, 9839) labels (1440,)\n",
      "160/160 [==============================] - 0s 139us/step\n",
      "Fitting with:  (1440, 9839) labels (1440,)\n",
      "160/160 [==============================] - 0s 172us/step\n",
      "Fitting with:  (1440, 9839) labels (1440,)\n",
      "160/160 [==============================] - 0s 172us/step\n",
      "Fitting with:  (1440, 9839) labels (1440,)\n",
      "160/160 [==============================] - 0s 190us/step\n",
      "Fitting with:  (1440, 9839) labels (1440,)\n",
      "160/160 [==============================] - 0s 199us/step\n",
      "Fitting with:  (1440, 9839) labels (1440,)\n",
      "160/160 [==============================] - 0s 219us/step\n",
      "Fitting with:  (1440, 9839) labels (1440,)\n",
      "160/160 [==============================] - 0s 129us/step\n",
      "Fitting with:  (1440, 9839) labels (1440,)\n",
      "160/160 [==============================] - 0s 196us/step\n"
     ]
    }
   ],
   "source": [
    "def get_ff_bow_model():\n",
    "  model = Sequential([\n",
    "      Dense(16, activation=relu, input_shape=(corpus_vocab_size,), kernel_regularizer=l2(0.01)),\n",
    "      Dropout(0.25),\n",
    "      Dense(8, activation=relu, kernel_regularizer=l2(0.01)),\n",
    "      Dense(1, activation=sigmoid)\n",
    "  ])\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "ff_bow_scores = run_cross_validate(get_ff_bow_model, bow_features, labels, cv=10, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we will get results for embeddings. This time I will use Word2Vec. Although this was not trained directly on words from our dataset, the Word2Vec has a higher dimensionality (making it harder to run on our machines) and so may show better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = None\n",
    "embedding_length = 0\n",
    "if read_existing_embeddings:\n",
    "  embedding_length=300\n",
    "  embedding_matrix = np.zeros((corpus_vocab_size, embedding_length))\n",
    "  with open('data.json', 'r') as infile:\n",
    "      data = json.load(infile)\n",
    "      for i in range(len(data)):\n",
    "          embedding_matrix[i] = np.array(data[i], dtype=np.float32)\n",
    "else:\n",
    "  word_vectors = gensim.models.KeyedVectors.load_word2vec_format(\"../data/GoogleNews-vectors-negative300.bin\",\n",
    "                                                                 binary=True)\n",
    "  embedding_length = word_vectors.vector_size\n",
    "    \n",
    "  embedding_matrix = np.zeros((corpus_vocab_size, embedding_length))\n",
    "  for word, index in corpus_words.items():\n",
    "    if word in word_vectors.vocab:\n",
    "      embedding_matrix[index] = np.array(word_vectors[word], dtype=np.float32)\n",
    "\n",
    "  with open('data.json', 'w') as outfile:\n",
    "      json.dump(embedding_matrix.tolist(), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ff_wv_model():\n",
    "  model_ff_wv = Sequential([\n",
    "      Embedding(corpus_vocab_size, embedding_length, weights=[embedding_matrix], trainable=False,\n",
    "                input_length=corpus_vocab_size),\n",
    "      Flatten(),\n",
    "      Dense(16, activation=relu, kernel_regularizer=l2(0.01)),\n",
    "      Dropout(0.25),\n",
    "      Dense(8, activation=relu, kernel_regularizer=l2(0.01)),\n",
    "      Dense(1, activation=sigmoid)\n",
    "  ])\n",
    "  model_ff_wv.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  return model_ff_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with:  (1280, 9839) labels (1280,)\n",
      "Train on 896 samples, validate on 384 samples\n",
      "Epoch 1/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.0891 - acc: 0.5882 - val_loss: 1.2110 - val_acc: 0.6198\n",
      "Epoch 2/12\n",
      "896/896 [==============================] - 38s 43ms/step - loss: 1.2013 - acc: 0.7132 - val_loss: 1.3584 - val_acc: 0.6745\n",
      "Epoch 3/12\n",
      "896/896 [==============================] - 38s 42ms/step - loss: 1.2186 - acc: 0.7333 - val_loss: 1.4261 - val_acc: 0.7005\n",
      "Epoch 4/12\n",
      "896/896 [==============================] - 38s 42ms/step - loss: 1.2512 - acc: 0.7054 - val_loss: 1.3712 - val_acc: 0.6484\n",
      "Epoch 5/12\n",
      "896/896 [==============================] - 38s 43ms/step - loss: 1.2558 - acc: 0.7533 - val_loss: 1.4386 - val_acc: 0.6719\n",
      "320/320 [==============================] - 2s 7ms/step\n",
      "Fitting with:  (1280, 9839) labels (1280,)\n",
      "Train on 896 samples, validate on 384 samples\n",
      "Epoch 1/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 0.9364 - acc: 0.5569 - val_loss: 1.0129 - val_acc: 0.6198\n",
      "Epoch 2/12\n",
      "896/896 [==============================] - 40s 44ms/step - loss: 1.1214 - acc: 0.6853 - val_loss: 1.2568 - val_acc: 0.6693\n",
      "Epoch 3/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.2156 - acc: 0.7355 - val_loss: 1.3580 - val_acc: 0.6823\n",
      "Epoch 4/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.2638 - acc: 0.7533 - val_loss: 1.5648 - val_acc: 0.6693\n",
      "Epoch 5/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.2139 - acc: 0.7879 - val_loss: 1.4685 - val_acc: 0.6354\n",
      "320/320 [==============================] - 2s 7ms/step\n",
      "Fitting with:  (1280, 9839) labels (1280,)\n",
      "Train on 896 samples, validate on 384 samples\n",
      "Epoch 1/12\n",
      "896/896 [==============================] - 47s 52ms/step - loss: 1.1827 - acc: 0.6306 - val_loss: 1.3397 - val_acc: 0.6823\n",
      "Epoch 2/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.1347 - acc: 0.7779 - val_loss: 1.4744 - val_acc: 0.7135\n",
      "Epoch 3/12\n",
      "896/896 [==============================] - 43s 47ms/step - loss: 1.2657 - acc: 0.7746 - val_loss: 1.3647 - val_acc: 0.6979\n",
      "Epoch 4/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.2354 - acc: 0.8013 - val_loss: 1.5523 - val_acc: 0.6901\n",
      "Epoch 5/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.2216 - acc: 0.8114 - val_loss: 1.4533 - val_acc: 0.7109\n",
      "320/320 [==============================] - 2s 7ms/step\n",
      "Fitting with:  (1280, 9839) labels (1280,)\n",
      "Train on 896 samples, validate on 384 samples\n",
      "Epoch 1/12\n",
      "896/896 [==============================] - 51s 57ms/step - loss: 0.9980 - acc: 0.5904 - val_loss: 1.1417 - val_acc: 0.6328\n",
      "Epoch 2/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.2157 - acc: 0.6775 - val_loss: 1.3167 - val_acc: 0.6797\n",
      "Epoch 3/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.2370 - acc: 0.7243 - val_loss: 1.2874 - val_acc: 0.6875\n",
      "Epoch 4/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.2164 - acc: 0.7143 - val_loss: 1.3321 - val_acc: 0.6797\n",
      "Epoch 5/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.2309 - acc: 0.7355 - val_loss: 1.3525 - val_acc: 0.6901\n",
      "320/320 [==============================] - 2s 7ms/step\n",
      "Fitting with:  (1280, 9839) labels (1280,)\n",
      "Train on 896 samples, validate on 384 samples\n",
      "Epoch 1/12\n",
      "896/896 [==============================] - 64s 71ms/step - loss: 0.9597 - acc: 0.5413 - val_loss: 1.0838 - val_acc: 0.5859\n",
      "Epoch 2/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.0716 - acc: 0.6696 - val_loss: 1.1920 - val_acc: 0.6693\n",
      "Epoch 3/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.0781 - acc: 0.7277 - val_loss: 1.0938 - val_acc: 0.6823\n",
      "Epoch 4/12\n",
      "896/896 [==============================] - 44s 49ms/step - loss: 1.0370 - acc: 0.7277 - val_loss: 1.2011 - val_acc: 0.6536\n",
      "Epoch 5/12\n",
      "896/896 [==============================] - 42s 47ms/step - loss: 1.0845 - acc: 0.7779 - val_loss: 1.2248 - val_acc: 0.6979\n",
      "320/320 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "ff_wv_scores = run_cross_validate(get_ff_wv_model, bow_features, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words:  [0.875, 0.8625, 0.88125, 0.88125, 0.86875, 0.91875, 0.875, 0.8625, 0.88125, 0.8875]\n",
      "Word vectors:  [0.628125, 0.709375, 0.665625, 0.703125, 0.659375]\n"
     ]
    }
   ],
   "source": [
    "print (\"Bag of words: \", ff_bow_scores['accuracies'])\n",
    "print (\"Word vectors: \", ff_wv_scores['accuracies'])\n",
    "\n",
    "ff_scores_entries =[('Bag of Words', x) for x in ff_bow_scores['accuracies']] + [('Word Vectors', x) for x in ff_wv_scores['accuracies']]\n",
    "ff_scores_data_frame = DataFrame(ff_scores_entries, columns=['input type', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(x='input type', y='accuracy', data=ff_scores_data_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like word vectors are doing better now! Although they should be more accurate than Bag of Words, unless this is an exceptional case. The next step here is to investigate how BoW and word vectors perform on more data, since a small amount of data is a case known to cause results like this. It is also very unlikely Bag of Words will perform as well on a large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research has shown that word embeddings perform better than Bag of Words (Convolutional Neural Networks for Sentence Classification, Yoon Kim 2014). We will our convolutional network on Word2Vec embeddings to see if we obtain an improved accuracy. First we will obtain results for bag of words again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 1, 9839, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = 1600\n",
    "convolutional_data = np.array(np.split(np.array([[[y] for y in z] for z in bow_features]), batches))\n",
    "convolutional_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with:  (1440, 1, 9839, 1) labels (1440, 2)\n",
      "Train on 1007 samples, validate on 433 samples\n",
      "Epoch 1/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.4154 - acc: 0.8093 - val_loss: 0.7797 - val_acc: 0.6189\n",
      "Epoch 2/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1201 - acc: 0.9593 - val_loss: 0.9390 - val_acc: 0.6143\n",
      "Epoch 3/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.0768 - acc: 0.9811 - val_loss: 0.9623 - val_acc: 0.6143\n",
      "Epoch 4/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0413 - acc: 0.9871 - val_loss: 1.0925 - val_acc: 0.6051\n",
      "Epoch 5/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.0225 - acc: 0.9980 - val_loss: 1.4042 - val_acc: 0.6028\n",
      "160/160 [==============================] - 1s 4ms/step\n",
      "Fitting with:  (1440, 1, 9839, 1) labels (1440, 2)\n",
      "Train on 1007 samples, validate on 433 samples\n",
      "Epoch 1/12\n",
      "1007/1007 [==============================] - 10s 10ms/step - loss: 0.4260 - acc: 0.7915 - val_loss: 0.6652 - val_acc: 0.6721\n",
      "Epoch 2/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1243 - acc: 0.9593 - val_loss: 0.8342 - val_acc: 0.6143\n",
      "Epoch 3/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0695 - acc: 0.9801 - val_loss: 0.9113 - val_acc: 0.6143\n",
      "Epoch 4/12\n",
      "1007/1007 [==============================] - 7s 7ms/step - loss: 0.0395 - acc: 0.9930 - val_loss: 1.0827 - val_acc: 0.6097\n",
      "Epoch 5/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0217 - acc: 0.9990 - val_loss: 1.4048 - val_acc: 0.5866\n",
      "160/160 [==============================] - 1s 4ms/step\n",
      "Fitting with:  (1440, 1, 9839, 1) labels (1440, 2)\n",
      "Train on 1007 samples, validate on 433 samples\n",
      "Epoch 1/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.4536 - acc: 0.7865 - val_loss: 0.7148 - val_acc: 0.6074\n",
      "Epoch 2/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1378 - acc: 0.9573 - val_loss: 0.7478 - val_acc: 0.6443\n",
      "Epoch 3/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0764 - acc: 0.9801 - val_loss: 0.9156 - val_acc: 0.6189\n",
      "Epoch 4/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0407 - acc: 0.9921 - val_loss: 1.0163 - val_acc: 0.6259\n",
      "Epoch 5/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0281 - acc: 0.9980 - val_loss: 1.1084 - val_acc: 0.6259\n",
      "160/160 [==============================] - 1s 4ms/step\n",
      "Fitting with:  (1440, 1, 9839, 1) labels (1440, 2)\n",
      "Train on 1007 samples, validate on 433 samples\n",
      "Epoch 1/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.4359 - acc: 0.7865 - val_loss: 0.6604 - val_acc: 0.6443\n",
      "Epoch 2/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1356 - acc: 0.9513 - val_loss: 0.7891 - val_acc: 0.6305\n",
      "Epoch 3/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0752 - acc: 0.9752 - val_loss: 0.9207 - val_acc: 0.6351\n",
      "Epoch 4/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0403 - acc: 0.9911 - val_loss: 1.0398 - val_acc: 0.6143\n",
      "Epoch 5/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0254 - acc: 0.9970 - val_loss: 1.2071 - val_acc: 0.5958\n",
      "160/160 [==============================] - 1s 4ms/step\n",
      "Fitting with:  (1440, 1, 9839, 1) labels (1440, 2)\n",
      "Train on 1007 samples, validate on 433 samples\n",
      "Epoch 1/12\n",
      "1007/1007 [==============================] - 10s 10ms/step - loss: 0.4518 - acc: 0.7766 - val_loss: 0.7762 - val_acc: 0.6005\n",
      "Epoch 2/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1332 - acc: 0.9553 - val_loss: 0.7796 - val_acc: 0.6351\n",
      "Epoch 3/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0774 - acc: 0.9791 - val_loss: 1.0630 - val_acc: 0.6051\n",
      "Epoch 4/12\n",
      "1007/1007 [==============================] - 9s 8ms/step - loss: 0.0478 - acc: 0.9871 - val_loss: 1.0660 - val_acc: 0.6328\n",
      "Epoch 5/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.0238 - acc: 0.9980 - val_loss: 1.2081 - val_acc: 0.6443\n",
      "160/160 [==============================] - 1s 4ms/step\n",
      "Fitting with:  (1440, 1, 9839, 1) labels (1440, 2)\n",
      "Train on 1007 samples, validate on 433 samples\n",
      "Epoch 1/12\n",
      "1007/1007 [==============================] - 10s 10ms/step - loss: 0.4275 - acc: 0.7905 - val_loss: 0.6714 - val_acc: 0.6559\n",
      "Epoch 2/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1216 - acc: 0.9633 - val_loss: 0.8006 - val_acc: 0.6328\n",
      "Epoch 3/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0662 - acc: 0.9831 - val_loss: 0.9595 - val_acc: 0.6189\n",
      "Epoch 4/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.0373 - acc: 0.9930 - val_loss: 1.0529 - val_acc: 0.5982\n",
      "Epoch 5/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0223 - acc: 1.0000 - val_loss: 1.3163 - val_acc: 0.5958\n",
      "160/160 [==============================] - 1s 4ms/step\n",
      "Fitting with:  (1440, 1, 9839, 1) labels (1440, 2)\n",
      "Train on 1007 samples, validate on 433 samples\n",
      "Epoch 1/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.4201 - acc: 0.7944 - val_loss: 0.6994 - val_acc: 0.6536\n",
      "Epoch 2/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1264 - acc: 0.9603 - val_loss: 0.8321 - val_acc: 0.6282\n",
      "Epoch 3/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.0656 - acc: 0.9861 - val_loss: 1.0260 - val_acc: 0.6097\n",
      "Epoch 4/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.0359 - acc: 0.9950 - val_loss: 1.3723 - val_acc: 0.5889\n",
      "Epoch 5/12\n",
      "1007/1007 [==============================] - 9s 8ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 1.3757 - val_acc: 0.5912\n",
      "160/160 [==============================] - 1s 4ms/step\n",
      "Fitting with:  (1440, 1, 9839, 1) labels (1440, 2)\n",
      "Train on 1007 samples, validate on 433 samples\n",
      "Epoch 1/12\n",
      "1007/1007 [==============================] - 10s 10ms/step - loss: 0.4649 - acc: 0.7656 - val_loss: 0.6972 - val_acc: 0.6467\n",
      "Epoch 2/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1442 - acc: 0.9573 - val_loss: 0.7018 - val_acc: 0.6605\n",
      "Epoch 3/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0873 - acc: 0.9762 - val_loss: 0.8550 - val_acc: 0.6328\n",
      "Epoch 4/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0512 - acc: 0.9891 - val_loss: 1.1547 - val_acc: 0.5982\n",
      "Epoch 5/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0388 - acc: 0.9901 - val_loss: 1.1154 - val_acc: 0.6259\n",
      "160/160 [==============================] - 1s 4ms/step\n",
      "Fitting with:  (1440, 1, 9839, 1) labels (1440, 2)\n",
      "Train on 1007 samples, validate on 433 samples\n",
      "Epoch 1/12\n",
      "1007/1007 [==============================] - 11s 11ms/step - loss: 0.4866 - acc: 0.7498 - val_loss: 0.7086 - val_acc: 0.6328\n",
      "Epoch 2/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.1414 - acc: 0.9494 - val_loss: 0.7206 - val_acc: 0.6628\n",
      "Epoch 3/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.0763 - acc: 0.9811 - val_loss: 0.8427 - val_acc: 0.6582\n",
      "Epoch 4/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.0460 - acc: 0.9901 - val_loss: 1.0458 - val_acc: 0.6236\n",
      "Epoch 5/12\n",
      "1007/1007 [==============================] - 9s 9ms/step - loss: 0.0255 - acc: 0.9980 - val_loss: 1.1191 - val_acc: 0.6189\n",
      "160/160 [==============================] - 1s 4ms/step\n",
      "Fitting with:  (1440, 1, 9839, 1) labels (1440, 2)\n",
      "Train on 1007 samples, validate on 433 samples\n",
      "Epoch 1/12\n",
      "1007/1007 [==============================] - 10s 10ms/step - loss: 0.4436 - acc: 0.7805 - val_loss: 0.6769 - val_acc: 0.6351\n",
      "Epoch 2/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.1286 - acc: 0.9533 - val_loss: 0.7343 - val_acc: 0.6397\n",
      "Epoch 3/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0720 - acc: 0.9791 - val_loss: 0.9275 - val_acc: 0.6074\n",
      "Epoch 4/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0413 - acc: 0.9921 - val_loss: 1.1031 - val_acc: 0.5958\n",
      "Epoch 5/12\n",
      "1007/1007 [==============================] - 8s 8ms/step - loss: 0.0274 - acc: 0.9970 - val_loss: 1.2255 - val_acc: 0.5797\n",
      "160/160 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "def get_conv_bow_model():\n",
    "  model = Sequential([\n",
    "      Conv2D(\n",
    "          filters=50,\n",
    "          kernel_size=(1, 10),\n",
    "          data_format=\"channels_last\",\n",
    "          input_shape=(1, corpus_vocab_size, 1),\n",
    "          activation=relu),\n",
    "      MaxPooling2D(pool_size=(1, 10)),\n",
    "      Dropout(0.2),\n",
    "      Flatten(),\n",
    "      Dense(2, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "conv_bow_scores = run_cross_validate(get_conv_bow_model, convolutional_data, labels, cv=10, categorical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter out reviews with more than 300 words because a small number have an exceptionally large number of words and dramatically increase the memory requirements. These reviews are rare and are not expected to provide much value, while also preventing this experiment from being run on a normal machine, so I will filter them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_words = []\n",
    "conv_wv_labels = []\n",
    "for i, raw_feature in enumerate(raw_features):\n",
    "    word_sequence = text_to_word_sequence(raw_feature)\n",
    "    if len(word_sequence) > 300:\n",
    "        continue\n",
    "    conv_wv_labels.append(labels[i])\n",
    "    reviews_words.append(word_sequence)\n",
    "max_review_len = max([len(x) for x in reviews_words])\n",
    "\n",
    "vectorized_reviews = np.zeros((len(reviews_words), 1, max_review_len, 300))\n",
    "for i, review in enumerate(reviews_words):\n",
    "    for j, word in enumerate(review):\n",
    "        vectorized_reviews[i][0][j] = [x for x in embedding_matrix[corpus_words[word]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with:  (1254, 1, 300, 300) labels (1254, 2)\n",
      "Train on 877 samples, validate on 377 samples\n",
      "Epoch 1/12\n",
      "877/877 [==============================] - 8s 9ms/step - loss: 0.6703 - acc: 0.5656 - val_loss: 0.6150 - val_acc: 0.6737\n",
      "Epoch 2/12\n",
      "877/877 [==============================] - 7s 8ms/step - loss: 0.4994 - acc: 0.7491 - val_loss: 0.5233 - val_acc: 0.7188\n",
      "Epoch 3/12\n",
      "877/877 [==============================] - 7s 8ms/step - loss: 0.2804 - acc: 0.8871 - val_loss: 0.5103 - val_acc: 0.7560\n",
      "Epoch 4/12\n",
      "877/877 [==============================] - 7s 9ms/step - loss: 0.1215 - acc: 0.9749 - val_loss: 0.5896 - val_acc: 0.7480\n",
      "Epoch 5/12\n",
      "877/877 [==============================] - 7s 8ms/step - loss: 0.0411 - acc: 0.9977 - val_loss: 0.5659 - val_acc: 0.7533\n",
      "Epoch 6/12\n",
      "877/877 [==============================] - 8s 9ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.5962 - val_acc: 0.7666\n",
      "Epoch 7/12\n",
      "877/877 [==============================] - 7s 8ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.6003 - val_acc: 0.7692\n",
      "252/252 [==============================] - 1s 3ms/step\n",
      "Fitting with:  (1254, 1, 300, 300) labels (1254, 2)\n",
      "Train on 877 samples, validate on 377 samples\n",
      "Epoch 1/12\n",
      "877/877 [==============================] - 8s 9ms/step - loss: 0.6795 - acc: 0.5530 - val_loss: 0.6402 - val_acc: 0.6207\n",
      "Epoch 2/12\n",
      "877/877 [==============================] - 7s 8ms/step - loss: 0.5136 - acc: 0.7548 - val_loss: 0.5188 - val_acc: 0.7533\n",
      "Epoch 3/12\n",
      "877/877 [==============================] - 7s 8ms/step - loss: 0.2888 - acc: 0.8997 - val_loss: 0.4976 - val_acc: 0.7692\n",
      "Epoch 4/12\n",
      "877/877 [==============================] - 8s 9ms/step - loss: 0.1243 - acc: 0.9772 - val_loss: 0.4873 - val_acc: 0.7772\n",
      "Epoch 5/12\n",
      "877/877 [==============================] - 7s 9ms/step - loss: 0.0388 - acc: 0.9989 - val_loss: 0.5377 - val_acc: 0.7798\n",
      "Epoch 6/12\n",
      "877/877 [==============================] - 8s 9ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.5269 - val_acc: 0.7984\n",
      "Epoch 7/12\n",
      "877/877 [==============================] - 7s 8ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5536 - val_acc: 0.7639\n",
      "Epoch 8/12\n",
      "877/877 [==============================] - 7s 8ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5557 - val_acc: 0.7745\n",
      "252/252 [==============================] - 1s 3ms/step\n",
      "Fitting with:  (1255, 1, 300, 300) labels (1255, 2)\n",
      "Train on 878 samples, validate on 377 samples\n",
      "Epoch 1/12\n",
      "878/878 [==============================] - 8s 9ms/step - loss: 0.6611 - acc: 0.5683 - val_loss: 0.5982 - val_acc: 0.6737\n",
      "Epoch 2/12\n",
      "878/878 [==============================] - 7s 8ms/step - loss: 0.4534 - acc: 0.8018 - val_loss: 0.5432 - val_acc: 0.7082\n",
      "Epoch 3/12\n",
      "878/878 [==============================] - 7s 8ms/step - loss: 0.1998 - acc: 0.9396 - val_loss: 0.5480 - val_acc: 0.7480\n",
      "Epoch 4/12\n",
      "878/878 [==============================] - 7s 8ms/step - loss: 0.0631 - acc: 0.9920 - val_loss: 0.6016 - val_acc: 0.7241\n",
      "Epoch 5/12\n",
      "878/878 [==============================] - 7s 8ms/step - loss: 0.0247 - acc: 0.9977 - val_loss: 0.6193 - val_acc: 0.7427\n",
      "Epoch 6/12\n",
      "878/878 [==============================] - 8s 9ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.6673 - val_acc: 0.7374\n",
      "251/251 [==============================] - 1s 4ms/step\n",
      "Fitting with:  (1255, 1, 300, 300) labels (1255, 2)\n",
      "Train on 878 samples, validate on 377 samples\n",
      "Epoch 1/12\n",
      "878/878 [==============================] - 8s 10ms/step - loss: 0.6294 - acc: 0.6207 - val_loss: 0.6388 - val_acc: 0.6605\n",
      "Epoch 2/12\n",
      "878/878 [==============================] - 8s 9ms/step - loss: 0.4074 - acc: 0.8064 - val_loss: 0.5437 - val_acc: 0.7374\n",
      "Epoch 3/12\n",
      "878/878 [==============================] - 7s 8ms/step - loss: 0.1881 - acc: 0.9396 - val_loss: 0.5386 - val_acc: 0.7454\n",
      "Epoch 4/12\n",
      "878/878 [==============================] - 7s 8ms/step - loss: 0.0700 - acc: 0.9954 - val_loss: 0.5646 - val_acc: 0.7454\n",
      "Epoch 5/12\n",
      "878/878 [==============================] - 7s 8ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.7156 - val_acc: 0.7666\n",
      "Epoch 6/12\n",
      "878/878 [==============================] - 7s 8ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.6859 - val_acc: 0.7294\n",
      "Epoch 7/12\n",
      "878/878 [==============================] - 7s 8ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.6885 - val_acc: 0.7401\n",
      "251/251 [==============================] - 1s 3ms/step\n",
      "Fitting with:  (1256, 1, 300, 300) labels (1256, 2)\n",
      "Train on 879 samples, validate on 377 samples\n",
      "Epoch 1/12\n",
      "879/879 [==============================] - 8s 9ms/step - loss: 0.6488 - acc: 0.6166 - val_loss: 0.6236 - val_acc: 0.6578\n",
      "Epoch 2/12\n",
      "879/879 [==============================] - 7s 8ms/step - loss: 0.3916 - acc: 0.8419 - val_loss: 0.5349 - val_acc: 0.7560\n",
      "Epoch 3/12\n",
      "879/879 [==============================] - 7s 8ms/step - loss: 0.1415 - acc: 0.9727 - val_loss: 0.5533 - val_acc: 0.7454\n",
      "Epoch 4/12\n",
      "879/879 [==============================] - 7s 8ms/step - loss: 0.0449 - acc: 0.9977 - val_loss: 0.5919 - val_acc: 0.7507\n",
      "Epoch 5/12\n",
      "879/879 [==============================] - 7s 8ms/step - loss: 0.0209 - acc: 0.9989 - val_loss: 0.5999 - val_acc: 0.7560\n",
      "Epoch 6/12\n",
      "879/879 [==============================] - 7s 8ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.6312 - val_acc: 0.7507\n",
      "250/250 [==============================] - 1s 3ms/step\n",
      "Fitting with:  (1256, 1, 300, 300) labels (1256, 2)\n",
      "Train on 879 samples, validate on 377 samples\n",
      "Epoch 1/12\n",
      "879/879 [==============================] - 8s 9ms/step - loss: 0.6585 - acc: 0.5973 - val_loss: 0.6021 - val_acc: 0.6711\n",
      "Epoch 2/12\n",
      "879/879 [==============================] - 7s 8ms/step - loss: 0.4230 - acc: 0.8055 - val_loss: 0.5247 - val_acc: 0.7374\n",
      "Epoch 3/12\n",
      "879/879 [==============================] - 7s 8ms/step - loss: 0.1802 - acc: 0.9454 - val_loss: 0.5668 - val_acc: 0.7454\n",
      "Epoch 4/12\n",
      "879/879 [==============================] - 7s 8ms/step - loss: 0.0631 - acc: 0.9954 - val_loss: 0.5973 - val_acc: 0.7401\n",
      "Epoch 5/12\n",
      "879/879 [==============================] - 7s 8ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.6069 - val_acc: 0.7586\n",
      "Epoch 6/12\n",
      "879/879 [==============================] - 7s 8ms/step - loss: 0.0102 - acc: 0.9989 - val_loss: 0.6607 - val_acc: 0.7401\n",
      "250/250 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "def get_conv_wv_model():\n",
    "  model = Sequential([\n",
    "      Conv2D(\n",
    "          filters=50,\n",
    "          kernel_size=(10, 300),\n",
    "          data_format=\"channels_first\",\n",
    "          input_shape=(1, 300, 300),\n",
    "          activation=relu),\n",
    "      MaxPooling2D(strides=(1, 1), pool_size=(2, 1), data_format=\"channels_first\"),\n",
    "      Dropout(0.2),\n",
    "      Flatten(),\n",
    "      Dense(2, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "conv_wv_scores = run_cross_validate(get_conv_wv_model, vectorized_reviews, conv_wv_labels, cv=6, categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words:  [0.7875, 0.7875, 0.8125, 0.85, 0.775, 0.80625, 0.80625, 0.81875, 0.83125, 0.86875]\n",
      "Word vectors:  [0.7579365050981915, 0.7936507917585827, 0.7808764971109975, 0.75697211060391, 0.7879999980926514, 0.7599999990463256]\n"
     ]
    }
   ],
   "source": [
    "print (\"Bag of words: \", conv_bow_scores['accuracies'])\n",
    "print (\"Word vectors: \", conv_wv_scores['accuracies'])\n",
    "\n",
    "conv_scores_entries =[('Bag of Words', x) for x in conv_bow_scores['accuracies']] + [('Word Vectors', x) for x in conv_wv_scores['accuracies']]\n",
    "conv_scores_data_frame = DataFrame(conv_scores_entries, columns=['input type', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(x='input type', y='accuracy', data=conv_scores_data_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again our results look better. If this continues to be consistent we know that Word2Vec has some property that is beneficial, which may be training on more data, or it may be the higher vector dimensionality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
